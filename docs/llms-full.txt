# Media Downloader

[![codecov](https://codecov.io/gh/j0nathan-ll0yd/aws-cloudformation-media-downloader/branch/master/graph/badge.svg)](https://codecov.io/gh/j0nathan-ll0yd/aws-cloudformation-media-downloader)

A media downloader designed to integrate with [it's companion iOS App](https://github.com/j0nathan-ll0yd/ios-OfflineMediaDownloader). It is [serverless](https://aws.amazon.com/serverless/), deployed with [OpenTofu](https://opentofu.org/), and built with [TypeScript](https://www.typescriptlang.org/).

## Architecture

View the [AWS Architecture Diagram](https://gitdiagram.com/repo/j0nathan-ll0yd/aws-cloudformation-media-downloader) (via GitDiagram)

## Technologies

### Core Stack
- **Runtime**: Node.js 22.x (AWS Lambda)
- **Language**: TypeScript with strict type checking
- **Infrastructure as Code**: OpenTofu (Terraform fork)
- **Package Manager**: pnpm (with security hardening)

### Authentication & Authorization
- **Better Auth 1.4.3**: Modern authentication framework with session management
- **First-in-class ElectroDB Adapter**: Custom DynamoDB adapter for Better Auth
- **Apple Sign In**: OAuth provider with ID token flow (eliminates 200-500ms latency)
- **Session-based Auth**: 30-day sessions with automatic refresh
- **Custom Authorizer**: Query-based API tokens for Feedly integration

### Database & ORM
- **DynamoDB**: AWS NoSQL database with single-table design
- **ElectroDB**: Type-safe ORM with optimized GSI queries
- **Entities**: Users, Sessions, Accounts, VerificationTokens, Files, Devices
- **Collections**: JOIN-like queries across entity boundaries

### AWS Services
- **Lambda**: Serverless compute (all business logic)
- **S3**: Media storage with transfer acceleration
- **API Gateway**: REST endpoints with custom authorizer
- **SNS**: Apple Push Notification Service (APNS) delivery
- **CloudWatch**: Logging, metrics, and fixture extraction
- **X-Ray**: Distributed tracing (optional)

### Development & Testing
- **Jest**: Unit testing with ESM support
- **LocalStack**: Local AWS service emulation for integration tests
- **Webpack**: Lambda function bundling with externals optimization
- **TSDoc**: API documentation generation
- **Fixture Logging**: Production request/response capture for test generation

### Media Processing
- **yt-dlp**: YouTube video downloading (auto-updated weekly)
- **FFmpeg**: Video processing and conversion
- **Cookie Authentication**: Bypass YouTube bot detection

### Notable Features
- **First ElectroDB adapter for Better Auth** (potential npm package)
- **Automated fixture extraction from CloudWatch** for test generation
- **pnpm lifecycle script protection** against supply chain attacks
- **Convention capture system** for institutional knowledge preservation

## Background

When [YouTube Premium](https://en.wikipedia.org/wiki/YouTube_Premium) was released they announced "exclusive original content, access to audio-only versions of videos and offline playback on your mobile device." I wasn't interested in the content, but I was excited about offline playback due to poor connectivity when commuting via the [MUNI](https://www.sfmta.com/). _Buuuuuuut_, there was a monthly fee of $11.99.

So, [as an engineer](https://www.linkedin.com/in/lifegames), I used this opportunity to build my own media downloader service, experiment with the latest AWS features, along with a [companion iOS App](https://github.com/j0nathan-ll0yd/ios-OfflineMediaDownloader) using SwiftUI and Combine.

The end result is a generic backend infrastructure that could support any number of features or Apps. This repository is the source code, OpenTofu templates, deployment scripts, documentation and tests that power the App's backend. This includes:

* **Authentication**: Better Auth integration with Apple Sign In (ID token flow) and session management
* **Media Downloads**: Download videos and store them to an S3 bucket
* **API Access**: View downloaded videos via authenticated REST API
* **Push Notifications**: Register for and dispatch push notifications to the iOS App
* **Custom Authorization**: Custom authorizer Lambda supporting query-based API tokens (Feedly integration)
* **Database**: DynamoDB single-table design with ElectroDB ORM for type-safe queries

I share this for any engineer to be able to build a basic backend and iOS App for a future pet project.

## Project Tenants

* The costs per month should be less than $12.
* Minimize external dependencies.
* [Convention over configuration](https://en.wikipedia.org/wiki/Convention_over_configuration). Minimize code, leverage AWS services.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

```bash
# Ensure the correct version of NodeJS (via NVM)
nvm use lts/hydrogen

# Install pnpm globally
npm install -g pnpm

# Install dependencies
pnpm install

# Build the AWS Lambda functions (using esbuild)
pnpm run build

# Run the tests to ensure everything is working
pnpm run test

# Use OpenTofu to deploy the infrastructure
cd terraform
tofu init
tofu apply

# Once complete, verify the application works remotely
pnpm run test-remote-list
pnpm run test-remote-hook
```

## Quick Start

```bash
# Install system dependencies and configure
brew install awscli graphviz jq nvm quicktype opentofu terraform-docs
nvm install lts/hydrogen
nvm use lts/hydrogen
npm install -g pnpm
aws configure

# Install Node dependencies and deploy project
pnpm install
pnpm run build-dependencies
pnpm run build
pnpm run test
pnpm run deploy

# Confirm everything is working as expected
pnpm run test-remote-list
```


## Installation

* Install the [Node Version Manager](https://github.com/creationix/nvm). This will allow you to download the specific version of NodeJS supported by AWS Lambda (8.10).

```bash
brew install nvm
nvm install lts/hydrogen
nvm use lts/hydrogen
```

* Install the [Official Amazon AWS command-line interface](https://aws.amazon.com/cli/). [Configure](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html) for your AWS account.

```bash
brew install awscli
aws configure
```

* Install [OpenTofu](https://opentofu.org/) (used for deployment scripts)

```bash
brew install opentofu
```

* Install [sops](https://github.com/getsops/sops) (used for secret management)

```bash
brew install sops age

# Generate a local encryption key (AGE format - modern and simple)
mkdir -p ~/.config/sops/age
age-keygen -o ~/.config/sops/age/keys.txt

# Get the public key for SOPS config
PUBLIC_KEY=$(age-keygen -y ~/.config/sops/age/keys.txt)
echo "Your public key: $PUBLIC_KEY"

# Create SOPS config in your project root
cat > .sops.yaml << EOF
creation_rules:
  # YAML and JSON files
  - path_regex: secrets\.yaml
    age: $PUBLIC_KEY
EOF

# Create secrets.yaml template
cat > secrets.yaml << 'EOF'
signInWithApple:
  config: >
    {"client_id":"your.bundle.id","team_id":"YOUR_TEAM_ID","redirect_uri":"","key_id":"YOUR_KEY_ID","scope":"email name"}
  authKey: |
    -----BEGIN PRIVATE KEY-----
    YOUR_SIGN_IN_WITH_APPLE_PRIVATE_KEY_HERE
    -----END PRIVATE KEY-----

apns:
  staging:
    team: YOUR_TEAM_ID
    keyId: YOUR_APNS_KEY_ID
    defaultTopic: your.bundle.id
    host: 'api.sandbox.push.apple.com'
    signingKey: |
      -----BEGIN PRIVATE KEY-----
      YOUR_APNS_SIGNING_KEY_HERE
      -----END PRIVATE KEY-----
    privateKey: |
      -----BEGIN PRIVATE KEY-----
      YOUR_APNS_PRIVATE_KEY_HERE
      -----END PRIVATE KEY-----
    certificate: |
      -----BEGIN CERTIFICATE-----
      YOUR_APNS_CERTIFICATE_HERE
      -----END CERTIFICATE-----

github:
  issue:
    token: YOUR_GITHUB_PERSONAL_ACCESS_TOKEN

platform:
  key: 'YOUR_RANDOM_ENCRYPTION_KEY_HERE'
EOF

echo "Setup complete! Your private key is in ~/.config/sops/age/keys.txt"
echo "Public key added to .sops.yaml"
echo "Created secrets.yaml template - update with your actual values"
echo "Keep your private key secure and share the public key with team members"

# Encrypt secrets (after updating with real values)
# sops --encrypt --output secrets.yaml.encrypted secrets.yaml
```

* Install [quicktype](https://quicktype.io/) (used for generating TypeScript types from OpenTofu)

```bash
brew install quicktype
```

* Install [terraform-docs](https://github.com/terraform-docs/terraform-docs) (used for infrastructure documentation)

```bash
brew install terraform-docs
```

* Install [jq](https://stedolan.github.io/jq/) (used for JSON parsing)

```bash
brew install jq
```

* Install [Graphviz](https://graphviz.org/) (used for dependency graph visualization)

```bash
brew install graphviz
```

* Install [gh](https://cli.github.com/) (for Github usage by Claude Code)

```bash
brew install gh
```

## Migration from Terraform to OpenTofu

This project migrated from Terraform to OpenTofu in [PR #95](https://github.com/j0nathan-ll0yd/aws-cloudformation-media-downloader/pull/95). OpenTofu is a drop-in replacement for Terraform with 100% HCL compatibility.

### Why OpenTofu?

- **Open Source Fork**: Based on Terraform 1.5 with MPL v2 license (no relicensing risk)
- **Community Governance**: Steering committee prevents single-vendor control
- **Enhanced Features**: State encryption, provider iteration, resource exclusion, early variable evaluation
- **Provider Compatibility**: Uses identical provider source code as Terraform with OpenTofu's own registry at registry.opentofu.org

Read more: [Make the Switch to OpenTofu](https://gruntwork.io/blog/make-the-switch-to-opentofu)

### For Existing Deployments

If you have an existing Terraform deployment, migration is straightforward:

```bash
# 1. Install OpenTofu (if not already installed)
brew install opentofu

# 2. No changes needed to .terraform/ directory or state files
# OpenTofu is fully compatible with Terraform state

# 3. Clean and reinitialize to use OpenTofu registry
cd terraform
rm -rf .terraform .terraform.lock.hcl
tofu init

# 4. Verify configuration
tofu validate

# 5. Review planned changes (should show no infrastructure changes)
tofu plan

# 6. Continue using npm scripts as before
cd ..
npm run deploy
```

**Note**: The `.terraform/` directory name and `.tf` file extensions remain unchanged - OpenTofu maintains backward compatibility with these conventions.

## Configuring Push Notifications

In order for this project to work out-of-the-box, you will need to do some additional configuration in order to support push notifications. This includes generating a certificate to use the Apple Push Notification Service (APNS) and a subsequent p12 file. Instructions can be found [here](https://calvium.com/how-to-make-a-p12-file/).

Once created, you will extract the certificate and the private key in to separate files and move them in to the `secure/APNS_SANDBOX` directory at the root of the project:

```bash
# Extract the private key
openssl pkcs12 -in certificate.p12 -nodes -nocerts -legacy | sed -ne '/-BEGIN PRIVATE KEY-/,/-END PRIVATE KEY-/p' > privateKey.txt

# Extract the certificate file
openssl pkcs12 -in certificate.p12 -clcerts -nokeys -legacy  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' > certificate.txt

# Create the directories
mkdir -p secure/APNS_SANDBOX

# Move the files in to the directory
mv privateKey.txt certificate.txt secure/APNS_SANDBOX
```

Once complete, run `tofu apply` and a new platform application will be created so you can register your device to receive push notifications.

## Configuring Github Issue Creation

As an engineer, I appreciate actionable alerting. If something went wrong, I'd like to be able to know about it, have the relevant data to address the situation, and then mark it as completed. To do this, errors that are correctable will be automatically submitted as Github issues to the repository. To support this functionality, you need to generate a [Github Personal Token](https://github.com/settings/tokens?type=beta) that has access to creating issues.

Once generated, store it as `githubPersonalToken.txt` in the `secure` directory so that it isn't tracked by version control.

## Deployment

* Deploy Code - To deploy code changes only, this command will build the distribution files and trigger an OpenTofu **auto approval**.

```bash
npm run build
npm run deploy
```

### Production Testing

In order to test your endpoint in production, you can use the npm commands below.

Remotely test the listing of files

```bash
npm run test-remote-list
```

Remotely test the feedly webhook

```bash
npm run test-remote-hook
```

Remotely test the register device method for registering for push notifications on iOS

```bash
npm run test-remote-registerDevice
```

### Integration Testing with LocalStack

This project includes integration tests that run against [LocalStack](https://localstack.cloud/), a local AWS cloud emulator. Integration tests verify that AWS service interactions work correctly without mocking, providing higher confidence in production deployments.

#### Prerequisites

- **Docker**: Required to run LocalStack container (includes Compose plugin)
- **jq**: Optional, for pretty-printing health check results

```bash
brew install docker jq
```

#### Running Integration Tests

**Quick Start:**

```bash
# Full CI with integration tests (handles LocalStack lifecycle)
pnpm run ci:local:full

# Or manually manage LocalStack:
pnpm run localstack:start
pnpm run test:integration
pnpm run localstack:stop
```

**Available Commands:**

- `pnpm run ci:local` - Fast local CI checks (~2-3 min, no integration tests)
- `pnpm run ci:local:full` - Full local CI (~5-10 min, manages LocalStack lifecycle)
- `pnpm run test:integration` - Run integration tests only (~30s, for fast iteration when developing tests)
- `pnpm run localstack:start` - Start LocalStack container in detached mode
- `pnpm run localstack:stop` - Stop and remove LocalStack container
- `pnpm run localstack:logs` - Stream LocalStack logs
- `pnpm run localstack:health` - Check LocalStack service health

> **Note:** Use `ci:local:full` for comprehensive pre-push validation. Use `test:integration` with manually-started LocalStack for rapid iteration when developing integration tests.

**Test Organization:**

Integration tests are located in `test/integration/` and organized by AWS service:

```
test/integration/
‚îú‚îÄ‚îÄ s3/                   # S3 integration tests
‚îú‚îÄ‚îÄ dynamodb/             # DynamoDB integration tests
‚îú‚îÄ‚îÄ lambda/               # Lambda integration tests
‚îú‚îÄ‚îÄ sns/                  # SNS integration tests
‚îú‚îÄ‚îÄ sqs/                  # SQS integration tests
‚îú‚îÄ‚îÄ cloudwatch/           # CloudWatch integration tests
‚îî‚îÄ‚îÄ apigateway/           # API Gateway integration tests
```

**LocalStack Configuration:**

LocalStack runs on `http://localhost:4566` with ephemeral storage (fresh state each run) and provides the following AWS services:

- S3 (Simple Storage Service)
- DynamoDB (NoSQL Database)
- SNS (Simple Notification Service)
- SQS (Simple Queue Service)
- Lambda (Serverless Functions)
- CloudWatch (Monitoring)
- API Gateway (REST APIs)

**Architecture:**

Integration tests use the same vendor wrappers (`lib/vendor/AWS/*`) as production code. When `USE_LOCALSTACK=true` environment variable is set, the vendor wrappers automatically configure AWS SDK clients to connect to LocalStack instead of production AWS.

See `test/integration/README.md` for detailed integration testing documentation.

## Maintenance

### Automated yt-dlp Updates

The project uses an **OpenTofu-based binary management system** with GitHub Actions automation to keep yt-dlp up-to-date without bloating the git repository.

#### Architecture

**Version Tracking**: The `layers/yt-dlp/VERSION` file contains the current yt-dlp version (e.g., `2025.11.12`)

**OpenTofu Download**: The `null_resource.DownloadYtDlpBinary` resource in `terraform/feedly_webhook.tf`:
- Triggers whenever the VERSION file changes
- Downloads the yt-dlp binary from GitHub releases
- Verifies SHA256 checksum against official release checksums
- Tests binary execution (`--version` check)
- Makes binary executable and places it in `layers/yt-dlp/bin/`

**Git Exclusion**: The binary (`layers/yt-dlp/bin/yt-dlp_linux`) is excluded from git via `.gitignore`, preventing repository bloat

#### Automated GitHub Actions Workflow

The workflow (`.github/workflows/update-yt-dlp.yml`):
- **Runs**: Weekly on Sunday at 2am UTC
- **Trigger**: Can be manually triggered via workflow_dispatch
- **Process**:
  1. Fetches latest stable release (excludes pre-releases)
  2. Compares with current VERSION file
  3. Downloads and verifies binary for testing
  4. Tests format listing capability
  5. Updates VERSION file only (not the binary)
  6. Creates PR with release notes and deployment instructions

#### Manual Update Process

To manually check for and apply yt-dlp updates:

```bash
# Check for updates
npm run update-yt-dlp check

# Update VERSION file (if update available)
npm run update-yt-dlp update

# Review the change
git diff layers/yt-dlp/VERSION

# Test locally with OpenTofu
npm run plan  # Should show null_resource.DownloadYtDlpBinary will run

# Commit and push
git add layers/yt-dlp/VERSION
git commit -m "chore(deps): update yt-dlp to <VERSION>"
git push
```

#### Deployment Process

When a VERSION update is merged:

1. **Deploy**: Run `npm run deploy` to apply infrastructure changes
2. **Binary Download**: OpenTofu's `null_resource.DownloadYtDlpBinary` executes:
   - Downloads binary from yt-dlp GitHub releases
   - Verifies SHA256 checksum
   - Tests binary execution
3. **Layer Update**: `data.archive_file.YtDlpLayer` creates new layer zip with updated binary
4. **Lambda Update**: `aws_lambda_layer_version.YtDlp` deploys new layer version
5. **Monitoring**: Check CloudWatch logs for any download issues

#### Rollback Procedure

If a yt-dlp update causes issues in production:

```bash
# Find the previous working version
git log layers/yt-dlp/VERSION

# Revert to previous version (example: 2025.11.10)
echo "2025.11.10" > layers/yt-dlp/VERSION

# Commit and redeploy
git commit -am "chore(deps): revert yt-dlp to 2025.11.10"
git push

# Deploy with OpenTofu
npm run deploy  # Downloads and deploys the previous version
```

Alternatively, use git revert:

```bash
# Revert the problematic commit
git revert <commit-hash>
git push

# Redeploy
npm run deploy
```

#### Monitoring yt-dlp Updates

**CloudWatch Logs**: Monitor `/aws/lambda/StartFileUpload` for download failures or errors

**GitHub Issues**: The workflow automatically creates a GitHub issue if the update process fails

**Version Tracking**: The deployed version can be verified by:
```bash
# Check VERSION file
cat layers/yt-dlp/VERSION

# Check deployed Lambda layer description
aws lambda list-layer-versions --layer-name yt-dlp --region us-west-2 | jq '.LayerVersions[0]'
```

#### Benefits of This Approach

- **No repository bloat**: 35MB binary not committed to git history
- **Single source of truth**: VERSION file tracks desired version
- **Automated verification**: Checksum validation on every download
- **Easy rollback**: Change VERSION file and redeploy
- **OpenTofu integration**: Binary download is part of infrastructure deployment
- **Testing before commit**: GitHub Actions verifies binary works before creating PR

## Documentation

This project uses multiple documentation approaches:

### API Documentation with TypeSpec

The API is documented using [TypeSpec](https://typespec.io/), a language for defining APIs that generates OpenAPI specifications. To generate and view API documentation:

```bash
npm run document-api
```

This command will:
1. Automatically discover and sync API fixtures (`apiRequest-*.json` and `apiResponse-*.json`) from lambda test directories
2. Compile TypeSpec definitions to OpenAPI 3.0 specification (`docs/api/openapi.yaml`)
3. Generate a Redoc HTML documentation file (`docs/api/index.html`)
4. Automatically open the documentation in your default browser

You can also view the documentation by opening `docs/api/index.html` directly in any browser.

See `tsp/README.md` for more details about the TypeSpec definitions.

### Source Code Documentation with TSDoc

This project uses [TSDoc](https://tsdoc.org) for documenting the source code. To generate this documentation:

```bash
npm run document-source
```

The resulting output is located in `docs/source` and can open viewed by running:

```bash
open docs/source/index.html
```
# Project Context for AI Agents

## Convention Capture System

**CRITICAL**: This project captures emergent conventions during development. Read `docs/conventions-tracking.md` at session start.

### Detection Signals:
- üö® **CRITICAL**: "NEVER", "FORBIDDEN", "Zero-tolerance"
- ‚ö†Ô∏è **HIGH**: "MUST", "REQUIRED", "ALWAYS"
- üìã **MEDIUM**: "Prefer X over Y", repeated decisions

### When Convention Detected:
1. Update `docs/conventions-tracking.md` with the new convention
2. Document in appropriate wiki page under `docs/wiki/`
3. Mark as documented in tracking file

### Reference:
- **Active Conventions**: `docs/conventions-tracking.md`
- **Documentation Guide**: `docs/wiki/Meta/Convention-Capture-System.md`

**Philosophy**: Current state documented in wiki. History lives in git/PRs. No duplicate documentation.

---

## Project Overview

AWS Serverless media downloader service built with OpenTofu and TypeScript. Downloads media content (primarily YouTube videos) and integrates with a companion iOS app for offline playback. Created as a cost-effective alternative to YouTube Premium's offline playback feature.

### Architecture
- **Infrastructure**: OpenTofu (IaC)
- **Runtime**: AWS Lambda (Node.js 22.x)
- **Language**: TypeScript
- **Storage**: Amazon S3
- **API**: AWS API Gateway with custom authorizer
- **Notifications**: Apple Push Notification Service (APNS)
- **Database**: DynamoDB with ElectroDB ORM (single-table design)
- **Monitoring**: CloudWatch, X-Ray (optional)

### Project Structure
```
.
‚îú‚îÄ‚îÄ terraform/             # AWS Infrastructure definitions (OpenTofu)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ entities/          # ElectroDB entity definitions (single-table design)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Collections.ts # Service combining entities for JOIN-like queries
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Files.ts       # File entity
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FileDownloads.ts # Download tracking entity
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Users.ts       # User entity
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Devices.ts     # Device entity
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UserFiles.ts   # User-File relationships
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UserDevices.ts # User-Device relationships
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Sessions.ts    # Better Auth session entity
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Accounts.ts    # Better Auth OAuth account entity
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VerificationTokens.ts # Better Auth verification tokens
‚îÇ   ‚îú‚îÄ‚îÄ lambdas/           # Lambda functions (each subdirectory = one Lambda)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [lambda-name]/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ src/index.ts         # Lambda handler
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ test/index.test.ts   # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ lib/vendor/        # 3rd party API wrappers & AWS SDK encapsulation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AWS/           # AWS SDK vendor wrappers (src/lib/vendor/AWS/)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BetterAuth/    # Better Auth configuration & ElectroDB adapter
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ElectroDB/     # ElectroDB configuration & service
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ YouTube.ts     # YouTube/yt-dlp wrapper
‚îÇ   ‚îî‚îÄ‚îÄ mcp/               # Model Context Protocol server & validation
‚îÇ       ‚îú‚îÄ‚îÄ server.ts      # MCP server entry point
‚îÇ       ‚îú‚îÄ‚îÄ handlers/      # Query tools (entities, lambda, infrastructure, etc.)
‚îÇ       ‚îî‚îÄ‚îÄ validation/    # AST-based convention enforcement (13 rules)
‚îú‚îÄ‚îÄ test/helpers/          # Test utilities
‚îÇ   ‚îî‚îÄ‚îÄ electrodb-mock.ts  # ElectroDB mock helper for unit tests
‚îú‚îÄ‚îÄ types/                 # TypeScript type definitions
‚îú‚îÄ‚îÄ util/                  # Shared utility functions
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ wiki/              # All documentation and style guides
‚îÇ   ‚îî‚îÄ‚îÄ conventions-tracking.md  # Project-specific conventions
‚îî‚îÄ‚îÄ build/graph.json       # Code graph (ts-morph) - READ THIS
```

## System Architecture

### Lambda Data Flow

```mermaid
graph TD
    %% External Triggers
    API[API Gateway] --> Authorizer[ApiGatewayAuthorizer]
    Authorizer --> ListFiles[ListFiles Lambda]
    Authorizer --> LoginUser[LoginUser Lambda]
    Authorizer --> RegisterDevice[RegisterDevice Lambda]
    Authorizer --> RegisterUser[RegisterUser Lambda]
    Authorizer --> RefreshToken[RefreshToken Lambda]
    Authorizer --> UserDelete[UserDelete Lambda]
    Authorizer --> UserSubscribe[UserSubscribe Lambda]

    Feedly[Feedly Webhook] --> WebhookFeedly[WebhookFeedly Lambda]

    %% Scheduled Tasks
    Schedule[CloudWatch Schedule] --> FileCoordinator[FileCoordinator Lambda]
    Schedule --> PruneDevices[PruneDevices Lambda]

    %% Lambda Invocations
    FileCoordinator --> StartFileUpload[StartFileUpload Lambda]

    %% S3 Triggers
    S3Upload[S3 Upload Event] --> S3ObjectCreated[S3ObjectCreated Lambda]
    S3ObjectCreated --> SQS[SQS Queue]
    SQS --> SendPushNotification[SendPushNotification Lambda]

    %% Data Stores
    ListFiles --> DDB[(DynamoDB)]
    LoginUser --> DDB
    RegisterDevice --> DDB
    RegisterUser --> DDB
    WebhookFeedly --> DDB
    FileCoordinator --> DDB
    UserDelete --> DDB
    PruneDevices --> DDB
    S3ObjectCreated --> DDB

    StartFileUpload --> S3Storage[(S3 Storage)]
    WebhookFeedly --> S3Storage

    SendPushNotification --> APNS[Apple Push Service]
```

### Entity Relationship Model

```mermaid
erDiagram
    USERS ||--o{ USER_FILES : has
    USERS ||--o{ USER_DEVICES : owns
    USERS ||--o{ SESSIONS : has
    USERS ||--o{ ACCOUNTS : has
    FILES ||--o{ USER_FILES : shared_with
    FILES ||--o{ FILE_DOWNLOADS : tracks
    DEVICES ||--o{ USER_DEVICES : registered_to

    USERS {
        string userId PK
        string email
        string status
        timestamp createdAt
    }

    FILES {
        string fileId PK
        string fileName
        string url
        string status
        number size
        timestamp createdAt
    }

    FILE_DOWNLOADS {
        string downloadId PK
        string fileId FK
        string status
        timestamp startedAt
        timestamp completedAt
    }

    DEVICES {
        string deviceId PK
        string deviceToken
        string platform
        timestamp lastActive
    }

    SESSIONS {
        string sessionId PK
        string userId FK
        string token
        timestamp expiresAt
    }

    ACCOUNTS {
        string accountId PK
        string userId FK
        string provider
        string providerAccountId
    }

    VERIFICATION_TOKENS {
        string token PK
        string identifier
        timestamp expiresAt
    }

    USER_FILES {
        string userId FK
        string fileId FK
        timestamp createdAt
    }

    USER_DEVICES {
        string userId FK
        string deviceId FK
        timestamp createdAt
    }
```

### Service Interaction Map

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        API Gateway                          ‚îÇ
‚îÇ                    (Custom Authorizer)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                                    ‚îÇ
             ‚ñº                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Lambda Functions  ‚îÇ              ‚îÇ   External Services ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§              ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ ListFiles         ‚îÇ              ‚îÇ ‚Ä¢ Feedly API        ‚îÇ
‚îÇ ‚Ä¢ LoginUser         ‚îÇ              ‚îÇ ‚Ä¢ YouTube (yt-dlp)  ‚îÇ
‚îÇ ‚Ä¢ RegisterDevice    ‚îÇ              ‚îÇ ‚Ä¢ APNS              ‚îÇ
‚îÇ ‚Ä¢ StartFileUpload   ‚îÇ              ‚îÇ ‚Ä¢ Sign In w/ Apple  ‚îÇ
‚îÇ ‚Ä¢ WebhookFeedly     ‚îÇ              ‚îÇ ‚Ä¢ GitHub API        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     AWS Services Layer                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    DynamoDB         ‚îÇ      S3       ‚îÇ    CloudWatch        ‚îÇ
‚îÇ  (ElectroDB ORM)    ‚îÇ  (Media Files)‚îÇ   (Logs/Metrics)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Dependency Analysis with graph.json

The `build/graph.json` file contains comprehensive dependency information. Key queries:

```bash
# Get all transitive dependencies for a Lambda function
cat build/graph.json | jq '.transitiveDependencies["src/lambdas/ListFiles/src/index.ts"]'

# Find all files that import a specific module
cat build/graph.json | jq '.files | to_entries[] | select(.value.imports[]? | contains("entities/Files")) | .key'

# List all Lambda entry points
cat build/graph.json | jq '.files | keys[] | select(contains("src/lambdas") and contains("/src/index.ts"))'

# Get import count for complexity analysis
cat build/graph.json | jq '.files | to_entries | map({file: .key, importCount: (.value.imports | length)}) | sort_by(.importCount) | reverse[:10]'
```

### Keeping MCP & GraphRAG in Sync

The MCP server (`src/mcp/`) and GraphRAG (`graphrag/`) use shared data sources for accuracy:

| Data Source | Purpose | Auto-Updated |
|-------------|---------|--------------|
| `src/lambdas/` | Lambda discovery | ‚úì Filesystem scan |
| `src/entities/` | Entity discovery | ‚úì Filesystem scan |
| `build/graph.json` | Dependencies | ‚úì Generated before build |
| `graphrag/metadata.json` | Semantic info | ‚úó Manual updates required |

**When adding/removing Lambdas or Entities:**
1. The MCP handlers and GraphRAG auto-discover from filesystem
2. Update `graphrag/metadata.json` with trigger types and purposes
3. Run `pnpm run graphrag:extract` to regenerate the knowledge graph
4. CI will fail if `knowledge-graph.json` is out of date

**When changing Lambda invocation chains:**
1. Update `graphrag/metadata.json` `lambdaInvocations` array
2. Run `pnpm run graphrag:extract`

### Lambda Trigger Patterns

| Lambda | Trigger Type | Source | Purpose |
|--------|-------------|--------|---------|
| ApiGatewayAuthorizer | API Gateway | All authenticated routes | Authorize API requests via Better Auth |
| CloudfrontMiddleware | CloudFront | Edge requests | Edge processing for CDN |
| FileCoordinator | CloudWatch Events | Scheduled | Orchestrate pending file downloads |
| ListFiles | API Gateway | GET /files | List user's available files |
| LogClientEvent | API Gateway | POST /events | Log client-side events |
| LoginUser | API Gateway | POST /auth/login | Authenticate user |
| PruneDevices | CloudWatch Events | Daily schedule | Clean inactive devices |
| RefreshToken | API Gateway | POST /auth/refresh | Refresh authentication token |
| RegisterDevice | API Gateway | POST /devices | Register iOS device for push |
| RegisterUser | API Gateway | POST /auth/register | Register new user |
| S3ObjectCreated | S3 Event | s3:ObjectCreated | Handle uploaded files, notify users |
| SendPushNotification | SQS | S3ObjectCreated | Send APNS notifications |
| StartFileUpload | Lambda Invoke | FileCoordinator | Initiate file download from YouTube |
| UserDelete | API Gateway | DELETE /users | Delete user and cascade |
| UserSubscribe | API Gateway | POST /subscriptions | Manage user topic subscriptions |
| WebhookFeedly | API Gateway | POST /webhooks/feedly | Process Feedly articles |

### Data Access Patterns

| Pattern | Entity | Access Method | Index Used |
|---------|--------|--------------|------------|
| User's files | UserFiles ‚Üí Files | Query by userId | GSI1 |
| User's devices | UserDevices ‚Üí Devices | Query by userId | GSI1 |
| File's users | UserFiles | Query by fileId | GSI2 |
| Device lookup | Devices | Get by deviceId | Primary |
| User resources | Collections.userResources | Batch query | GSI1 |

## Critical Project-Specific Rules

1. **Use build/graph.json for dependency analysis**:
   - Auto-generated before every build
   - Shows file-level imports and transitive dependencies
   - **CRITICAL for Jest tests**: Use `transitiveDependencies` to find all mocks needed
   - Example: `cat build/graph.json | jq '.transitiveDependencies["src/lambdas/WebhookFeedly/src/index.ts"]'`
2. **pnpm lifecycle script protection** (security hardening):
   - All lifecycle scripts disabled by default in `.npmrc`
   - Protects against AI-targeted typosquatting and supply chain attacks
   - Scripts blocked during installation - must explicitly allowlist packages
   - If package requires install scripts, audit code first then add to `.npmrc`
3. **Feedly webhook** uses query-based authentication (custom authorizer)
4. **APNS certificates** required for iOS push notifications (p12 format)
5. **YouTube downloads** require cookie authentication due to bot detection
6. **LocalStack integration** for local AWS testing via vendor wrappers
7. **Webpack externals** must be updated when adding AWS SDK packages

## ElectroDB Architecture

**CRITICAL**: This project uses ElectroDB as the DynamoDB ORM for type-safe, maintainable database operations.

### Key ElectroDB Features
- **Single-table design**: All entities in one DynamoDB table with optimized GSIs
- **Type-safe queries**: Full TypeScript type inference for all operations
- **Collections**: JOIN-like queries across entity boundaries (see `src/entities/Collections.ts`)
- **Batch operations**: Efficient bulk reads/writes with automatic chunking

### Entity Relationships
- **Users** ‚Üî **Files**: Many-to-many via UserFiles entity
- **Users** ‚Üî **Devices**: Many-to-many via UserDevices entity
- **Users** ‚Üî **Sessions**: One-to-many (Better Auth sessions)
- **Users** ‚Üî **Accounts**: One-to-many (Better Auth OAuth accounts)
- **Files** ‚Üî **FileDownloads**: One-to-many (download tracking)

### Collections (JOIN-like Queries)
- **Collections.userResources**: Query all files & devices for a user in one call
- **Collections.fileUsers**: Get all users associated with a file (for notifications)
- **Collections.deviceUsers**: Get all users associated with a device (for cleanup)
- **Collections.userSessions**: Get all sessions for a user (Better Auth)
- **Collections.userAccounts**: Get all OAuth accounts for a user (Better Auth)

### Testing with ElectroDB
- **ALWAYS** use `test/helpers/electrodb-mock.ts` for mocking entities
- **NEVER** create manual mocks for ElectroDB entities
- See test style guide for detailed mocking patterns

## Wiki Conventions to Follow

**BEFORE WRITING ANY CODE, READ THE APPLICABLE GUIDE:**

### Core Conventions
- **Git Workflow**: [docs/wiki/Conventions/Git-Workflow.md](docs/wiki/Conventions/Git-Workflow.md) - NO AI attribution in commits
- **Naming**: [docs/wiki/Conventions/Naming-Conventions.md](docs/wiki/Conventions/Naming-Conventions.md) - camelCase, PascalCase rules
- **Comments**: [docs/wiki/Conventions/Code-Comments.md](docs/wiki/Conventions/Code-Comments.md) - Git as source of truth

### TypeScript & Testing
- **Lambda Patterns**: [docs/wiki/TypeScript/Lambda-Function-Patterns.md](docs/wiki/TypeScript/Lambda-Function-Patterns.md)
- **Jest Mocking**: [docs/wiki/Testing/Jest-ESM-Mocking-Strategy.md](docs/wiki/Testing/Jest-ESM-Mocking-Strategy.md)
- **Mock Types**: [docs/wiki/Testing/Mock-Type-Annotations.md](docs/wiki/Testing/Mock-Type-Annotations.md)
- **Coverage Philosophy**: [docs/wiki/Testing/Coverage-Philosophy.md](docs/wiki/Testing/Coverage-Philosophy.md)
- **Integration Testing**: [docs/wiki/Integration/LocalStack-Testing.md](docs/wiki/Integration/LocalStack-Testing.md)

### AWS & Infrastructure
- **SDK Encapsulation**: [docs/wiki/AWS/SDK-Encapsulation-Policy.md](docs/wiki/AWS/SDK-Encapsulation-Policy.md) - ZERO tolerance
- **Bash Scripts**: [docs/wiki/Bash/Script-Patterns.md](docs/wiki/Bash/Script-Patterns.md)
- **OpenTofu/Terraform**: [docs/wiki/Infrastructure/OpenTofu-Patterns.md](docs/wiki/Infrastructure/OpenTofu-Patterns.md)

## Anti-Patterns to Avoid

The following patterns have caused issues in this project and should be avoided:

### 1. Direct AWS SDK Imports (CRITICAL)
**Wrong**: `import {DynamoDBClient} from '@aws-sdk/client-dynamodb'`
**Right**: `import {getDynamoDBClient} from '#lib/vendor/AWS/DynamoDB'`
**Why**: Breaks encapsulation, makes testing difficult, loses type safety benefits

### 2. Manual ElectroDB Entity Mocks (CRITICAL)
**Wrong**: Hand-crafted mock objects for entities in tests
**Right**: `const mock = createElectroDBEntityMock({queryIndexes: ['byUser']})`
**Why**: Inconsistent mocking leads to false positives and maintenance burden

### 3. Promise.all for Cascade Deletions (CRITICAL)
**Wrong**: `await Promise.all([deleteUser(), deleteUserFiles()])`
**Right**: `await Promise.allSettled([deleteUserFiles(), deleteUser()])`
**Why**: Partial failures leave orphaned data; children must be deleted before parents

### 4. Try-Catch for Required Environment Variables (CRITICAL)
**Wrong**: `try { config = JSON.parse(process.env.Config) } catch { return fallback }`
**Right**: `const config = getRequiredEnv('Config')` - let it fail fast
**Why**: Silent failures hide configuration errors that should break at cold start

### 5. Underscore-Prefixed Unused Variables (HIGH)
**Wrong**: `handler(event, _context, _callback)` to suppress warnings
**Right**: `handler({body}: APIGatewayProxyEvent)` - destructure only what you need
**Why**: Backwards-compatibility hacks obscure intent and violate project conventions

### 6. AI Attribution in Commits (CRITICAL)
**Wrong**: Commit messages with "Generated with Claude", emojis, "Co-Authored-By: AI"
**Right**: Clean commit messages following commitlint format: `feat: add new feature`
**Why**: Professional commits, code ownership clarity, industry standard

### 7. Module-Level Environment Variable Validation (HIGH)
**Wrong**: `const config = getRequiredEnv('Config')` at top of module
**Right**: Call `getRequiredEnv()` inside functions (lazy evaluation)
**Why**: Module-level calls break tests that need to set up mocks before import

### 8. Raw Response Objects in Lambdas (HIGH)
**Wrong**: `return {statusCode: 200, body: JSON.stringify(data)}`
**Right**: `return response(200, data)`
**Why**: Inconsistent formatting, missing headers, no type safety

## Type Naming Patterns

| Pattern | Usage | Examples |
|---------|-------|----------|
| Simple nouns | Domain entities | `User`, `File`, `Device`, `Session` |
| `*Item` | ElectroDB parsed types | `UserItem`, `FileItem`, `DeviceItem` |
| `*Input` | Request payloads & mutations | `UserLoginInput`, `CreateFileInput` |
| `*Response` | API response wrappers | `FileResponse`, `LoginResponse` |
| `*Error` | Error classes | `AuthorizationError`, `ValidationError` |

### File Organization (`src/types/`)

| File | Contents |
|------|----------|
| `domain-models.d.ts` | User, File, Device, IdentityProvider |
| `request-types.d.ts` | *Input types for API requests |
| `notification-types.d.ts` | Push notification payloads |
| `persistence-types.d.ts` | Relationship types (UserDevice, UserFile) |
| `infrastructure-types.d.ts` | AWS/API Gateway types |
| `enums.ts` | FileStatus, UserStatus, ResponseStatus |

### Enum Values (PascalCase)

```typescript
// FileStatus values (aligned with iOS)
Queued | Downloading | Downloaded | Failed
```

## Development Workflow

### Essential Commands
```bash
pnpm run precheck       # TypeScript type checking and lint (run before commits)
pnpm run build          # Build Lambda functions with esbuild
pnpm run test           # Run unit tests
pnpm run deploy         # Deploy infrastructure with OpenTofu
pnpm run format         # Auto-format with dprint (157 char lines)

# Local CI (run before pushing)
pnpm run ci:local                # Fast CI checks (~2-3 min, no integration)
pnpm run ci:local:full           # Full CI checks (~5-10 min, with integration)

# Integration testing
pnpm run localstack:start        # Start LocalStack
pnpm run test:integration        # Run integration tests (assumes LocalStack running)

# Remote testing
pnpm run test-remote-list        # Test file listing
pnpm run test-remote-hook        # Test Feedly webhook
pnpm run test-remote-registerDevice  # Test device registration

# Documentation
pnpm run document-source         # Generate TSDoc documentation
```

### Pre-Commit Checklist
1. Run `pnpm run precheck` - TypeScript type checking and lint
2. Run `pnpm run format` - Auto-format code
3. Run `pnpm run build` - Compile with esbuild
4. Run `pnpm test` - Ensure all tests pass
5. Verify NO AI references in commit message
6. Stage changes: `git add -A`
7. Commit with clean message: `git commit -m "type: description"`
8. **NEVER push automatically** - Wait for user request

## Integration Points

### External Services
- **Feedly**: Webhook-based article processing (query auth)
- **YouTube**: yt-dlp for video downloads (cookie auth required)
- **APNS**: iOS push notifications (requires certificates)
- **Sign In With Apple**: Authentication for iOS app
- **GitHub API**: Automated issue creation for errors

### AWS Services
- **Lambda**: Event-driven compute (all business logic)
- **S3**: Media storage with transfer acceleration
- **DynamoDB**: Single-table design via ElectroDB ORM for all entities
- **API Gateway**: REST endpoints with custom authorizer
- **SNS**: Push notification delivery
- **CloudWatch**: Logging and metrics
- **X-Ray**: Distributed tracing (optional)

## Common Development Tasks

### Adding New Lambda Function
1. Create `src/lambdas/[name]/` directory structure
2. Implement handler in `src/index.ts` with TypeDoc
3. Write tests in `test/index.test.ts` with fixtures
4. Mock ALL transitive dependencies (see Wiki)
5. Define Lambda resource in OpenTofu
6. Verify esbuild discovers new Lambda entry point
7. Configure appropriate IAM permissions
8. Import utilities from `util/` directory

### Debugging Production Issues
1. Check CloudWatch logs for Lambda
2. Review automated GitHub issues
3. Use AWS X-Ray for tracing (if enabled)
4. Test with production-like data locally
5. Use `test-remote-*` scripts for validation

### Updating API Endpoints
1. Modify API Gateway configuration in OpenTofu
2. Update Lambda handler code
3. Adjust custom authorizer if needed
4. Test with `test-remote-*` scripts
5. Update iOS app if contract changes

## Security & Secrets

- **SOPS**: All secrets managed via SOPS (`secrets.encrypted.yaml`)
- **Environment Variables**: Production secrets via Lambda environment
- **APNS Certificates**: P12 format, separate sandbox/production
- **API Tokens**: Query-based for Feedly compatibility
- **Never commit**: secrets.yaml, certificates, .env files

## Performance Considerations

- Lambda memory allocation: Optimize for cold starts
- S3 transfer acceleration: For large media files
- API Gateway caching: Reduce Lambda invocations
- DynamoDB indexes: Query optimization
- Webpack externals: Reduce bundle size

## Support Resources

- **CI/CD**: GitHub Actions with test pipeline
- **Local Testing**: LocalStack for AWS service emulation
- **Documentation**: TSDoc + terraform-docs
- **Error Tracking**: Automated GitHub issue creation
- **Monitoring**: CloudWatch dashboards and alarms

---

**Remember**: Use TodoWrite tool for complex tasks to track progress and ensure thoroughness.# LocalStack Testing

## Quick Reference
- **When to use**: Local AWS service testing
- **Enforcement**: Recommended for integration tests
- **Impact if violated**: LOW - Tests run against real AWS

## Setup

```bash
# Start LocalStack
npm run localstack:start

# Run integration tests
npm run test:integration

# Full test suite with lifecycle
npm run test:integration:full
```

## Configuration

### Docker Compose

```yaml
# docker-compose.yml
services:
  localstack:
    image: localstack/localstack:latest
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3,dynamodb,lambda,sns,sqs,apigateway
      - AWS_DEFAULT_REGION=us-west-2
```

### Test Environment

```typescript
// test/helpers/localstack-config.ts
export const localstackConfig = {
  endpoint: 'http://localhost:4566',
  region: 'us-west-2',
  credentials: {
    accessKeyId: 'test',
    secretAccessKey: 'test'
  }
}
```

## Vendor Wrapper Pattern

All AWS SDK clients use vendor wrappers that automatically detect LocalStack:

```typescript
// lib/vendor/AWS/DynamoDB.ts
function getDynamoDbClient(): DynamoDBClient {
  if (process.env.USE_LOCALSTACK === 'true') {
    return new DynamoDBClient({
      endpoint: 'http://localhost:4566',
      region: 'us-west-2'
    })
  }
  return new DynamoDBClient()
}
```

## Integration Test Pattern

```typescript
// test/integration/lambda.test.ts
import {beforeAll, afterAll, test} from '@jest/globals'
import {setupLocalStack, teardownLocalStack} from '../helpers/localstack'

beforeAll(async () => {
  await setupLocalStack()
})

afterAll(async () => {
  await teardownLocalStack()
})

test('Lambda processes file', async () => {
  // Test against LocalStack services
  const result = await lambda.invoke({
    FunctionName: 'ProcessFile',
    Payload: JSON.stringify({fileId: 'test'})
  })

  expect(result.StatusCode).toBe(200)
})
```

## Service-Specific Setup

### DynamoDB
```bash
aws --endpoint-url=http://localhost:4566 dynamodb create-table \
  --table-name MediaDownloader \
  --attribute-definitions AttributeName=PK,AttributeType=S
```

### S3
```bash
aws --endpoint-url=http://localhost:4566 s3 mb s3://media-files
```

### Lambda
```bash
aws --endpoint-url=http://localhost:4566 lambda create-function \
  --function-name ProcessFile \
  --runtime nodejs22.x
```

## ElectroDB Integration Testing

### Setup Helper

```typescript
import {setupLocalStackTable, cleanupLocalStackTable} from '../helpers/electrodb-localstack'

beforeAll(async () => {
  await setupLocalStackTable()
})

afterAll(async () => {
  await cleanupLocalStackTable()
})
```

**Creates**: MediaDownloader table with all GSIs (gsi1/userResources, gsi2/fileUsers, gsi3/deviceUsers)

### Testing Collections

```typescript
import {collections} from '../../../src/entities/Collections'

test('userResources collection', async () => {
  // Create test data
  await Users.create({userId: 'user-1', appleDeviceIdentifier: 'apple-1'}).go()
  await Files.create({fileId: 'file-1', status: 'Downloaded', url: 'https://...'}).go()
  await UserFiles.create({userId: 'user-1', fileId: 'file-1'}).go()

  // Query collection (JOIN-like operation)
  const result = await collections.userResources({userId: 'user-1'}).go()

  // Validate single-table design
  expect(result.data.Users).toHaveLength(1)
  expect(result.data.Files).toHaveLength(1)
  expect(result.data.UserFiles).toHaveLength(1)
})
```

**See**: [ElectroDB Testing Patterns](../Testing/ElectroDB-Testing-Patterns.md) for comprehensive examples

## Common Issues

| Issue | Solution |
|-------|----------|
| Connection refused | Ensure LocalStack is running |
| Service not available | Check SERVICES env var |
| Credentials error | Use 'test' for both key and secret |
| Region mismatch | Use us-west-2 consistently |

## Best Practices

1. **Use vendor wrappers** - Automatic LocalStack detection
2. **Set UseLocalstack=true** - Enable LocalStack mode
3. **Clean state between tests** - Reset services in afterEach
4. **Mock external services** - Don't call real APIs from LocalStack

## Related Patterns

- [Vendor Wrappers](../AWS/SDK-Encapsulation-Policy.md) - AWS SDK encapsulation
- [Integration Testing](../Testing/Integration-Testing.md) - Test strategies
- [Jest ESM Mocking](../Testing/Jest-ESM-Mocking-Strategy.md) - Mocking patterns

---

*Use LocalStack for local AWS testing. Vendor wrappers automatically detect LocalStack mode.*# Module Best Practices

## Quick Reference
- **When to use**: Structuring TypeScript modules
- **Enforcement**: Required
- **Impact if violated**: MEDIUM - Circular dependencies

## Module Rules

1. **One primary export per file**
2. **Use named exports** (not default)
3. **Barrel files for public APIs**
4. **Avoid circular dependencies**

## Export Patterns

### ‚úÖ Named Exports (Preferred)
```typescript
// util/transformers.ts
export function toCamelCase(obj: Record<string, any>) {}
export function toSnakeCase(obj: Record<string, any>) {}

// Usage
import {toCamelCase, toSnakeCase} from './transformers'
```

### ‚ùå Default Exports (Avoid)
```typescript
// Harder to refactor
export default class Processor {}
```

## Barrel Files

```typescript
// entities/index.ts
export {Files} from './Files'
export {Users} from './Users'
export {collections} from './Collections'

// Usage
import {Files, Users, collections} from '../entities'
```

## Vendor Wrapper Pattern

```typescript
// lib/vendor/AWS/S3.ts
import {S3Client} from '@aws-sdk/client-s3'

let client: S3Client | null = null

function getS3Client(): S3Client {
  if (!client) {
    client = new S3Client()
  }
  return client
}

// Export only functions, not SDK
export function uploadToS3(bucket: string, key: string) {
  const client = getS3Client()
  // Use client
}
```

## Lazy Initialization

```typescript
let expensive: Resource | null = null

export function getResource(): Resource {
  if (!expensive) {
    expensive = createExpensive()
  }
  return expensive
}
```

## Type-Only Imports

```typescript
// Prefer type imports when possible
import type {FileData} from '../types/main'
import {processFile} from '../processors'
```

## Best Practices

‚úÖ Named exports only
‚úÖ One concern per module
‚úÖ Vendor wrappers for external libs
‚úÖ Lazy init expensive resources
‚úÖ Type-only imports when possible
‚úÖ Clear module boundaries

## Related Patterns

- [Import Organization](../Conventions/Import-Organization.md)
- [Type Definitions](Type-Definitions.md)
- [Lambda Function Patterns](Lambda-Function-Patterns.md)

---

*Use named exports and maintain clear module boundaries.*# Type Definitions

## Quick Reference
- **When to use**: Defining TypeScript types and interfaces
- **Enforcement**: Required - MCP `types-location` rule validates on push
- **Impact if violated**: HIGH - Type sprawl, duplication, poor IDE experience

## Exported Type Location (HIGH Priority)

**Rule**: All exported type definitions (type aliases, interfaces, enums) must be in the `src/types/` directory.

**Why**: Separation of concerns, discoverability, and maintainability. Types scattered across implementation files are hard to find and lead to duplication.

**Enforcement**: MCP `types-location` rule (HIGH severity) detects violations in CI.

### Allowed Exceptions

| Location | Reason |
|----------|--------|
| `src/types/**/*.ts` | Canonical location for types |
| `src/entities/**/*.ts` | Entity-derived types from ElectroDB |
| `src/mcp/**/*.ts` | Self-contained MCP module |
| `**/*.test.ts`, `test/**/*.ts` | Test-only types |
| `src/lib/vendor/**/*.ts` | Internal vendor wrapper types |

### Type File Organization

```
src/types/
‚îú‚îÄ‚îÄ domain-models.ts     # Core domain types (User, Device, etc.)
‚îú‚îÄ‚îÄ persistence-types.ts # Relationship types (UserDevice, UserFile)
‚îú‚îÄ‚îÄ enums.ts             # Shared enumerations
‚îú‚îÄ‚îÄ lambda-wrappers.ts   # Lambda handler wrapper types
‚îú‚îÄ‚îÄ video.ts             # Video processing types
‚îú‚îÄ‚îÄ util.ts              # Utility function types
‚îú‚îÄ‚îÄ youtube.ts           # YouTube/yt-dlp types
‚îî‚îÄ‚îÄ vendor/              # Third-party integration types
    ‚îî‚îÄ‚îÄ IFTTT/
```

### Examples

```typescript
// ‚úÖ CORRECT - Export from src/types/
// src/types/lambda-wrappers.ts
export type WrapperMetadata = {traceId: string}
export type ApiHandlerParams<TEvent> = {event: TEvent; context: Context; metadata: WrapperMetadata}

// ‚úÖ CORRECT - Import from types directory
// src/lambdas/ListFiles/src/index.ts
import type {ApiHandlerParams} from '#types/lambda-wrappers'

// ‚ùå WRONG - Exporting type from implementation file
// src/util/helpers.ts
export type HelperConfig = {maxRetries: number}  // Should be in src/types/util.ts
```

## The Rules

1. **Exported Types in `types/` Directory** - All exported types must be in `src/types/`
2. **Inline Types for Single-Use Cases** - Define internal (non-exported) types inline
3. **Entity Types with Entities** - ElectroDB entity types stay with entity definitions
4. **Use `import type` Syntax** - Better tree-shaking and clearer intent

## Examples

### ‚úÖ Correct - Inline Types

```typescript
// src/lambdas/ProcessVideo/src/index.ts

// Small, single-use type - defined inline
interface VideoMetadata {
  title: string
  duration: number
  format: string
}

export const handler = async (event: any) => {
  const metadata: VideoMetadata = extractMetadata(event)
  // Use metadata
}
```

### ‚úÖ Correct - Shared Types in types/

```typescript
// types/api.ts - Shared API types
export interface ApiGatewayEvent {
  body: string
  headers: Record<string, string>
  pathParameters: Record<string, string>
}

export interface ApiGatewayResponse {
  statusCode: number
  headers?: Record<string, string>
  body: string
}

// Used across multiple Lambda functions
```

### ‚ùå Incorrect - Type Sprawl

```typescript
// ‚ùå WRONG - Separate file for one type used once
// types/VideoMetadata.ts
export interface VideoMetadata {
  title: string
  duration: number
}

// Only used in one place - should be inline
```

### ‚ùå Incorrect - Duplicated Types

```typescript
// ‚ùå WRONG - Same type defined in multiple files
// src/lambdas/ListFiles/src/index.ts
interface ApiResponse {
  statusCode: number
  body: string
}

// src/lambdas/GetFile/src/index.ts
interface ApiResponse {  // Duplicate!
  statusCode: number
  body: string
}

// Should be shared in types/api.ts
```

## Type Organization Structure

```
types/
‚îú‚îÄ‚îÄ api.ts              # API Gateway types
‚îú‚îÄ‚îÄ domain.ts           # Domain models (User, File, Device)
‚îú‚îÄ‚îÄ events.ts           # AWS event types (SNS, SQS)
‚îú‚îÄ‚îÄ errors.ts           # Error types
‚îî‚îÄ‚îÄ validation.ts       # Validation constraint types

src/
‚îú‚îÄ‚îÄ entities/
‚îÇ   ‚îú‚îÄ‚îÄ Files.ts        # File entity with types
‚îÇ   ‚îú‚îÄ‚îÄ Users.ts        # User entity with types
‚îÇ   ‚îî‚îÄ‚îÄ Devices.ts      # Device entity with types
‚îú‚îÄ‚îÄ lambdas/
‚îÇ   ‚îî‚îÄ‚îÄ [Function]/
‚îÇ       ‚îî‚îÄ‚îÄ src/
‚îÇ           ‚îî‚îÄ‚îÄ index.ts  # Inline types for single-use
```

## When to Create Shared Types

Create types in `types/` directory when:

1. **Used in 3+ files** - Clear reuse pattern
2. **Cross-cutting concern** - API contracts, domain models
3. **External contract** - Types exposed to consumers
4. **Complex type** - Large types that clutter implementation files

Keep types inline when:

1. **Single use** - Only needed in one file
2. **Small** - 3-4 properties or less
3. **Implementation detail** - Not part of public API
4. **Tightly coupled** - Specific to one function's logic

## Type Naming Conventions

```typescript
// Interfaces use PascalCase
interface UserProfile {
  userId: string
  email: string
}

// Type aliases use PascalCase
type FileStatus = 'Queued' | 'Downloading' | 'Downloaded' | 'Failed'

// Generic type parameters use single uppercase letter
function map<T, R>(items: T[], fn: (item: T) => R): R[] {
  return items.map(fn)
}

// Avoid prefixing with 'I' or 'T'
// ‚ùå WRONG
interface IUser {}
type TFileStatus = string

// ‚úÖ CORRECT
interface User {}
type FileStatus = string
```

## Type Imports

```typescript
// Use 'type' keyword for type-only imports (better tree-shaking)
import type {ApiGatewayEvent} from '../../../types/api'
import type {User} from '../../../types/domain'

// Regular import for values (functions, classes, enums)
import {validateInput} from '../../../util/constraints'
```

## Lambda-Specific Types

Lambda functions may have types used only within that lambda. The rule for organizing these types follows a threshold-based approach.

### When to Create a types/ Directory

Create a `src/lambdas/[name]/types/` directory when ANY of these apply:

1. **3+ types** specific to that lambda
2. **Re-exported types** - Types exported from the handler for external consumers
3. **Complex types** - Types with 5+ properties or nested structures count as 2

### When to Use Inline Types

Define types inline in the handler when ALL of these apply:

1. **1-2 simple types** only
2. **Not re-exported** - Types are internal to the lambda
3. **Small types** - 4 or fewer properties, no nested structures

### Examples

```typescript
// ‚úÖ Keep types/ directory (3+ types)
// CloudfrontMiddleware has 3 CloudFront-related types
src/lambdas/CloudfrontMiddleware/types/index.ts

// ‚úÖ Keep types/ directory (re-exported)
// PruneDevices re-exports PruneDevicesResult for callers
src/lambdas/PruneDevices/types/index.ts
export type {PruneDevicesResult} from '../types'  // in handler

// ‚úÖ Inline types (1 simple type, not re-exported)
// FileCoordinator's DownloadInfo is only used internally
interface DownloadInfo {
  fileId: string
  correlationId?: string
}
```

### Current Lambda Type Organization

| Lambda | Types | Location | Reason |
|--------|-------|----------|--------|
| CloudfrontMiddleware | 3 | `types/` | 3+ types threshold |
| PruneDevices | 2 | `types/` | Re-exported for callers |
| FileCoordinator | 1 | Inline | Single simple type |
| LoginUser | 1 | Inline | Single simple type |
| RegisterDevice | 1 | Inline | Single simple type |
| RegisterUser | 1 | Inline | Single simple type |
| StartFileUpload | 1 | Inline | Single simple type |
| UserSubscribe | 1 | Inline | Single simple type |

## Enforcement

### Code Review Checklist

- [ ] Shared types in `types/` directory
- [ ] Single-use types defined inline
- [ ] No type-only files for trivial types
- [ ] Entity types stay with entity definitions
- [ ] No AWS SDK types in public APIs
- [ ] Type imports use `import type` keyword
- [ ] Type names follow PascalCase convention
- [ ] Lambda types follow 3+ threshold or re-export rule

## Related Patterns

- [Naming Conventions](../Conventions/Naming-Conventions.md) - PascalCase for types
- [Import Organization](../Conventions/Import-Organization.md) - Type import order

---

*Organize types based on usage. Inline for single-use, shared directory for cross-cutting types. Keep entity types with entities.*
# Lambda Function Patterns

## Quick Reference
- **When to use**: Writing AWS Lambda functions
- **Enforcement**: Required
- **Impact if violated**: MEDIUM - Inconsistent structure

## Import Order (STRICT)

```typescript
// 1. AWS Lambda types
import {APIGatewayProxyResult, Context} from 'aws-lambda'

// 2. ElectroDB entities
import {Files} from '../../../entities/Files'

// 3. Vendor libraries
import {createS3Upload} from '../../../lib/vendor/AWS/S3'

// 4. Type imports
import type {File} from '../../../types/domain-models'

// 5. Utilities
import {logInfo, response} from '../../../util/lambda-helpers'

// ‚ùå NEVER import AWS SDK directly - use vendor wrappers
```

## Handler Pattern

Lambda handlers use wrapper functions that eliminate boilerplate and ensure consistency:

```typescript
// Helper functions first
async function processFile(fileId: string): Promise<void> {
  const file = await Files.get({fileId}).go()
  // Process...
}

// Handler with wrappers - business logic only, no try-catch needed
export const handler = withXRay(wrapApiHandler(async ({event, context}: ApiHandlerParams) => {
  await processFile(event.fileId)
  return response(context, 200, {success: true})
  // Errors automatically converted to 500 responses
}))
```

### Available Handler Wrappers

| Wrapper | Use Case | Error Handling |
|---------|----------|----------------|
| `wrapApiHandler` | Public API endpoints | Catches errors ‚Üí 500 response |
| `wrapAuthenticatedHandler` | Auth-required endpoints | Rejects Unauthenticated + Anonymous ‚Üí 401 |
| `wrapOptionalAuthHandler` | Mixed auth endpoints | Rejects only Unauthenticated ‚Üí 401 |
| `wrapAuthorizer` | API Gateway authorizers | Propagates `Error('Unauthorized')` ‚Üí 401 |
| `wrapEventHandler` | S3/SQS batch processing | Per-record error handling |
| `wrapScheduledHandler` | CloudWatch scheduled events | Logs and rethrows errors |

All wrappers provide:
- Automatic event logging via `logInfo`
- Fixture logging for test data extraction
- `WrapperMetadata` with traceId passed to handler

## Response Format (REQUIRED)

**Mandatory**: ALWAYS use the `response` and `lambdaErrorResponse` helper functions from `lambda-helpers.ts`. Never return raw API Gateway response objects.

```typescript
// ‚úÖ CORRECT - Use response helper
return response(context, 200, {
  data: result,
  requestId: context.awsRequestId
})

// ‚úÖ CORRECT - Use error response helper
return lambdaErrorResponse(context, error)

// ‚ùå WRONG - Never return raw objects
return {
  statusCode: 200,
  body: JSON.stringify(data),
  headers: {'Content-Type': 'application/json'}
}
```

**Why**: Ensures consistent response formatting, headers, and error handling across all Lambda functions.

## Common Patterns

## No Underscore-Prefixed Unused Variables (CRITICAL)

**Rule**: Never use underscore-prefixed variables (`_event`, `_context`, `_metadata`) to suppress unused variable warnings.

**Why**: Per AGENTS.md: "Avoid backwards-compatibility hacks like renaming unused `_vars`". This pattern hides poor API design and creates maintenance debt.

**Solution**: Use object destructuring to extract only the properties you need:

```typescript
// ‚ùå WRONG - Underscore-prefixed unused parameters
export const handler = wrapApiHandler(async (event, context, _metadata) => {
  // _metadata is unused but accepted to satisfy signature
})

// ‚úÖ CORRECT - Object destructuring extracts only what's needed
export const handler = wrapApiHandler(async ({event, context}: ApiHandlerParams) => {
  // Only event and context are destructured
})
```

**Enforcement**: MCP `config-enforcement` rule validates that ESLint config doesn't allow underscore-prefixed variables.

### Public API Gateway Handler
```typescript
import type {ApiHandlerParams} from '#types/lambda-wrappers'
import {wrapApiHandler, response} from '#util/lambda-helpers'
import {withXRay} from '#lib/vendor/AWS/XRay'

// Public endpoints - no authentication required
export const handler = withXRay(wrapApiHandler(async ({event, context}: ApiHandlerParams) => {
  // Business logic - just throw errors, wrapper handles conversion
  return response(context, 200, {data: result})
}))
```

### Authenticated API Gateway Handler (PREFERRED)
```typescript
import type {AuthenticatedApiParams} from '#types/lambda-wrappers'
import {wrapAuthenticatedHandler, response} from '#util/lambda-helpers'
import {withXRay} from '#lib/vendor/AWS/XRay'

// Authenticated endpoints - userId guaranteed by wrapper
// Rejects both Unauthenticated AND Anonymous users with 401
export const handler = withXRay(wrapAuthenticatedHandler(async ({context, userId}: AuthenticatedApiParams) => {
  // userId is guaranteed to be a string - no need to check
  await deleteUser(userId)
  return response(context, 204)
}))
```

### Optional Auth API Gateway Handler
```typescript
import type {OptionalAuthApiParams} from '#types/lambda-wrappers'
import {wrapOptionalAuthHandler, response} from '#util/lambda-helpers'
import {withXRay} from '#lib/vendor/AWS/XRay'
import {UserStatus} from '#types/enums'

// Optional auth endpoints - allows anonymous but rejects invalid tokens
// Rejects only Unauthenticated (invalid token) with 401
// Anonymous users (no token) are allowed
export const handler = withXRay(wrapOptionalAuthHandler(async ({context, userId, userStatus}: OptionalAuthApiParams) => {
  if (userStatus === UserStatus.Anonymous) {
    return response(context, 200, {demo: true})
  }
  // userId is defined when Authenticated
  return response(context, 200, {userId})
}))
```

### API Gateway Authorizer
```typescript
import type {AuthorizerParams} from '#types/lambda-wrappers'
import {wrapAuthorizer} from '#util/lambda-helpers'
import {withXRay} from '#lib/vendor/AWS/XRay'

export const handler = withXRay(wrapAuthorizer(async ({event}: AuthorizerParams) => {
  // Throw Error('Unauthorized') for 401 response
  if (!isValid) throw new Error('Unauthorized')
  return generateAllow(userId, event.methodArn)
}))
```

### S3 Event Handler
```typescript
import type {EventHandlerParams} from '#types/lambda-wrappers'
import {wrapEventHandler, s3Records} from '#util/lambda-helpers'
import {withXRay} from '#lib/vendor/AWS/XRay'

// Process individual records - errors don't stop other records
async function processS3Record({record}: EventHandlerParams<S3EventRecord>) {
  const key = record.s3.object.key
  await processFile(key)
}

export const handler = withXRay(wrapEventHandler(processS3Record, {getRecords: s3Records}))
```

### SQS Handler
```typescript
import type {EventHandlerParams} from '#types/lambda-wrappers'
import {wrapEventHandler, sqsRecords} from '#util/lambda-helpers'
import {withXRay} from '#lib/vendor/AWS/XRay'

// Process individual messages - errors logged but don't stop processing
async function processSQSRecord({record}: EventHandlerParams<SQSRecord>) {
  const body = JSON.parse(record.body)
  await handleMessage(body)
}

export const handler = withXRay(wrapEventHandler(processSQSRecord, {getRecords: sqsRecords}))
```

### Scheduled Event Handler
```typescript
import type {ScheduledHandlerParams} from '#types/lambda-wrappers'
import {wrapScheduledHandler} from '#util/lambda-helpers'
import {withXRay} from '#lib/vendor/AWS/XRay'

export const handler = withXRay(wrapScheduledHandler(async ({}: ScheduledHandlerParams) => {
  // Scheduled task logic - errors propagate to CloudWatch
  await pruneOldRecords()
  return {pruned: count}
}))

## Environment Variable Handling

### Lazy Evaluation (Default Pattern)
**Rule**: Environment variables should be read inside functions, not at module scope.

```typescript
// ‚úÖ CORRECT - Read inside function (lazy evaluation)
async function processFile() {
  const bucketName = getRequiredEnv('BUCKET_NAME')
  // ...
}

// ‚ùå WRONG - Module-level read (breaks test setup)
const BUCKET_NAME = getRequiredEnv('BUCKET_NAME')  // Throws before tests can mock
```

**Why**: Module-level reads execute at import time, before test mocks can be configured.

### Acceptable Exceptions

**AWS Powertools initialization** (`src/lib/vendor/Powertools/index.ts`) uses module-level env reads:

```typescript
// Acceptable - has fallback values, required for framework initialization
export const logger = new Logger({
  serviceName: process.env['AWS_LAMBDA_FUNCTION_NAME'] || 'MediaDownloader',
  logLevel: (process.env['LOG_LEVEL'] as LogLevel) || 'INFO'
})
```

This is acceptable because:
1. All reads have fallback values (won't throw if missing)
2. Powertools requires initialization at import time for tracing to work correctly
3. Refactoring would require updating all handler imports with minimal benefit

### Helper Functions

```typescript
import {getRequiredEnv, getOptionalEnv, getOptionalEnvNumber} from '#util/env-validation'

// Required - throws if missing
const apiKey = getRequiredEnv('API_KEY')

// Optional with default
const host = getOptionalEnv('APNS_HOST', 'api.sandbox.push.apple.com')

// Optional numeric with default
const batchSize = getOptionalEnvNumber('BATCH_SIZE', 5)
```

## Best Practices

‚úÖ Use `withXRay` wrapper for tracing
‚úÖ Use appropriate handler wrapper (`wrapApiHandler`, `wrapAuthorizer`, etc.)
‚úÖ Use vendor wrappers for AWS SDK (never import AWS SDK directly)
‚úÖ Return responses using `response()` helper
‚úÖ Throw errors instead of manual try-catch (wrapper handles it)
‚úÖ Keep handler at bottom of file
‚úÖ Define record processing functions separately for event handlers
‚úÖ Read environment variables inside functions, not at module scope

## Testing

```typescript
// Mock all dependencies first
jest.unstable_mockModule('../../../lib/vendor/AWS/S3', () => ({
  createS3Upload: jest.fn()
}))

// Import handler after mocks
const {handler} = await import('../src/index')

test('processes file', async () => {
  const result = await handler(mockEvent, mockContext)
  expect(result.statusCode).toBe(200)
})
```

## Related Patterns

- [X-Ray Integration](../AWS/X-Ray-Integration.md)
- [Error Handling](TypeScript-Error-Handling.md)
- [Jest ESM Mocking](../Testing/Jest-ESM-Mocking-Strategy.md)

---

*Consistent Lambda structure: imports ‚Üí helpers ‚Üí handler with X-Ray wrapper.*# Error Handling

## Quick Reference
- **When to use**: All Lambda functions and error-prone operations
- **Enforcement**: Required - consistent error handling across all functions
- **Impact if violated**: HIGH - Poor user experience, inconsistent error responses

## The Rules

### API Gateway Lambdas: Always Return Response

**NEVER throw errors in API Gateway Lambda handlers.**

API Gateway Lambdas must ALWAYS return a well-formed response object, even for errors. Throwing an error returns a 502 Bad Gateway to the client.

### Event-Driven Lambdas: Throw Errors for Retries

**DO throw errors in event-driven Lambdas.**

Event-driven Lambdas (SNS, SQS, EventBridge) should throw errors to trigger automatic retries and DLQ processing.

## Examples

### ‚úÖ Correct - API Gateway Error Handling

```typescript
// src/lambdas/ListFiles/src/index.ts
import {APIGatewayProxyResult, Context} from 'aws-lambda'
import {lambdaErrorResponse, response, getUserDetailsFromEvent} from '../../../util/lambda-helpers'
import {withXRay} from '../../../lib/vendor/AWS/XRay'

export const handler = withXRay(async (event, context, {traceId}): Promise<APIGatewayProxyResult> => {
  const {userId, userStatus} = getUserDetailsFromEvent(event)

  // Return 401 for unauthenticated users
  if (userStatus == UserStatus.Unauthenticated) {
    return lambdaErrorResponse(context, generateUnauthorizedError())
  }

  try {
    const files = await getFilesByUser(userId as string)
    // Return 200 with data
    return response(context, 200, {contents: files, keyCount: files.length})
  } catch (error) {
    // Return error response, don't throw
    return lambdaErrorResponse(context, error)
  }
})
```

### ‚úÖ Correct - Event-Driven Error Handling

```typescript
// src/lambdas/S3ObjectCreated/src/index.ts
import {logError, logInfo} from '../../../util/lambda-helpers'
import {withXRay} from '../../../lib/vendor/AWS/XRay'
import {S3Event, Context} from 'aws-lambda'

export const handler = withXRay(async (event: S3Event, context: Context, {traceId}) => {
  logInfo('S3ObjectCreated triggered', event)

  try {
    for (const record of event.Records) {
      await processS3Record(record)
    }
    return {statusCode: 200}
  } catch (error) {
    logError('Failed to process S3 event', error)
    // Throw to trigger retry/DLQ
    throw error
  }
})
```

### ‚ùå Incorrect - Throwing in API Gateway Lambda

```typescript
// ‚ùå WRONG - Throws error, returns 502 to client
export const handler = async (event, context) => {
  const result = await riskyOperation()  // Might throw
  return response(context, 200, result)
}

// ‚ùå WRONG - Throws instead of returning error response
export const handler = async (event, context) => {
  if (!event.body) {
    throw new Error('Missing body')  // Returns 502!
  }
}
```

### ‚ùå Incorrect - Not Throwing in Event-Driven Lambda

```typescript
// ‚ùå WRONG - Swallows error, no retry triggered
export const handler = async (event, context) => {
  try {
    await processEvent(event)
  } catch (error) {
    console.error(error)
    return {statusCode: 500}  // Event appears "successful"
  }
}
```

## Input Validation Errors

### API Gateway: Return 400 Bad Request

```typescript
import {getPayloadFromEvent, validateRequest} from '../../../util/apigateway-helpers'
import {lambdaErrorResponse, response} from '../../../util/lambda-helpers'

export const handler = withXRay(async (event, context, {traceId}) => {
  let requestBody
  try {
    requestBody = getPayloadFromEvent(event)
    validateRequest(requestBody, registerDeviceSchema)
  } catch (error) {
    // Validation errors return 400 via lambdaErrorResponse
    return lambdaErrorResponse(context, error)
  }

  try {
    const device = await registerDevice(requestBody)
    return response(context, 200, {endpointArn: device.endpointArn})
  } catch (error) {
    return lambdaErrorResponse(context, error)
  }
})
```

## HTTP Status Codes

Use the `response` helper from lambda-helpers with appropriate status codes:

```typescript
// 200 - Success with data
return response(context, 200, {contents: files})

// 201 - Created
return response(context, 201, {endpointArn: device.endpointArn})

// 400 - Bad Request (via lambdaErrorResponse)
throw new BadRequestError('Invalid parameters')

// 401 - Unauthorized
return lambdaErrorResponse(context, generateUnauthorizedError())

// 404 - Not Found
throw new NotFoundError('Resource not found')

// 500 - Internal Server Error
return lambdaErrorResponse(context, error)
```

## Error Logging

Always use `logError` from lambda-helpers:

```typescript
import {logError} from '../../../util/lambda-helpers'

try {
  await operation()
} catch (error) {
  logError(error, {
    context: 'operation',
    traceId,
    userId: event.userId
  })

  // Handle appropriately for Lambda type
}
```

## Enforcement

### Code Review Checklist

- [ ] API Gateway Lambdas NEVER throw errors
- [ ] API Gateway Lambdas return proper status codes
- [ ] Event-driven Lambdas throw errors on failure
- [ ] All errors logged with `logError()`
- [ ] Input validation returns 400 for API Gateway

## Related Patterns

- [Lambda Function Patterns](Lambda-Function-Patterns.md) - Handler structure
- [CloudWatch Logging](../AWS/CloudWatch-Logging.md) - Structured logging

---

*Handle errors appropriately for your Lambda invocation type. API Gateway Lambdas return error responses, event-driven Lambdas throw errors for retries.*
# Comprehensive Serverless Project Evaluation

## Executive Summary

Based on 50+ web searches across serverless frameworks, architecture patterns, testing strategies, and open-source projects, combined with deep codebase exploration, this document provides a comprehensive evaluation of the **AWS CloudFormation Media Downloader** project against industry best practices.

**Overall Assessment: EXCELLENT (9/10)**

This project demonstrates production-grade serverless architecture that exceeds most open-source serverless projects in sophistication and adherence to best practices.

---

## Research Methodology

### Web Searches Performed (50+)
1. Serverless Framework project structure best practices 2024-2025
2. AWS Lambda organization patterns (monorepo vs multi-repo)
3. SST Framework AWS serverless infrastructure as code
4. Terraform vs CDK vs SST comparison
5. DynamoDB single-table design ElectroDB best practices
6. DynamoDB vs Aurora Serverless comparison
7. AWS Lambda testing best practices LocalStack integration
8. Webpack vs esbuild serverless Lambda bundling
9. Lambda layers vs bundling tradeoffs cold start
10. Jest ESM mocking Lambda TypeScript patterns
11. AWS Powertools Lambda TypeScript observability
12. Terraform OpenTofu Lambda deployment patterns
13. Serverless TypeScript monorepo turborepo pnpm
14. API Gateway custom authorizer Lambda JWT best practices
15. Serverless APNS push notification Lambda integration
16. yt-dlp serverless Lambda YouTube download implementation
17. AWS X-Ray Lambda tracing serverless observability
18. AWS SDK v3 modular imports Lambda bundle optimization
19. Serverless IAM least privilege permissions per Lambda
20. DynamoDB ElectroDB alternatives (Dynamoose, TypeDORM)
21. Serverless S3 transfer acceleration large file upload
22. Serverless SQS Lambda dead letter queue patterns
23. Better Auth serverless Lambda authentication patterns
24. Sign In with Apple serverless Lambda implementation
25. Serverless CloudWatch logging best practices structured logs
26. Serverless cold start optimization Node.js Lambda 2024
27. Serverless TypeSpec OpenAPI specification generation
28. Serverless Zod validation TypeScript Lambda
29. Serverless GitHub Actions CI/CD Lambda deployment
30. Serverless SOPS secrets management encrypted Lambda
31. Serverless DynamoDB on-demand billing capacity
32. Serverless webhook reliability idempotency patterns
33. AWS Lambda Node.js 22 runtime features 2024
34. Serverless error handling patterns Lambda retry behavior
35. Serverless production architecture scalability patterns
36. Serverless microservices API Gateway domain driven
37. Serverless event-driven Step Functions orchestration
38. Serverless testing fixtures mock AWS services
39. Dependency injection serverless Lambda TypeScript
40. Serverless documentation generation TSDoc
41. Serverless ESLint TypeScript rules code quality
42. Serverless Lambda handler wrapper middleware patterns
43. Serverless media processing Lambda S3 FFmpeg video
44. Serverless code graph dependency analysis TypeScript
45. Serverless Lambda concurrency throttling provisioned
46. Serverless architecture security best practices 2024
47. AWS SAM vs Terraform vs CDK comparison
48. Serverless Lambda CloudWatch metrics dashboards alarms
49. Serverless cost optimization Lambda pricing 2024
50. Open source serverless projects GitHub examples

---

## Detailed Evaluation by Category

### 1. Project Structure - EXCELLENT

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| Lambda Organization | Per-Lambda directories with `src/` and `test/` subdirectories | Modular per-function directories | Matches |
| Monorepo Structure | Single repo with all 17 Lambda functions | Monorepo recommended for <100 devs | Optimal |
| Shared Code | `lib/`, `util/`, `entities/`, `types/` | Domain-based separation | Excellent |
| Entry Point Convention | `src/lambdas/[name]/src/index.ts` | Single entry point per function | Matches |
| Test Co-location | Tests in `test/` adjacent to `src/` | Co-located or separate `__tests__` | Modern pattern |

**Strengths:**
- Automatic Lambda discovery via esbuild entry point scanning
- Clean separation between handler code and shared utilities
- Path aliases (`#entities/*`, `#lib/*`) eliminate relative path hell

**Industry Comparison:**
- Better than Serverless Framework examples (more modular)
- Comparable to AWS SAM best practices
- Matches patterns from successful open-source projects like `serverless-samples`

### 2. Infrastructure as Code - EXCELLENT

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| Tool Choice | OpenTofu (Terraform fork) | Terraform/CDK/SAM/SST | Production-ready |
| File Organization | Per-Lambda `.tf` files | Modular resource files | Excellent |
| IAM Policies | Dedicated role per Lambda | Least-privilege per function | Best practice |
| State Management | Remote state (assumed) | Remote state with locking | Standard |

**Your Advantage Over Alternatives:**
- **vs CDK**: More explicit resource definitions, easier debugging
- **vs SST v3**: No vendor lock-in to Pulumi, more mature ecosystem
- **vs SAM**: More flexibility for non-serverless resources

**Strengths:**
- Each Lambda has its own IAM role with scoped permissions
- Per-Lambda Terraform files allow independent modifications
- SOPS for secrets management (encrypted at rest)

**Gap Identified:**
- Could benefit from Terraform modules for repeated patterns

### 3. Database Architecture - EXCELLENT (Industry-Leading)

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| Database Choice | DynamoDB (single-table) | DynamoDB for serverless | Optimal |
| ORM | ElectroDB | ElectroDB or DynamoDB-Toolbox | Best choice |
| Billing Mode | PAY_PER_REQUEST | On-demand for variable traffic | Cost-effective |
| GSI Strategy | 5+ GSIs for access patterns | Design GSIs per access pattern | Proper design |

**Why This is Industry-Leading:**

1. **Single-Table Design**: Your 9-entity single-table design follows Rick Houlihan's re:Invent guidance exactly
2. **ElectroDB Choice**: Per [DEV.to comparison](https://dev.to/thomasaribart/an-in-depth-comparison-of-the-most-popular-dynamodb-wrappers-5b73), ElectroDB is the "best DynamoDB client wrapper" with superior type inference
3. **Collections Pattern**: Your `Collections.ts` implements JOIN-like queries efficiently
4. **Type Safety**: Full TypeScript inference for all entity operations

**Comparison to Aurora Serverless:**
| Factor | DynamoDB | Aurora Serverless v2 |
|--------|----------|---------------------|
| Cold starts | None | Possible |
| Scaling | Instant | Seconds |
| Pricing | Pay-per-request | Capacity-based |
| Your use case | Perfect fit | Overkill |

Your choice of DynamoDB is optimal for this workload.

### 4. Testing Strategy - EXCELLENT

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| Mock Strategy | Custom ElectroDB mock helper | Centralized mock utilities | Superior |
| Integration Tests | LocalStack | LocalStack or cloud testing | Cost-effective |
| ESM Support | `jest.unstable_mockModule` | Required for ES modules | Modern |
| Fixtures | JSON from real AWS responses | Production-like fixtures | Best practice |

**Your Innovation:**
- `test/helpers/electrodb-mock.ts` is a unique, type-safe solution
- Transitive dependency tracking via `build/graph.json` ensures complete mocking

**Industry Validation:**
- AWS recommends LocalStack integration ([AWS Blog](https://aws.amazon.com/blogs/compute/enhance-the-local-testing-experience-for-serverless-applications-with-localstack/))
- Jest ESM mocking is the current standard pattern ([Jest Docs](https://jestjs.io/docs/ecmascript-modules))

**Gap Identified:**
- Consider adding AWS Powertools Parser for Zod validation in tests

### 5. Build System - EXCELLENT

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| Bundler | esbuild | esbuild (10x faster) | Optimal |
| AWS SDK | Externalized (v3) | Modular imports + external | Optimal |
| Code Splitting | Disabled (single file) | Single file per Lambda | Correct |
| TypeScript | esbuild (native) | esbuild (fastest) | Optimal |

**Status: esbuild Migration Complete**

The project uses esbuild with parallel Lambda builds (`config/esbuild.config.ts`):
- Parallel builds for all Lambda functions
- Tree shaking and dead code elimination
- Source maps for debugging
- Bundle analysis available via `pnpm run analyze`

### 6. Observability - EXCELLENT

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| X-Ray Tracing | AWS Powertools Tracer | Active mode enabled | Optimal |
| Structured Logging | AWS Powertools Logger | AWS Powertools Logger | Optimal |
| Custom Metrics | AWS Powertools Metrics | AWS Powertools Metrics | Optimal |
| Error Tracking | GitHub Issues | Centralized + alerting | Unique approach |

**Status: AWS Lambda Powertools Integrated**

The project uses AWS Lambda Powertools for TypeScript (`src/lib/vendor/Powertools/`):
- Logger: Structured JSON with correlation IDs and persistent attributes
- Metrics: CloudWatch embedded metrics format with custom namespaces
- Tracer: Enhanced X-Ray annotations and subsegments
- `withPowertools()` wrapper integrates all three tools

### 7. Security - EXCELLENT

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| IAM | Per-function least privilege | Principle of least privilege | Best practice |
| Secrets | SOPS encrypted | Secrets Manager or SOPS | Secure |
| API Auth | Custom authorizer + Better Auth | Lambda authorizer | Proper |
| Dependencies | `.npmrc` lifecycle protection | Supply chain security | Innovative |

**Your Security Innovations:**
1. **`.npmrc` lifecycle script protection**: Blocks AI-targeted typosquatting attacks - this is ahead of industry practices
2. **Per-Lambda IAM roles**: Each function has exactly the permissions it needs
3. **Better Auth integration**: Enterprise-grade authentication with ElectroDB adapter

**Industry Alignment:**
- Matches [14 AWS Lambda Security Best Practices](https://www.ranthebuilder.cloud/post/14-aws-lambda-security-best-practices-for-building-secure-serverless-applications)
- Exceeds OWASP serverless guidelines

### 8. Developer Experience - EXCELLENT

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| Path Aliases | `#entities/*`, `#lib/*`, etc. | tsconfig paths | Modern |
| Hot Reload | Not applicable (Lambda) | N/A for Lambda | N/A |
| Local CI | `pnpm run ci:local` | Pre-push validation | Excellent |
| Documentation | Wiki + AGENTS.md + TSDoc | Comprehensive docs | Thorough |

**Unique Innovations:**
1. **AGENTS.md**: AI-friendly documentation for code assistants
2. **Convention Capture System**: Automatic documentation of emergent patterns
3. **MCP Server**: Custom tooling for project-specific queries

### 9. Webhook & Event Patterns - EXCELLENT

| Aspect | Your Implementation | Industry Best Practice | Assessment |
|--------|---------------------|----------------------|------------|
| Feedly Webhook | Query-based auth | HMAC or query auth | Appropriate |
| Retry Handling | SQS + DLQ pattern | Dead letter queues | Best practice |
| Idempotency | FileDownloads entity | DynamoDB for state | Implemented |
| Push Notifications | SNS -> SQS -> Lambda | AWS recommended | Correct pattern |

**Your FileDownloads Entity is Elegant:**
- Tracks download state separately from Files metadata
- Enables retry with exponential backoff
- GSI6 for status + retryAfter queries

---

## Comparison to Notable Open Source Projects

### vs [serverless/examples](https://github.com/serverless/examples)
| Aspect | Your Project | serverless/examples |
|--------|--------------|---------------------|
| TypeScript | Full strict mode | Mixed (some JS) |
| Testing | Comprehensive | Basic examples |
| ORM | ElectroDB | Direct SDK calls |
| **Winner** | Your project | - |

### vs [aws-samples/serverless-samples](https://github.com/aws-samples/serverless-samples)
| Aspect | Your Project | AWS Samples |
|--------|--------------|-------------|
| Single-table design | 9 entities | Usually separate tables |
| IaC | OpenTofu | SAM/CDK |
| Production-ready | Yes | Reference only |
| **Winner** | Your project (production) | Educational |

### vs SST Examples
| Aspect | Your Project | SST Examples |
|--------|--------------|--------------|
| Infrastructure | OpenTofu (explicit) | SST/Pulumi (abstracted) |
| Vendor lock-in | None | SST ecosystem |
| Maturity | Production | Framework examples |
| **Winner** | Your project (independence) | SST (DX) |

---

## Recommendations for Future Development

### High Priority (Significant Impact)

#### ~~1. Migrate to esbuild for Build Performance~~ ‚úÖ COMPLETE
**Status**: Implemented in `config/esbuild.config.ts`
- Parallel Lambda builds with esbuild
- Tree shaking and bundle analysis
- Achieved 10x faster builds

#### ~~2. Add AWS Lambda Powertools for TypeScript~~ ‚úÖ COMPLETE
**Status**: Implemented in `src/lib/vendor/Powertools/`
- Logger with structured JSON and correlation IDs
- Metrics with CloudWatch embedded format
- Tracer with enhanced X-Ray annotations
- `withPowertools()` wrapper for all handlers

#### 3. Add Idempotency for WebhookFeedly
**Current State**: No explicit idempotency handling
**Recommendation**: Use Powertools Idempotency utility
**Impact**: Prevent duplicate processing of webhooks

**Sources**:
- [Handling Lambda functions idempotency](https://aws.amazon.com/blogs/compute/handling-lambda-functions-idempotency-with-aws-lambda-powertools/)
- [Webhooks on AWS Lambda Tips & Tricks](https://blog.serverlessadvocate.com/webhooks-on-aws-lambda-tips-tricks-63b231d09360)

### Medium Priority (Quality of Life)

#### 4. Consider Node.js 22 Runtime
**Current State**: Node.js 24.x (already using!)
**Status**: Already optimal
**Note**: You're already on the latest LTS runtime

**Sources**:
- [Node.js 22 runtime now available in AWS Lambda](https://aws.amazon.com/blogs/compute/node-js-22-runtime-now-available-in-aws-lambda/)

#### 5. Add CloudWatch Dashboards via IaC
**Current State**: Implemented in Terraform (commit #187)
**Status**: Already complete

#### 6. Implement Provisioned Concurrency for Auth Lambdas
**Current State**: On-demand scaling
**Recommendation**: Provisioned concurrency for `ApiGatewayAuthorizer`, `LoginUser`
**Impact**: Eliminate cold starts for authentication (latency-sensitive)
**Tradeoff**: Additional cost (~$5-20/month depending on config)

**Sources**:
- [AWS Lambda Provisioned Concurrency](https://www.serverless.com/blog/aws-lambda-provisioned-concurrency)

### Low Priority (Nice to Have)

#### 7. Terraform Modules for Lambda Patterns
**Current State**: Individual `.tf` files per Lambda
**Recommendation**: Create reusable module for Lambda + IAM + CloudWatch pattern
**Impact**: Reduced duplication, easier maintenance

#### 8. Add Zod Validation with Powertools Parser
**Current State**: Already using Zod for validation
**Recommendation**: Integrate with Powertools Parser middleware
**Impact**: Catch malformed payloads at function entry with middleware pattern

**Sources**:
- [Validating event payload with Powertools](https://aws.amazon.com/blogs/compute/validating-event-payload-with-powertools-for-aws-lambda-typescript/)

---

## Architecture Decisions Validated

### DynamoDB vs Aurora: Correct Choice
Your workload characteristics:
- Variable traffic (personal use + occasional spikes)
- Simple access patterns (key-value lookups, relationship queries)
- No complex transactions or joins

DynamoDB is the right choice. Aurora Serverless v2 would be overkill with higher cold starts and costs.

### OpenTofu vs SST: Correct Choice
Your requirements:
- Full infrastructure control
- No framework lock-in
- Complex IAM policies

OpenTofu provides the flexibility you need. SST would abstract away too much control.

### ElectroDB vs Alternatives: Correct Choice
Per industry comparison, ElectroDB offers:
- Best type inference
- Native single-table support
- Collections for JOIN-like queries

### esbuild: Migration Complete ‚úÖ
esbuild is now the project bundler, providing:
- 10x faster builds via parallel compilation
- Tree shaking and dead code elimination
- Bundle analysis via `pnpm run analyze`

---

## Summary Scorecard

| Category | Score | Notes |
|----------|-------|-------|
| Project Structure | 10/10 | Industry-leading organization |
| Infrastructure as Code | 9/10 | Could use Terraform modules |
| Database Architecture | 10/10 | Exemplary single-table design |
| Testing Strategy | 9/10 | Custom mock helper is innovative |
| Build System | 10/10 | esbuild with parallel builds |
| Observability | 10/10 | AWS Powertools fully integrated |
| Security | 10/10 | npm lifecycle protection is ahead of curve |
| Developer Experience | 9/10 | AGENTS.md, MCP server are unique |

**Overall: 9.6/10 - Production-Grade Excellence**

---

## Key Sources Referenced

### Project Structure
- [AWS Blog: Best practices for organizing larger serverless applications](https://aws.amazon.com/blogs/compute/best-practices-for-organizing-larger-serverless-applications/)
- [Serverless.com: Structuring a Real-World Serverless App](https://www.serverless.com/blog/structuring-a-real-world-serverless-app)
- [Lumigo: Mono-Repo vs One-Per-Service](https://lumigo.io/blog/mono-repo-vs-one-per-service/)

### Database & ORM
- [Alex DeBrie: The What, Why, and When of Single-Table Design](https://www.alexdebrie.com/posts/dynamodb-single-table/)
- [ElectroDB Documentation](https://electrodb.dev/en/core-concepts/introduction/)
- [DEV.to: DynamoDB wrapper comparison](https://dev.to/thomasaribart/an-in-depth-comparison-of-the-most-popular-dynamodb-wrappers-5b73)

### Testing
- [AWS Blog: Enhance local testing with LocalStack](https://aws.amazon.com/blogs/compute/enhance-the-local-testing-experience-for-serverless-applications-with-localstack/)
- [Jest ESM Documentation](https://jestjs.io/docs/ecmascript-modules)

### Observability
- [AWS Lambda Powertools for TypeScript](https://aws.amazon.com/blogs/compute/simplifying-serverless-best-practices-with-aws-lambda-powertools-for-typescript/)
- [AWS X-Ray Lambda Tracing Best Practices](https://aws-observability.github.io/observability-best-practices/patterns/Tracing/xraylambda/)

### Build Optimization
- [Medium: 10x faster TypeScript Serverless builds with esbuild](https://medium.com/@arsenyyankovski/how-we-sped-up-our-typescript-serverless-builds-ten-times-70-lambdas-under-1-minute-f79a925dfe4c)
- [AWS Blog: Optimizing Node.js dependencies in Lambda](https://aws.amazon.com/blogs/compute/optimizing-node-js-dependencies-in-aws-lambda/)

### Security
- [RanTheBuilder: 14 AWS Lambda Security Best Practices](https://www.ranthebuilder.cloud/post/14-aws-lambda-security-best-practices-for-building-secure-serverless-applications)
- [AWS Lambda Permissions Documentation](https://docs.aws.amazon.com/lambda/latest/dg/lambda-permissions.html)

---

## Conclusion

This project represents **production-grade serverless architecture** that exceeds most open-source examples and follows AWS Well-Architected Framework principles. The main opportunities for improvement are:

1. **Build performance**: Migrate to esbuild for faster builds and smaller bundles
2. **Observability**: Add AWS Lambda Powertools for structured logging, metrics, and tracing
3. **Webhook reliability**: Add idempotency handling with Powertools

The architecture choices (DynamoDB, ElectroDB, OpenTofu, single-table design) are optimal for the use case and should not be changed.

---

*Assessment Date: December 2025*
*Assessment Version: 1.0*
# AI Tool Context Files

## Quick Reference
- **When to use**: Setting up AI assistant context for a project
- **Enforcement**: Recommended - ensures AI tool compatibility
- **Impact if violated**: Low - some AI tools may not auto-load context

## Overview

AI coding assistants look for specific filenames to auto-load project context. The industry has consolidated around **AGENTS.md** as the universal standard, with tool-specific passthrough files for compatibility.

## The AGENTS.md Standard

AGENTS.md is the open standard for AI coding assistant context, maintained collaboratively by OpenAI, Amp, Google, Cursor, and Factory, with support across 20+ AI coding tools.

### Tool Support Matrix

| AI Tool | Auto-Reads AGENTS.md | Auto-Reads CLAUDE.md | Auto-Reads GEMINI.md |
|---------|---------------------|---------------------|---------------------|
| **OpenAI Codex CLI** | ‚úÖ Yes | No | No |
| **GitHub Copilot** | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes |
| **Google Gemini CLI** | Configurable | No | ‚úÖ Yes |
| **Claude Code** | No | ‚úÖ Yes | No |
| **Cursor** | ‚úÖ Yes | - | - |
| **Codeium** | ‚úÖ Yes | - | - |

**Official Resource**: https://agents.md

## File Architecture

### Recommended Structure

```
project/
‚îú‚îÄ‚îÄ AGENTS.md          # Universal context (single source of truth)
‚îú‚îÄ‚îÄ CLAUDE.md          # Claude Code passthrough (1 line)
‚îú‚îÄ‚îÄ GEMINI.md          # Gemini Code Assist passthrough (4 lines)
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ wiki/          # Detailed conventions
    ‚îî‚îÄ‚îÄ conventions-tracking.md  # Project-specific patterns
```

### Benefits
- Single source of truth in AGENTS.md
- Tool compatibility via passthrough files
- No duplication or sync issues
- Works with 20+ AI coding tools

## AGENTS.md Content Structure

```markdown
# Project Context for AI Agents

## Convention Capture System
[Universal detection and tracking instructions]

## Project Overview
[Project-specific architecture and tech stack]

## Wiki Conventions to Follow
[Links to relevant wiki pages]

## Critical Project-Specific Rules
[Unique requirements for THIS project only]

## Development Workflow
[Commands, tools, build process]
```

### What Goes in AGENTS.md

**Include**:
- Convention Capture System instructions (universal)
- Project overview and architecture
- Links to wiki for universal patterns
- Project-specific unique requirements
- Development workflow commands

**Exclude (put in wiki instead)**:
- Universal naming conventions
- Standard testing patterns
- Common TypeScript patterns
- AWS service usage patterns

## Passthrough File Pattern

### CLAUDE.md Passthrough

```markdown
@AGENTS.md
```

That's it. One line. Claude Code will read AGENTS.md via this reference.

### GEMINI.md Passthrough

```markdown
# See AGENTS.md

This project uses AGENTS.md as the single source of truth for AI coding assistant context.

Please see AGENTS.md in the repository root for comprehensive project documentation and guidelines.
```

## Creating AGENTS.md for New Projects

### Step 1: Copy Template

```bash
cp path/to/template/AGENTS.md ./AGENTS.md
```

### Step 2: Add Project-Specific Content

Edit AGENTS.md to include:
- Your project description
- Your architecture stack
- Your specific requirements
- Your development commands

### Step 3: Create Passthrough Files

**CLAUDE.md**:
```markdown
@AGENTS.md
```

**GEMINI.md**:
```markdown
# See AGENTS.md

This project uses AGENTS.md as the single source of truth.

Please see AGENTS.md for documentation.
```

### Step 4: Initialize Convention Tracking

```bash
touch docs/conventions-tracking.md
```

## Migration from Existing Projects

### From CLAUDE.md Only

```bash
# Rename to AGENTS.md
mv CLAUDE.md AGENTS.md

# Create new CLAUDE.md passthrough
echo "@AGENTS.md" > CLAUDE.md

# Create GEMINI.md passthrough
cat > GEMINI.md << 'EOF'
# See AGENTS.md
Please see AGENTS.md for documentation.
EOF
```

## Benefits

### For Developers
- Edit context in one place (AGENTS.md)
- Works with any AI coding tool
- No duplication or sync issues

### For AI Assistants
- Automatically load context on session start
- Inherit Convention Capture System
- Access project-specific rules

### For Teams
- Consistent across all AI tools
- Single file to review in PRs
- Easy onboarding

## Related Documentation

- [Convention Capture System](Convention-Capture-System.md) - How conventions persist
- [Working with AI Assistants](Working-with-AI-Assistants.md) - Effective collaboration

---

*Use AGENTS.md as the single source of truth for AI tool context. Maintain compatibility with tool-specific passthrough files.*
# Emerging Conventions

## Quick Reference
- **When to use**: Capturing new patterns discovered during development
- **Enforcement**: Ongoing - live append-only log
- **Impact if violated**: LOW - Lost institutional knowledge

## Overview

This is a live, append-only log of conventions discovered during development that haven't yet been promoted to formal wiki pages. Think of it as the "working memory" of the Convention Capture System.

## Format

Each entry follows this structure:

```markdown
## [Date] - [Convention Name]

**Type**: [Rule/Pattern/Methodology/Anti-Pattern]
**Priority**: [Critical/High/Medium/Low]
**Context**: [Where/when this applies]

**What**: [One-sentence description]

**Why**: [Rationale for the convention]

**Example**:
```[language]
// Code example
```

**Status**: [Emerging/Validated/Documented/Deprecated]
**Wiki Page**: [Link when promoted to wiki, or "Pending"]
```

## Current Emerging Conventions

### 2025-11-24 - ElectroDB Mock Helper Pattern

**Type**: Pattern
**Priority**: High
**Context**: Unit testing with ElectroDB entities

**What**: Always use `test/helpers/electrodb-mock.ts` for mocking ElectroDB entities

**Why**: 
- Consistent mock structure across all tests
- Handles ElectroDB's complex entity API
- Reduces test boilerplate
- Easier to update mocks when ElectroDB changes

**Example**:
```typescript
import {createElectroDBMock} from '../../../test/helpers/electrodb-mock'

jest.unstable_mockModule('../../../lib/vendor/ElectroDB/entity', () =>
  createElectroDBMock({
    get: jest.fn().mockResolvedValue({data: mockUser}),
    query: jest.fn().mockResolvedValue({data: [mockUser]})
  })
)
```

**Status**: Validated (in use across test suite)
**Wiki Page**: Mentioned in Testing/Jest-ESM-Mocking-Strategy.md

---

### 2025-11-24 - build/graph.json for Dependency Analysis

**Type**: Tool/Pattern
**Priority**: High
**Context**: Understanding code dependencies, especially for testing

**What**: Use auto-generated `build/graph.json` to find all transitive dependencies

**Why**:
- Shows complete dependency tree
- Critical for Jest tests (need to mock ALL transitive deps)
- Prevents "missing mock" test failures
- Automated (regenerated on every build)

**Example**:
```bash
# Find all dependencies of a file
cat build/graph.json | jq '.transitiveDependencies["src/lambdas/WebhookFeedly/src/index.ts"]'

# Output shows ALL files that need mocking
```

**Status**: Validated (documented in project conventions)
**Wiki Page**: Mentioned in AGENTS.md, could be separate Testing wiki page

---

### 2025-11-24 - LocalStack Vendor Wrapper Configuration

**Type**: Pattern
**Priority**: Medium
**Context**: Integration testing with LocalStack

**What**: Vendor wrappers check `USE_LOCALSTACK` env var and configure endpoints accordingly

**Why**:
- Single source for LocalStack configuration
- Tests don't need to mock AWS service endpoints
- Same vendor wrappers work in LocalStack and real AWS
- Easy to switch between local and cloud testing

**Example**:
```typescript
// lib/vendor/AWS/S3.ts
function getS3Client(): S3Client {
  if (!s3Client) {
    const isLocalStack = process.env.USE_LOCALSTACK === 'true'
    
    s3Client = new S3Client({
      region: process.env.AWS_REGION || 'us-west-2',
      endpoint: isLocalStack ? 'http://localhost:4566' : undefined,
      forcePathStyle: isLocalStack  // Required for LocalStack
    })
  }
  return s3Client
}
```

**Status**: Validated (used in multiple vendor wrappers)
**Wiki Page**: Could be added to Integration/LocalStack-Testing.md or Testing/Integration-Testing.md

---

## How to Use This Page

### For Developers

1. **Check before coding** - See if someone already solved your problem
2. **Add discoveries** - Append new conventions you find
3. **Validate patterns** - Mark as "Validated" after successful use
4. **Promote to wiki** - Create proper wiki page for important patterns

### For AI Assistants

1. **Monitor this page** - Check for patterns relevant to current task
2. **Flag new patterns** - When you notice repeated decisions, flag them
3. **Suggest promotion** - Recommend validated patterns for wiki pages
4. **Update status** - Mark patterns as you see them used/validated

### Adding an Entry

```markdown
## [Today's Date] - [Descriptive Name]

**Type**: [Rule/Pattern/Methodology/Anti-Pattern]
**Priority**: [Critical/High/Medium/Low]
**Context**: [When/where this applies]

**What**: [Clear one-sentence description]

**Why**: [Brief rationale - what problem does this solve?]

**Example**:
```[language]
[Clear, minimal code example]
```

**Status**: Emerging
**Wiki Page**: Pending
```

## Promotion Criteria

A convention should be promoted to a wiki page when:

1. **Validated** - Used successfully in 3+ places
2. **Important** - Priority High or Critical
3. **Stable** - Pattern unlikely to change
4. **General** - Applies broadly, not one-off solution
5. **Ready** - Enough examples and rationale to document properly

## Archive

When a convention is promoted to a wiki page, update the entry:

```markdown
## [Date] - [Convention Name]
[... existing content ...]

**Status**: Documented
**Wiki Page**: `../Category/Page-Name.md` (example path)
**Promoted**: [Date]
```

Leave the entry here for reference, but mark it as documented.

## Anti-Patterns to Avoid

Document anti-patterns (things NOT to do):

```markdown
## [Date] - [Anti-Pattern Name]

**Type**: Anti-Pattern
**Priority**: [Level]
**Context**: [Where people try this]

**What**: [What people mistakenly do]

**Why Not**: [Why this doesn't work]

**Instead**: [What to do instead]

**Example of Problem**:
```[language]
// Bad approach
```

**Correct Approach**:
```[language]
// Good approach
```

**Status**: [Status]
**Wiki Page**: [Link or Pending]
```

## Integration with Convention Capture

This page is part of the Convention Capture System:

1. **Detection** - Patterns emerge during development
2. **Flagging** - Developer or AI flags pattern (adds to this page)
3. **Validation** - Pattern used successfully multiple times
4. **Documentation** - Create proper wiki page
5. **Enforcement** - Add linting/testing where possible

See [Convention Capture System](Convention-Capture-System.md) for full methodology.

## Status Definitions

- **Emerging**: Just discovered, not yet validated
- **Validated**: Successfully used in production code
- **Documented**: Promoted to formal wiki page
- **Deprecated**: Pattern no longer recommended
- **Rejected**: Tried but doesn't work well

## Related Patterns

- [Convention Capture System](Convention-Capture-System.md) - Full methodology
- [Documentation Patterns](Documentation-Patterns.md) - Wiki organization
- [Working with AI Assistants](Working-with-AI-Assistants.md) - AI collaboration

---

*This is a living document. Append new conventions as they emerge. Update status as patterns are validated and promoted to wiki pages. Never delete entries - they provide history of pattern evolution.*
# Documentation Patterns

## Quick Reference
- **When to use**: Organizing documentation across projects
- **Enforcement**: Recommended - maintains consistency
- **Impact if violated**: Low - may have disorganized docs

## Passthrough File Pattern

A **passthrough file** references a canonical source, allowing multiple tools to access the same content.

```
Canonical Source (AGENTS.md)
       ‚Üì
   References
       ‚Üì
Passthrough Files (CLAUDE.md, GEMINI.md)
```

### Benefits
1. **Single Source of Truth** - Content defined once
2. **Tool Compatibility** - Works with multiple AI tools
3. **No Duplication** - Eliminates sync issues
4. **Easy Maintenance** - Update one file

## Passthrough Examples

### Claude Code Passthrough
**File**: `CLAUDE.md`
```markdown
@AGENTS.md
```

Claude Code reads CLAUDE.md, sees the reference, and loads AGENTS.md content.

### Gemini Code Assist Passthrough
**File**: `GEMINI.md`
```markdown
# See AGENTS.md

This project uses AGENTS.md as the single source of truth for AI coding assistant context.

Please see AGENTS.md in the repository root for comprehensive project documentation and guidelines.
```

### Documentation Wiki Passthrough
```markdown
# [Topic] Documentation

For comprehensive documentation on testing patterns, see the wiki:

- [Jest ESM Mocking Strategy](../Testing/Jest-ESM-Mocking-Strategy.md)
- [Lazy Initialization Pattern](../Testing/Lazy-Initialization-Pattern.md)

This keeps documentation centralized and avoids duplication.
```

## Wiki Organization

### Git-Based Wiki
Store wiki content in main repository for version control:

```
docs/
‚îî‚îÄ‚îÄ wiki/
    ‚îú‚îÄ‚îÄ Home.md
    ‚îú‚îÄ‚îÄ Conventions/
    ‚îÇ   ‚îú‚îÄ‚îÄ Naming-Conventions.md
    ‚îÇ   ‚îî‚îÄ‚îÄ Git-Workflow.md
    ‚îú‚îÄ‚îÄ TypeScript/
    ‚îÇ   ‚îî‚îÄ‚îÄ Lambda-Function-Patterns.md
    ‚îî‚îÄ‚îÄ Meta/
        ‚îî‚îÄ‚îÄ Documentation-Patterns.md
```

### Auto-Sync to GitHub Wiki
Use GitHub Actions to automatically sync:

```
docs/wiki/ (Git)  ‚Üí  GitHub Actions  ‚Üí  GitHub Wiki (Public)
Source of Truth      Auto-sync on       Beautiful UI
PR reviewed          push to master     Search enabled
```

## Page Template

### Standard Convention Page
```markdown
# [Convention Name]

## Quick Reference
- **When to use**: [One-line description]
- **Enforcement**: [Zero-tolerance/Required/Recommended]
- **Impact if violated**: [Critical/High/Medium/Low]

## The Rule
[Clear, concise statement of the convention]

## Examples
### ‚úÖ Correct
[Good example with code]

### ‚ùå Incorrect
[Bad example with code]

## Rationale
[Why this convention exists]

## Enforcement
[How to check/automate compliance]

## Related Patterns
- Link to related convention 1
- Link to related convention 2
```

### Why This Template?
1. **Quick Reference** - Developers get essence immediately
2. **Clear Rules** - No ambiguity about what's required
3. **Learning by Example** - Visual comparison of good/bad
4. **Context** - Rationale explains the "why"
5. **Actionable** - Enforcement section shows how to apply
6. **Discoverable** - Related patterns aid navigation

## Reference Pattern

### From Application Code
```typescript
/**
 * Validates user credentials
 *
 * See: docs/wiki/TypeScript/TypeScript-Error-Handling.md
 */
function validateCredentials(username: string, password: string) {
  // Implementation
}
```

### From AGENTS.md
```markdown
## Wiki Conventions to Follow

**BEFORE WRITING ANY CODE, READ THE APPLICABLE GUIDE:**

### Core Conventions
- [Git Workflow](docs/wiki/Conventions/Git-Workflow.md) - NO AI attribution
- [Naming](docs/wiki/Conventions/Naming-Conventions.md) - camelCase rules

### Language-Specific
- [Lambda](docs/wiki/TypeScript/Lambda-Function-Patterns.md)
- [Testing](docs/wiki/Testing/Jest-ESM-Mocking-Strategy.md)
- [AWS SDK](docs/wiki/AWS/SDK-Encapsulation-Policy.md) - ZERO tolerance
```

## Multi-Project Documentation

### Shared Wiki Pattern
```
shared-conventions/
‚îî‚îÄ‚îÄ wiki/
    ‚îú‚îÄ‚îÄ TypeScript/
    ‚îú‚îÄ‚îÄ Testing/
    ‚îî‚îÄ‚îÄ AWS/

project-a/
‚îú‚îÄ‚îÄ AGENTS.md (references shared wiki)
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ conventions-tracking.md (project-specific)
```

### Symlink Pattern
```bash
cd docs
ln -s ../../shared-conventions/wiki wiki
```

## Link Management

### Internal Wiki Links
```markdown
See also [Naming Conventions](../Conventions/Naming-Conventions.md)
See also [Lambda Patterns](../TypeScript/Lambda-Function-Patterns.md)
```

### External Links
```markdown
See [Conventional Commits](https://www.conventionalcommits.org/)
See [Issue Tracker](https://github.com/user/repo/issues)
```

## Best Practices

### Do's
‚úÖ Use passthrough files for tool compatibility
‚úÖ Maintain single source of truth
‚úÖ Reference wiki instead of duplicating
‚úÖ Auto-sync to GitHub Wiki
‚úÖ Version control all documentation
‚úÖ Link between related patterns
‚úÖ Use standard page template

### Don'ts
‚ùå Duplicate content across files
‚ùå Edit GitHub Wiki directly (edit docs/wiki/)
‚ùå Create documentation silos
‚ùå Skip cross-references
‚ùå Leave broken links
‚ùå Create tool-specific forks

## Related Documentation
- [AI Tool Context Files](AI-Tool-Context-Files.md) - AGENTS.md and passthroughs
- [Convention Capture System](Convention-Capture-System.md) - How patterns are captured
- [Working with AI Assistants](Working-with-AI-Assistants.md) - Effective collaboration

---

*Use passthrough files to maintain compatibility while keeping a single source of truth. Auto-sync documentation to make it accessible in multiple formats.*
# Working with AI Assistants

## Quick Reference
- **When to use**: All interactions with AI coding assistants
- **Enforcement**: Recommended - improves collaboration effectiveness
- **Impact if violated**: LOW - Less effective AI assistance

## The Rules

1. **Provide Complete Context** - Include relevant code, errors, and desired outcomes
2. **Be Specific About Constraints** - State conventions, patterns, and restrictions explicitly
3. **Request Incremental Changes** - Break large tasks into smaller, verifiable steps
4. **Review and Iterate** - Check AI output, provide feedback, refine results

## Effective Prompting Patterns

### ‚úÖ Correct - Specific with Context

```
Add error handling to the ProcessFile Lambda function.

Context:
- File: src/lambdas/ProcessFile/src/index.ts
- This is an API Gateway Lambda (must return responses, not throw)
- We use the withXRay decorator for all handlers
- Error logging uses logError from util/lambda-helpers

Requirements:
- Wrap main logic in try/catch
- Log errors with file ID and trace ID
- Return 500 status with generic error message
- Follow existing error handling pattern from DownloadVideo Lambda
```

### ‚úÖ Correct - Explicit Constraints

```
Create a new Lambda function called RegisterDevice.

Constraints:
- Use TypeScript with strict types
- Follow Lambda Function Patterns wiki guide
- Use vendor wrappers for AWS SDK (ZERO tolerance)
- Mock ALL transitive dependencies in tests
- Use PascalCase for function name
- Include X-Ray tracing with withXRay decorator

Structure:
src/lambdas/RegisterDevice/
‚îú‚îÄ‚îÄ src/index.ts
‚îî‚îÄ‚îÄ test/index.test.ts

Follow existing Lambda patterns (see ProcessFile, DownloadVideo).
```

### ‚ùå Incorrect - Vague Request

```
Add error handling to my Lambda.
```

Problems: Which Lambda? What type of error handling? What patterns to follow?

### ‚ùå Incorrect - Too Large

```
Create the entire media download system including all Lambdas, DynamoDB schema,
S3 buckets, API Gateway, testing, documentation, and deployment scripts.
```

Problems: Too many components at once, hard to review, difficult to debug.

## Providing Context

### Share Relevant Code

```
I need to refactor the download logic in DownloadVideo Lambda.

Current implementation:
[paste src/lambdas/DownloadVideo/src/index.ts]

Related utilities:
[paste relevant util functions]

Issue: Download times out for large videos (>500MB)

Goal: Implement streaming download with progress tracking
```

### Share Error Messages

```
Tests are failing with this error:

```
TypeError: Cannot read property 'send' of undefined
  at headObject (lib/vendor/AWS/S3.ts:15:25)
```

Test file: [paste test code]
Handler: [paste handler code]

I think it's a mocking issue but not sure what's missing.
```

## Iterative Refinement

### Step 1: Initial Request

```
Create a Lambda function to process video files from S3.
```

### Step 2: AI Response Review

```
The AI created the function but:
1. ‚ùå Used direct AWS SDK import (violates SDK-Encapsulation-Policy)
2. ‚úÖ Used correct error handling
3. ‚ùå Missing X-Ray tracing
4. ‚úÖ Tests included

Feedback:
Please fix issues #1 and #3:
- Replace AWS SDK imports with vendor wrappers (see lib/vendor/AWS/S3.ts)
- Add withXRay decorator (see existing Lambdas for pattern)
```

### Step 3: Verification

```
Perfect! The code now:
‚úÖ Uses vendor wrappers
‚úÖ Has X-Ray tracing
‚úÖ Follows all patterns

Let's proceed to Step 2: Add business logic.
```

## Common Scenarios

### Adding a New Feature

```
Task: Add retry logic to S3 uploads

Context: File lib/vendor/AWS/S3.ts
Current: createS3Upload() creates Upload instance
Issue: Uploads fail on network issues with no retry

Requirements:
1. Add retry logic (max 3 attempts)
2. Use exponential backoff (1s, 2s, 4s)
3. Log retry attempts with logWarn
4. Throw on final failure

Constraints:
- Don't change function signature
- Don't add new dependencies
- Keep lazy initialization pattern
```

### Fixing a Bug

```
Bug: ProcessFile Lambda returns 502 instead of 500 on errors

Current code: [paste handler]

Expected: Errors should return {statusCode: 500, body: {error: message}}
NOT throw (causes 502)

Please:
1. Identify where error is being thrown
2. Add proper error handling
3. Ensure we follow API Gateway pattern (return response, never throw)
```

## Zero-Tolerance Rules

Before making changes, always:
1. Read applicable wiki guide (docs/wiki/)
2. Check existing similar code
3. Follow established patterns
4. Ask if unsure

**Zero-tolerance violations**:
- AWS SDK Encapsulation (NEVER import @aws-sdk/* directly)
- No AI attribution in commits
- Git as source of truth (no commented-out code explanations)

## Related Patterns

- [Convention Capture System](Convention-Capture-System.md) - Detecting emerging conventions
- [AI Tool Context Files](AI-Tool-Context-Files.md) - AGENTS.md structure

---

*Provide complete context, be specific about constraints, request incremental changes, and iterate based on review. AI assistants work best with clear, specific instructions and relevant examples.*
# Convention Capture System

## Quick Reference
- **When to use**: Every development session with AI assistants
- **Enforcement**: Required - prevents knowledge loss
- **Impact if violated**: CRITICAL - institutional memory lost

## Overview

The Convention Capture System automatically detects, captures, and preserves development conventions as they emerge during work. This ensures no institutional knowledge is lost to conversation history.

## How It Works

### Detection Signals

Monitor for these signals during development:

| Priority | Signal Words | Action |
|----------|--------------|--------|
| üö® **CRITICAL** | NEVER, FORBIDDEN, Zero-tolerance | Immediate capture |
| ‚ö†Ô∏è **HIGH** | MUST, REQUIRED, ALWAYS | Flag for documentation |
| üìã **MEDIUM** | Prefer, Should, Convention | Track pattern |
| üí° **LOW** | Consider, Might, Sometimes | Monitor |

### Real-Time Flagging

When a convention is detected:

```
üîî **CONVENTION DETECTED**

**Name**: AWS SDK Encapsulation
**Type**: Rule
**What**: Never import AWS SDK directly, use vendor wrappers
**Why**: Maintains encapsulation and testability
**Priority**: Critical

Document now? [Y/N]
```

### Convention Tracking

Central registry in `docs/conventions-tracking.md`:

```markdown
## üü° Pending Documentation

### Detected: 2025-11-22
1. **Pattern Name** (Type)
   - What: [Description]
   - Why: [Rationale]
   - Target: docs/wiki/[Category]/[Page].md
   - Status: ‚è≥ Pending

## üü¢ Recently Documented
- [x] **Convention Name** ‚Üí docs/wiki/[Path]
```

## Implementation Guide

### For AI Assistants

**Session Start**:
1. Read AGENTS.md (contains Convention Capture instructions)
2. Check `docs/conventions-tracking.md` for pending items
3. Activate detection mode

**During Work**:
1. Monitor for detection signals
2. Flag conventions immediately
3. Offer to document or defer
4. Continue with primary task

**Session End**:
1. Generate session summary
2. List detected conventions
3. Update `conventions-tracking.md`
4. List pending documentation tasks

### For Developers

**Setting Up**:
1. Add Convention Capture section to AGENTS.md
2. Create `docs/conventions-tracking.md`
3. Create `docs/templates/` directory
4. Initialize with known conventions

**Contributing**:
1. Work normally with AI assistant
2. Confirm when conventions are flagged
3. Review session summaries
4. Approve wiki documentation

## Detection Patterns

### Explicit Statements
```
"Always use camelCase"
"Never commit secrets"
```
‚Üí Immediate capture as rule

### Corrections
```
"Actually, it's PascalCase not camelCase"
"No, we use OpenTofu not Terraform"
```
‚Üí High priority pattern

### Repeated Decisions
```
First occurrence: "Let's use vendor wrappers"
Second occurrence: "Use vendor wrapper again"
```
‚Üí Pattern detected, suggest documentation

## Documentation Template

```markdown
# [Convention Name]

## Classification
- **Type**: Rule | Pattern | Methodology
- **Priority**: Critical | High | Medium | Low
- **Enforcement**: Zero-tolerance | Required | Recommended

## The Rule
[Clear, concise statement]

## Context
**Problem Solved**: [What issue this addresses]
**Benefits**: [Why it matters]

## Examples
### ‚úÖ Correct
[Code example]

### ‚ùå Incorrect
[Anti-pattern]

## Enforcement
[How to check/automate]

## Related Patterns
[Links to related conventions]
```

## Benefits

### Immediate
- No repeated explanations - document once, reference forever
- Consistent patterns - same conventions across all work
- Clear communication - shared vocabulary
- Reduced cognitive load

### Long-term
- Institutional memory persists beyond individuals
- Faster onboarding for new team members
- Patterns evolve and improve over time
- Prevents technical debt from bad patterns

## Integration with AGENTS.md

Every project using AGENTS.md automatically gets Convention Capture:

```markdown
# AGENTS.md

## Convention Capture System
[Universal instructions for using system]
[Links to this wiki page]

## Project-Specific Content
[Project details]
```

Each project maintains its own:
- `docs/conventions-tracking.md` - Project conventions
- `docs/sessions/` - Session summaries
- Local overrides and additions

## Related Documentation

- [AGENTS.md Template](AI-Tool-Context-Files.md) - Universal instructions
- [Working with AI Assistants](Working-with-AI-Assistants.md) - Collaboration guide

---

*The Convention Capture System ensures valuable patterns and conventions are never lost. By systematically detecting, tracking, and documenting conventions as they emerge, we build persistent institutional memory that benefits all future work.*
# GitHub Wiki Sync Automation

## Quick Reference
- **When to use**: Maintaining project documentation
- **Enforcement**: Automated via GitHub Actions
- **Impact if violated**: N/A - fully automated

## Overview

The GitHub Wiki sync automation provides the best of both worlds:
- **Git-tracked source** - Documentation in `docs/wiki/` is version controlled
- **Beautiful web UI** - GitHub Wiki provides excellent browsing experience
- **Zero manual maintenance** - Automatic sync within 30 seconds of merge

## How It Works

### Directory Structure
```
docs/
‚îî‚îÄ‚îÄ wiki/                        # Source of truth (version controlled)
    ‚îú‚îÄ‚îÄ Home.md                  # Wiki homepage
    ‚îú‚îÄ‚îÄ Getting-Started.md       # Quick start guide
    ‚îú‚îÄ‚îÄ AWS/                     # Category folders
    ‚îÇ   ‚îú‚îÄ‚îÄ CloudWatch-Logging.md
    ‚îÇ   ‚îî‚îÄ‚îÄ Lambda-Environment-Variables.md
    ‚îú‚îÄ‚îÄ Testing/
    ‚îÇ   ‚îú‚îÄ‚îÄ Jest-ESM-Mocking-Strategy.md
    ‚îÇ   ‚îî‚îÄ‚îÄ Coverage-Philosophy.md
    ‚îî‚îÄ‚îÄ ...
```

### Sync Process
1. Developer edits markdown files in `docs/wiki/`
2. Creates PR with documentation changes
3. PR gets reviewed and merged to master
4. GitHub Actions workflow triggers automatically
5. Wiki updates within 30 seconds

## GitHub Actions Workflow

### Trigger Conditions
```yaml
on:
  push:
    branches: [master, main]
    paths:
      - 'docs/wiki/**'
      - '.github/scripts/sync-wiki.sh'
      - '.github/scripts/generate-sidebar.sh'
      - '.github/workflows/sync-wiki.yml'
```

### Key Implementation Details

#### Flat Namespace Requirement
GitHub Wiki requires **all pages at root level** (no subdirectories):

```bash
# Source structure (organized by category)
docs/wiki/AWS/CloudWatch-Logging.md
docs/wiki/Testing/Jest-ESM-Mocking-Strategy.md

# Wiki structure (flat)
wiki/CloudWatch-Logging.md
wiki/Jest-ESM-Mocking-Strategy.md
```

#### Sidebar Generation
The sidebar (_Sidebar.md) is generated from source structure:
```bash
# Reads from categorized source
SOURCE_DIR=main/docs/wiki

# Writes flat links to wiki
[CloudWatch Logging](CloudWatch-Logging)  # No path prefix
```

#### Link Transformation
Internal links are automatically transformed (path removed, extension stripped):
```markdown
# In source file
[See Error Handling](../TypeScript/Error-Handling.md)

# After transformation in wiki
[See Error Handling](Error-Handling)
```

## Scripts

### sync-wiki.sh
- Flattens directory structure
- Transforms internal links
- Handles special files (Home.md, _Sidebar.md, _Footer.md)

### generate-sidebar.sh
- Reads source directory structure
- Creates categorized navigation
- Generates flat links for GitHub Wiki

## Adding New Documentation

### Creating a New Page
```bash
# 1. Create markdown file in appropriate category
echo "# My New Feature" > docs/wiki/Testing/My-New-Feature.md

# 2. Add content
vim docs/wiki/Testing/My-New-Feature.md

# 3. Commit and push
git add docs/wiki/
git commit -m "docs: add My New Feature documentation"
git push
```

### Creating a New Category
```bash
# 1. Create category directory
mkdir docs/wiki/MyCategory

# 2. Add first page
echo "# Category Overview" > docs/wiki/MyCategory/Overview.md

# 3. Commit (sidebar auto-updates)
git add docs/wiki/
git commit -m "docs: add MyCategory documentation"
git push
```

## File Naming

### Unique Names Required
Due to flat namespace, all files must have unique names:

```bash
# ‚ùå Will cause conflicts
docs/wiki/TypeScript/Error-Handling.md
docs/wiki/Bash/Error-Handling.md

# ‚úÖ Use unique names
docs/wiki/TypeScript/TypeScript-Error-Handling.md
docs/wiki/Bash/Bash-Error-Handling.md
```

### Naming Conventions
- Use **Title-Case-With-Hyphens.md** for file names
- Match page title in file name for clarity
- Keep names descriptive but concise

## Special Files

### Home.md
- Wiki landing page
- Must exist at `docs/wiki/Home.md`
- Contains navigation overview

### _Sidebar.md
- Auto-generated, don't edit manually
- Created from source directory structure
- Updates on every sync

### _Footer.md
- Auto-generated with sync timestamp
- Shows link to source repository
- Updates on every sync

## Troubleshooting

### Wiki Not Updating
1. Check workflow runs: `gh run list --workflow=sync-wiki.yml`
2. Verify wiki is enabled in repo settings
3. Check for naming conflicts (duplicate file names)

### Broken Links
1. Ensure unique file names across categories
2. Check link transformation in sync-wiki.sh
3. Verify flat links in _Sidebar.md

### Missing Categories
1. Categories only appear if they contain .md files
2. Check SOURCE_DIR in generate-sidebar.sh
3. Verify directory structure in docs/wiki/

## Benefits

1. **Version Control** - All docs in Git with full history
2. **Code Review** - Documentation changes reviewed in PRs
3. **Automation** - No manual wiki editing needed
4. **Organization** - Category folders in source
5. **Discovery** - Beautiful GitHub Wiki UI
6. **Search** - GitHub Wiki search functionality
7. **Offline Access** - Docs available in cloned repo

## Related Patterns

- [Documentation Patterns](Documentation-Patterns.md) - Documentation standards
- [Convention Capture System](Convention-Capture-System.md) - How conventions are documented
- [AI Tool Context Files](AI-Tool-Context-Files.md) - AGENTS.md integration

---

*Automated GitHub Wiki sync provides version-controlled documentation with zero manual maintenance.*# pnpm Migration Guide

## Overview

This project migrated from npm to pnpm v10+ to implement strategic security hardening against AI-targeted supply chain attacks while improving CI/CD performance by 50-66%.

## Why pnpm?

### Security: Lifecycle Script Protection

**The Primary Motivation**: Defense against AI-targeted typosquatting attacks.

**Attack Vector**:
1. Attackers study which package names LLMs frequently hallucinate
2. Create typosquatted packages matching those hallucinations (e.g., `stripe-node` vs `stripe`, `aws-s3` vs `@aws-sdk/client-s3`)
3. Add malicious `postinstall` scripts that execute **before** developer realizes the mistake
4. Scripts steal: AWS credentials, environment variables, source code, SSH keys

**pnpm v10+ Defense**:
- **Installation-time protection** ‚Üí Scripts blocked by default via `enable-pre-post-scripts=false`
- **Explicit allowlist** ‚Üí Force conscious decision per package in `.npmrc`
- **Audit window** ‚Üí Review code before any execution
- **Visibility** ‚Üí Know exactly which packages need script execution

**Example Protection**:
```bash
# npm (DANGEROUS)
npm install aws-dynamodb  # ‚ö†Ô∏è Runs postinstall script IMMEDIATELY
# If malicious: Credentials stolen before you realize it's wrong package

# pnpm (SAFE)
pnpm install aws-dynamodb  # ‚úÖ Refuses to run scripts
# Error: "aws-dynamodb" tried to run a postinstall script. 
# Add to .npmrc if you trust it: pnpm.onlyBuiltDependencies[]=aws-dynamodb
# You have time to: Check package, realize typo, remove package
```

### Performance: 50-66% Faster CI/CD

**CI/CD Improvements**:
- **Cold cache**: 2-3 min (npm) ‚Üí 45-60 sec (pnpm) = 50% faster
- **Warm cache**: 45-60 sec (npm) ‚Üí 15-20 sec (pnpm) = 66% faster

**ROI**: 30 builds/month √ó 1.5 min saved = **45 min/month** ‚Üí **9 hours/year** saved

### Future: Monorepo Architecture

pnpm workspaces enable future evolution:
- Extract `cloudwatch-fixture-extractor` as standalone package (#102)
- Extract `electrodb-dynamodb-adapter` for Better Auth (#85)
- Share ElectroDB entities across multiple projects
- Dependency isolation per Lambda package

## Configuration Files

### .npmrc (Security Hardening)

Located at project root with security-first settings:

```ini
# SECURITY: Disable all lifecycle scripts by default
enable-pre-post-scripts=false

# Explicitly allowlist packages requiring scripts (AUDIT BEFORE ADDING)
# Expected: NONE for this project (all pure JS/TS dependencies)
# pnpm.onlyBuiltDependencies[]=package-name

# PERFORMANCE: Use hard links (faster, disk-efficient)
package-import-method=hardlink

# Strict peer dependencies (catch compatibility issues)
strict-peer-dependencies=false

# Hoist pattern (compatibility with some tools)
shamefully-hoist=false
```

### pnpm-workspace.yaml (Future Monorepo)

Located at project root for future workspace support:

```yaml
packages:
  - 'packages/*'
  - 'apps/*'
```

Currently unused but positions project for growth.

## Usage

### Installation

```bash
# Install pnpm globally
npm install -g pnpm

# Install project dependencies
pnpm install

# Frozen lockfile for CI (like npm ci)
pnpm install --frozen-lockfile
```

### Common Commands

All npm commands work with pnpm by replacing `npm` with `pnpm`:

```bash
# Build
pnpm run build          # Was: npm run build

# Test
pnpm test               # Was: npm test
pnpm run test:integration  # Was: npm run test:integration

# Deploy
pnpm run deploy         # Was: npm run deploy

# Format
pnpm run format         # Was: npm run format

# Add dependency
pnpm add package-name   # Was: npm install package-name

# Add dev dependency
pnpm add -D package-name  # Was: npm install --save-dev package-name

# Production install
pnpm install --prod     # Was: npm install --only=production
```

### CI/CD Usage

GitHub Actions workflows updated to use pnpm:

```yaml
- name: Setup pnpm
  uses: pnpm/action-setup@v4
  with:
    version: 10

- name: Setup Node.js
  uses: actions/setup-node@v4
  with:
    node-version-file: '.nvmrc'
    cache: 'pnpm'  # Changed from 'npm'

- name: Install dependencies
  run: pnpm install --frozen-lockfile  # Was: npm ci --ignore-scripts
```

## Security Best Practices

### Adding New Dependencies

When adding a new package that requires install scripts:

1. **Try installing** - pnpm will block and error if scripts needed
2. **Audit the package** - Check package code on npm/GitHub
3. **Verify legitimacy** - Ensure it's the correct package (not typosquatted)
4. **Review scripts** - Look at `package.json` scripts field
5. **Add to allowlist** (only if safe):
   ```ini
   # .npmrc
   pnpm.onlyBuiltDependencies[]=package-name
   ```

### Monitoring for Typosquatting

Be extra vigilant when:
- LLM suggests a package name
- Installing based on AI code suggestions
- Package name seems "close but not quite right"
- Error mentions blocked install scripts

**Always verify**:
- Package name spelling
- Package exists on npmjs.com
- Package has legitimate install scripts (most don't need them)
- Package maintainers and download counts

### Expected Behavior

**Current Project**: 
- **Zero packages should require install scripts**
- All dependencies are pure JS/TS (no native bindings)
- If script error occurs ‚Üí likely typosquatted package or incorrect name

**If Adding Native Dependencies** (future):
- esbuild (native binary compilation)
- sharp (image processing)
- canvas (native graphics)

These would need explicit allowlist after audit.

## Dependency Audit Results

**Audit Date**: November 24, 2025
**Total Packages**: 962 resolved packages
**Packages with Build Scripts**: 2 (core-js, esbuild)

### Identified Build Scripts

| Package | Version | Purpose | Required? | Action |
|---------|---------|---------|-----------|--------|
| `core-js` | 3.47.0 | Polyfills setup | ‚ùå No | Scripts blocked - dev dependency of redoc, not needed for runtime |
| `esbuild` | 0.25.12 | Native binary compilation | ‚ùå No | Scripts blocked - comes with prebuilt binaries for darwin-arm64 |

### Security Assessment

‚úÖ **Zero packages require install scripts for this project**
- All production dependencies are pure JavaScript/TypeScript
- Both packages with scripts are dev dependencies (redoc, tsx)
- Both work correctly without running install scripts
- Build and tests pass successfully with scripts blocked

### Verification Commands

```bash
# Check which packages have build scripts
pnpm list core-js esbuild

# Verify no production deps have scripts
pnpm why core-js  # Result: dev dependency (redoc)
pnpm why esbuild  # Result: dev dependency (tsx)

# Test that everything works
pnpm run build    # ‚úÖ Succeeds
pnpm test         # ‚úÖ 163 tests pass
```

### Conclusion

The security configuration (`enable-pre-post-scripts=false`) successfully blocks all install scripts without impacting functionality. The two packages that have scripts are:
1. Dev-only dependencies (not in production bundles)
2. Work correctly with prebuilt binaries/configurations

**No allowlist additions needed.** ‚úÖ

## Troubleshooting

### Script Blocked Error

**Error**:
```
ERR_PNPM_LIFECYCLE_SCRIPT_NOT_FOUND "package-name" tried to run a postinstall script
```

**Solution**:
1. Verify package name is correct (not typosquatted)
2. Check package on npmjs.com
3. If legitimate, audit script code
4. Add to `.npmrc` allowlist if safe

### Lock File Issues

**Error**: `ERR_PNPM_LOCKFILE_BREAKING_CHANGE`

**Solution**:
```bash
# Remove old lock file
rm pnpm-lock.yaml

# Reinstall
pnpm install
```

### Cache Issues

**Error**: Weird dependency resolution

**Solution**:
```bash
# Clear pnpm store
pnpm store prune

# Reinstall
pnpm install
```

### Peer Dependency Warnings

**Warning**: `WARN ... has unmet peer dependency`

**Solution**:
- Review warning - may need to install peer dependency
- If known safe, leave as warning (strict-peer-dependencies=false)
- If causing issues, set `strict-peer-dependencies=true` in `.npmrc`

## Migration Checklist

For future projects or contributors:

- [ ] Install pnpm globally: `npm install -g pnpm`
- [ ] Remove npm artifacts: `rm -rf node_modules package-lock.json`
- [ ] Create `.npmrc` with security settings
- [ ] Create `pnpm-workspace.yaml` (for future monorepo)
- [ ] Update `package.json` engines field
- [ ] Update CI/CD workflows to use pnpm
- [ ] Generate `pnpm-lock.yaml`: `pnpm import` or `pnpm install`
- [ ] Test build: `pnpm run build`
- [ ] Test unit tests: `pnpm test`
- [ ] Test integration: `pnpm run test:integration`
- [ ] Update documentation (README.md, AGENTS.md)
- [ ] Add `pnpm-lock.yaml` to git, exclude `.pnpm-store` in `.gitignore`

## Emergency Rollback

If the pnpm migration causes critical issues in production, follow these steps to revert:

### Rollback Procedure

1. **Revert the migration commits**:
   ```bash
   # Find the migration commits
   git log --oneline --grep="pnpm"

   # Revert the changes (replace with actual commit SHAs)
   git revert <commit-sha-1> <commit-sha-2>
   ```

2. **Remove pnpm artifacts**:
   ```bash
   rm -rf node_modules pnpm-lock.yaml .pnpm-store
   rm -f .npmrc pnpm-workspace.yaml
   rm -rf packages/ apps/
   ```

3. **Restore npm lock file** (if available in git history):
   ```bash
   git checkout <pre-migration-commit> -- package-lock.json
   ```

4. **Reinstall with npm**:
   ```bash
   npm install
   npm run build
   npm test
   ```

5. **Update CI/CD workflows**:
   - Revert `.github/workflows/unit-tests.yml` to use npm
   - Revert `.github/workflows/integration-tests.yml` to use npm
   - Remove `pnpm/action-setup` step
   - Change `cache: 'pnpm'` back to `cache: 'npm'`

6. **Update documentation**:
   - Revert `README.md` and `AGENTS.md` command examples
   - Remove `docs/wiki/Meta/pnpm-Migration.md`
   - Revert shell script references

7. **Update package.json scripts** (if modified):
   ```json
   {
     "build": "node --loader ts-node/esm ./node_modules/.bin/webpack-cli --config ./config/webpack.config.ts",
     "test": "node --no-warnings --experimental-vm-modules ./node_modules/.bin/jest --silent --config config/jest.config.mjs"
   }
   ```

### Rollback Verification

After rollback, verify everything works:

```bash
# Build should succeed
npm run build

# Tests should pass
npm test

# CI should be green
git push && # Check GitHub Actions
```

### When to Rollback

Consider rollback only if:
- ‚ùå CI/CD consistently fails despite fixes
- ‚ùå Production deployments break
- ‚ùå Critical dependency issues arise
- ‚ùå Team cannot adapt to pnpm workflow

**Note**: Minor issues (warnings, local setup) should not trigger rollback. The security benefits outweigh minor friction.

## References

- **pnpm Security**: https://pnpm.io/cli/install#--ignore-scripts
- **pnpm v10 Release**: https://github.com/pnpm/pnpm/releases/tag/v10.0.0
- **Supply Chain Security**: https://slsa.dev/
- **Content-Addressable Storage**: https://pnpm.io/symlinked-node-modules-structure
- **Original Discussion**: [HN - AI-Targeted Package Typosquatting](https://news.ycombinator.com/item?id=42451576)

## Benefits Summary

**Security**:
- ‚úÖ Defense against AI-targeted typosquatting
- ‚úÖ Explicit consent for code execution
- ‚úÖ Audit window before script execution
- ‚úÖ 100% visibility into script dependencies

**Performance**:
- ‚úÖ 50-66% faster CI/CD installs
- ‚úÖ 40-60% disk space savings
- ‚úÖ Content-addressable storage (integrity verification)
- ‚úÖ Faster local development

**Architecture**:
- ‚úÖ Monorepo-ready with workspaces
- ‚úÖ Strict dependency resolution (no phantom deps)
- ‚úÖ Better organization for future growth

**The time invested in this migration is a proactive defense against existential security threats while accelerating development velocity.**
# Convention Over Configuration

## Quick Reference
- **When to use**: All development decisions and architectural choices
- **Enforcement**: Philosophy, code reviews, established patterns
- **Impact if violated**: LOW - Increased complexity, inconsistency, maintenance burden

## Overview

Prefer established patterns with sensible defaults over flexible configuration. This principle reduces decision fatigue, improves consistency, speeds development, and makes the codebase more predictable.

## The Rules

1. **Use Project Defaults** - Don't configure what already has a sensible default
2. **Follow Established Patterns** - Use existing patterns before creating new ones
3. **Minimize Configuration Files** - Avoid proliferation of config files when conventions suffice
4. **Document Exceptions** - When configuration is necessary, document why the convention doesn't work

## Examples

### ‚úÖ Correct - Using Convention for Lambda Handlers

```typescript
// src/lambdas/ListFiles/src/index.ts

// Standard Lambda pattern - no configuration needed
import {lambdaErrorResponse, response, logInfo, getUserDetailsFromEvent} from '../../../util/lambda-helpers'
import {withXRay} from '../../../lib/vendor/AWS/XRay'
import {Files} from '../../../entities/Files'

export const handler = withXRay(async (event, context, {traceId}) => {
  logInfo('event <=', event)  // Standard logging pattern

  try {
    const {userId, userStatus} = getUserDetailsFromEvent(event)
    const files = await getFilesByUser(userId)

    // Standard success response
    return response(context, 200, {contents: files, keyCount: files.length})
  } catch (error) {
    // Standard error handling for API Gateway
    return lambdaErrorResponse(context, error)
  }
})
```

### ‚úÖ Correct - Standard File Structure

```
src/lambdas/FunctionName/
‚îú‚îÄ‚îÄ src/index.ts       # Convention: handler always here
‚îú‚îÄ‚îÄ test/index.test.ts # Convention: test mirrors source
‚îî‚îÄ‚îÄ fixtures/          # Convention: test data location
    ‚îî‚îÄ‚îÄ event.json

terraform/LambdaFunctionName.tf  # Convention: PascalCase matches function
```

No configuration needed - the structure itself is the convention.

### ‚ùå Incorrect - Over-Configuration

```typescript
// ‚ùå Custom configuration for standard behavior
const lambdaConfig = {
  errorHandler: customErrorHandler,
  responseFormatter: customResponseFormatter,
  loggingLevel: 'custom',
  timeout: 30,
  retryPolicy: customRetryPolicy
}

export const handler = createCustomHandler(lambdaConfig, async (event) => {
  // Now we need to maintain this custom configuration
})
```

Problems: Configuration duplicates what conventions provide, custom patterns when standard ones work.

### ‚ùå Incorrect - Configuration Files for Standard Behavior

```json
// ‚ùå lambda-config.json (unnecessary)
{
  "handlers": {
    "ProcessFile": {
      "path": "src/lambdas/ProcessFile/src/index.ts",
      "handler": "handler",
      "runtime": "nodejs22.x"
    }
  }
}
```

Instead: Use convention that all Lambdas follow the same structure.

## Real Project Examples

### Lambda Conventions

```typescript
// Convention: All API Gateway Lambdas return responses
// No need to configure response vs throw behavior
if (isApiGatewayLambda) {
  return response(context, statusCode, body)
} else {
  throw error  // Event-driven Lambdas throw for retry
}
```

### Testing Conventions

```typescript
// Convention: Test files mirror source files
src/lambdas/ProcessFile/src/index.ts
src/lambdas/ProcessFile/test/index.test.ts

// Convention: Fixtures in standard location
src/lambdas/ProcessFile/test/fixtures/event.json
```

### Infrastructure Conventions

```hcl
# Convention: Resource names match TypeScript names
resource "aws_lambda_function" "ProcessFile" {
  function_name = "ProcessFile"  # No configuration mapping needed
}
```

## When Configuration IS Appropriate

### Environment-Specific Settings

```typescript
// ‚úÖ Configuration for environment differences
const config = {
  apiUrl: process.env.API_URL,  // Varies by environment
  region: process.env.AWS_REGION || 'us-west-2'
}
```

### Security and Secrets

```typescript
// ‚úÖ Configuration for sensitive data
const config = {
  apiKey: process.env.API_KEY,  // Can't be hardcoded
  certificatePath: process.env.CERT_PATH
}
```

## Benefits

### Reduced Cognitive Load
- Developers don't need to make decisions already made
- New team members learn one way of doing things
- Less documentation needed

### Faster Development
- No time spent on configuration
- Copy existing patterns
- Focus on business logic

### Better Consistency
- All code follows same patterns
- Predictable structure
- Easier code reviews

## Implementation Guidelines

1. **Establish Conventions Early** - Define patterns at project start
2. **Document Conventions** - Create wiki pages for each convention
3. **Enforce Through Code Review** - Check that code follows established patterns
4. **Automate Where Possible** - ESLint rules for project conventions

## Related Patterns

- [Lambda Function Patterns](../TypeScript/Lambda-Function-Patterns.md) - Standard Lambda conventions
- [Naming Conventions](../Conventions/Naming-Conventions.md) - Consistent naming patterns
- [Testing Patterns](../Testing/Jest-ESM-Mocking-Strategy.md) - Test conventions

---

*Choose convention over configuration. Make the easy path the right path.*
# Library Migration Checklist

## Quick Reference
- **When to use**: Replacing major libraries
- **Enforcement**: Required for breaking changes
- **Impact if violated**: HIGH - Production failures

## Migration Phases

### 1. Planning
- Document current usage: `grep -r "old-library" src/`
- Check feature parity
- Review breaking changes

### 2. Parallel Implementation
```typescript
// lib/vendor/Wrapper.ts
export function getClient() {
  if (process.env.USE_NEW) {
    return newLibrary.create()
  }
  return oldLibrary.create()
}
```

### 3. Incremental Migration
- [ ] Install new library alongside old
- [ ] Create vendor wrapper with flag
- [ ] Migrate one Lambda at a time
- [ ] Test in staging
- [ ] Monitor metrics

### 4. Validation
- [ ] Unit tests pass
- [ ] Integration tests pass
- [ ] Performance acceptable
- [ ] No memory leaks

### 5. Cleanup
- [ ] Remove feature flag
- [ ] Uninstall old library
- [ ] Update documentation

## Common Migrations

### AWS SDK v2 ‚Üí v3
```bash
npm uninstall aws-sdk
npm install @aws-sdk/client-*
# Update webpack externals
```

### Jest Major Version
```bash
npm update jest @jest/globals @types/jest
# Check migration guide for config changes
```

### ElectroDB Updates
```bash
npm update electrodb
# Test all entity queries
```

## Rollback Strategy

1. Keep old library during migration
2. Use environment variable switch
3. Monitor error rates
4. Quick revert if needed

## Testing Requirements

‚úÖ All unit tests pass
‚úÖ Integration tests with LocalStack
‚úÖ Load testing completed
‚úÖ Error handling verified
‚úÖ Rollback tested

## Related Patterns

- [Dependabot Resolution](Dependabot-Resolution.md)
- [Vendor Wrappers](../AWS/SDK-Encapsulation-Policy.md)

---

*Migrate gradually with feature flags and vendor wrappers.*# Dependabot Resolution

## Quick Reference
- **When to use**: Handling dependency updates
- **Enforcement**: Automated via GitHub Actions
- **Impact if violated**: MEDIUM - Security vulnerabilities

## Auto-Merge Rules

### ‚úÖ Auto-Merge When
- Patch version (x.x.PATCH)
- All tests passing
- Dev dependencies only
- No breaking changes

### üîç Manual Review When
- Minor/major versions
- Production dependencies
- AWS SDK updates
- Security alerts

## Resolution Process

```bash
# 1. Check what changed
npm outdated
npm audit

# 2. Update and test
npm update <package>
npm test
npm run build

# 3. Verify
npm audit fix
git commit -m "chore(deps): update <package>"
```

## Common Issues

| Update Type | Action |
|------------|--------|
| Security alert | Fix immediately |
| Major version | Check migration guide |
| Type errors | Update @types packages |
| AWS SDK | Update all @aws-sdk/* together |
| Jest | Update all jest packages together |

## AWS SDK Special Handling

```bash
# Update all AWS packages
npm update @aws-sdk/client-*

# Add new services to webpack externals
externals: ['@aws-sdk/client-new-service']
```

## Priority Levels

1. **Critical Security** - Fix immediately
2. **High Security** - Within 24 hours
3. **Production Deps** - Within week
4. **Dev Dependencies** - Next sprint

## Related Patterns

- [Library Migration](Library-Migration-Checklist.md)
- [Testing Strategy](../Testing/Jest-ESM-Mocking-Strategy.md)

---

*Auto-merge patch updates. Review minor/major versions and production dependencies.*# Production Debugging

## Quick Reference
- **When to use**: Investigating production issues
- **Enforcement**: Recommended
- **Impact if violated**: MEDIUM - Longer resolution time

## Debugging Tools

1. **CloudWatch Logs** - Real-time logs and search
2. **X-Ray** - Distributed tracing (via withXRay wrapper)
3. **CloudWatch Insights** - SQL-like log analysis
4. **GitHub Issues** - Automated error reporting

## Common Issues & Solutions

### Lambda Timeout
```sql
-- CloudWatch Insights query
fields @timestamp, @duration, @message
| filter @message like /Task timed out/
| stats max(@duration) as max_duration
```

**Fix**: Use parallel processing with `Promise.all()` instead of serial loops

### Memory Exhaustion
```sql
-- Check memory usage
fields @timestamp, @maxMemoryUsed/@memorySize as memory_percentage
| filter @type = "REPORT" and memory_percentage > 0.9
```

**Fix**: Stream large files instead of loading into memory

### DynamoDB Throttling
```sql
-- Find throttled requests
fields @timestamp, @message
| filter @message like /ProvisionedThroughputExceededException/
| stats count() by bin(@timestamp, 5m)
```

**Fix**: Implement exponential backoff and batch operations

### API Gateway 502 Errors
```sql
-- Find integration failures
fields @timestamp, method, resource
| filter status = 502
| stats count() by resource
```

**Fix**: Ensure Lambda returns proper API Gateway response format

## X-Ray Integration

All Lambdas use the withXRay wrapper for automatic tracing:

```typescript
export const handler = withXRay(async (event, context, {traceId}) => {
  logInfo('event <=', event)
  // traceId available for correlation
})
```

## Quick Commands

```bash
# Recent errors
aws logs filter-log-events \
  --log-group-name /aws/lambda/FunctionName \
  --filter-pattern ERROR

# X-Ray traces
aws xray get-trace-summaries \
  --time-range-type LastHour \
  --query "TraceSummaries[?ErrorRootCauses]"

# Lambda metrics
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name Errors \
  --dimensions Name=FunctionName,Value=ProcessFile
```

## Performance Optimization

1. **Cold Starts** - Check duration for first invocation
2. **Memory Allocation** - Monitor @maxMemoryUsed
3. **Concurrent Executions** - Check throttling metrics
4. **External API Calls** - Add timeouts and retries

## Error Patterns

| Error | Cause | Solution |
|-------|-------|----------|
| Task timed out | Long-running operation | Increase timeout or optimize |
| Runtime exited | Memory exhaustion | Increase memory or stream data |
| AccessDenied | IAM permissions | Check Lambda execution role |
| ECONNREFUSED | Network issue | Verify endpoints and security groups |

## Related Patterns

- [CloudWatch Logging](../AWS/CloudWatch-Logging.md) - Logging setup
- [X-Ray Integration](../AWS/X-Ray-Integration.md) - Tracing details
- [Error Handling](../TypeScript/TypeScript-Error-Handling.md) - Error patterns

---

*Use CloudWatch Insights for log analysis, X-Ray for tracing, and monitor key metrics for production debugging.*# MCP Convention Tools

## Quick Reference
- **When to use**: AI assistants querying project conventions and validating code
- **Enforcement**: Automated via MCP server and optional CI integration
- **Impact if violated**: Varies by rule severity (CRITICAL to LOW)

## Overview

The MCP server provides 5 tools for convention querying and code validation:

| Tool | Purpose | Primary Use Case |
|------|---------|-----------------|
| `query_conventions` | Search project conventions | Understanding rules before coding |
| `validate_pattern` | AST-based code validation | Checking code against conventions |
| `check_coverage` | Mock analysis for tests | Identifying required Jest mocks |
| `lambda_impact` | Dependency impact analysis | Understanding change scope |
| `suggest_tests` | Test scaffolding generation | Creating new test files |

## Tool Details

### query_conventions

Search and filter project conventions from `docs/conventions-tracking.md` and wiki pages.

**Query Types:**
- `list` - List all conventions grouped by severity
- `search` - Full-text search across conventions and wiki
- `category` - Filter by category (testing, aws, typescript, etc.)
- `enforcement` - Filter by severity (CRITICAL, HIGH, MEDIUM, LOW)
- `detail` - Get full details for a specific convention
- `wiki` - List or search wiki documentation

**Examples:**
```typescript
// Find all testing conventions
query_conventions({ query: "category", category: "testing" })

// Search for mock-related conventions
query_conventions({ query: "search", term: "mock" })

// Get CRITICAL rules that must not be violated
query_conventions({ query: "enforcement", severity: "CRITICAL" })
```

### validate_pattern

Validate TypeScript files against project conventions using AST analysis (ts-morph).

**Query Types:**
- `rules` - List all available validation rules
- `all` - Run all applicable validations on a file
- `summary` - Concise validation summary
- **CRITICAL Rules:**
  - `aws-sdk` - Check AWS SDK encapsulation
  - `electrodb` - Check ElectroDB mocking patterns
  - `config` - Check for configuration drift
  - `env` - Check environment variable validation
  - `cascade` - Check cascade deletion safety
- **HIGH Rules:**
  - `response` - Check response helper usage
  - `types` - Check exported type location
  - `batch` - Check batch operation retry handling
  - `scan` - Check scan pagination handling
- **HIGH Rules (documentation):**
  - `docs` - Check documentation sync with codebase
- **MEDIUM Rules:**
  - `imports` - Check import ordering
  - `enum` - Check ResponseStatus enum usage
  - `mock` - Check mock formatting patterns

**Validation Rules:**

| Rule | Alias | Severity | Description |
|------|-------|----------|-------------|
| aws-sdk-encapsulation | aws-sdk | CRITICAL | No direct AWS SDK imports outside src/lib/vendor/AWS/ |
| electrodb-mocking | electrodb | CRITICAL | Test files must use createElectroDBEntityMock() |
| config-enforcement | config | CRITICAL | Detects configuration drift (e.g., ESLint allowing underscore vars) |
| env-validation | env | CRITICAL | Raw process.env access must use getRequiredEnv() wrapper |
| cascade-safety | cascade | CRITICAL | Promise.all with delete operations must use Promise.allSettled |
| response-helpers | response | HIGH | Lambda handlers must use response() helper |
| types-location | types | HIGH | Exported types must be in src/types/ directory |
| batch-retry | batch | HIGH | Batch operations must use retryUnprocessed() wrapper |
| scan-pagination | scan | HIGH | Scan operations must use scanAllPages() wrapper |
| import-order | imports | MEDIUM | Imports grouped: node ‚Üí aws-lambda ‚Üí external ‚Üí entities ‚Üí vendor ‚Üí types ‚Üí utilities ‚Üí relative |
| response-enum | enum | MEDIUM | Use ResponseStatus enum instead of magic strings |
| mock-formatting | mock | MEDIUM | Sequential mock returns should be separate statements |
| doc-sync | docs | HIGH | Documentation stays in sync with codebase |

**Examples:**
```typescript
// Full validation of a Lambda handler
validate_pattern({ file: "src/lambdas/ListFiles/src/index.ts", query: "all" })

// Check only AWS SDK encapsulation
validate_pattern({ file: "src/lambdas/ListFiles/src/index.ts", query: "aws-sdk" })

// List all available rules
validate_pattern({ query: "rules" })
```

### check_coverage

Analyze which dependencies need mocking for Jest tests using build/graph.json.

**Query Types:**
- `required` - List all dependencies that need mocking
- `missing` - Compare required mocks to existing test file
- `all` - Full analysis with categorization
- `summary` - Quick summary of mock requirements

**Dependency Categories:**
- **Entities**: ElectroDB entities (use createElectroDBEntityMock)
- **Vendors**: AWS SDK wrappers (lib/vendor/AWS/*)
- **Utilities**: Shared helpers (util/*)
- **External**: Third-party packages

**Examples:**
```typescript
// Get all mocks needed for a Lambda
check_coverage({ file: "src/lambdas/ListFiles/src/index.ts", query: "required" })

// Find missing mocks in existing test
check_coverage({ file: "src/lambdas/ListFiles/src/index.ts", query: "missing" })
```

### lambda_impact

Show what's affected by changing a file - dependents, tests, and infrastructure.

**Query Types:**
- `dependents` - Direct files that import this file
- `cascade` - Full transitive dependency cascade
- `tests` - Test files that need updating
- `infrastructure` - Terraform files that may be affected
- `all` - Comprehensive impact analysis

**Examples:**
```typescript
// See what's affected by changing an entity
lambda_impact({ file: "src/entities/Files.ts", query: "cascade" })

// Find tests that need updating
lambda_impact({ file: "src/util/lambda-helpers.ts", query: "tests" })

// Full impact analysis
lambda_impact({ file: "src/entities/Users.ts", query: "all" })
```

### suggest_tests

Generate test file scaffolding with all required mocks based on dependency analysis.

**Query Types:**
- `scaffold` - Complete test file with all mocks
- `mocks` - Just the mock setup section
- `fixtures` - Suggested test fixtures
- `structure` - Test structure outline (describe/it blocks)

**Examples:**
```typescript
// Generate complete test file
suggest_tests({ file: "src/lambdas/NewLambda/src/index.ts", query: "scaffold" })

// Get just the mock setup
suggest_tests({ file: "src/lambdas/NewLambda/src/index.ts", query: "mocks" })
```

## CI Integration

The validation rules in `src/mcp/validation/` are designed for reuse in CI pipelines:

```typescript
import { validateFile, allRules } from './src/mcp/validation/index.js'

// Validate a file
const result = await validateFile('src/lambdas/ListFiles/src/index.ts')

// Check for CRITICAL violations
const critical = result.violations.filter(v => v.severity === 'CRITICAL')
if (critical.length > 0) {
  process.exit(1)
}
```

## Architecture

```
src/mcp/
‚îú‚îÄ‚îÄ server.ts              # MCP server with tool definitions
‚îú‚îÄ‚îÄ README.md              # Tool documentation
‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îú‚îÄ‚îÄ conventions.ts     # query_conventions handler
‚îÇ   ‚îú‚îÄ‚îÄ coverage.ts        # check_coverage handler
‚îÇ   ‚îú‚îÄ‚îÄ validation.ts      # validate_pattern handler
‚îÇ   ‚îú‚îÄ‚îÄ impact.ts          # lambda_impact handler
‚îÇ   ‚îú‚îÄ‚îÄ test-scaffold.ts   # suggest_tests handler
‚îÇ   ‚îî‚îÄ‚îÄ data-loader.ts     # Shared data loading with caching
‚îú‚îÄ‚îÄ parsers/
‚îÇ   ‚îî‚îÄ‚îÄ convention-parser.ts  # Convention file parser
‚îî‚îÄ‚îÄ validation/
    ‚îú‚îÄ‚îÄ types.ts           # Shared validation types
    ‚îú‚îÄ‚îÄ index.ts           # Unified validation interface
    ‚îî‚îÄ‚îÄ rules/
        ‚îú‚îÄ‚îÄ aws-sdk-encapsulation.ts  # CRITICAL
        ‚îú‚îÄ‚îÄ electrodb-mocking.ts      # CRITICAL
        ‚îú‚îÄ‚îÄ config-enforcement.ts     # CRITICAL
        ‚îú‚îÄ‚îÄ env-validation.ts         # CRITICAL
        ‚îú‚îÄ‚îÄ cascade-safety.ts         # CRITICAL
        ‚îú‚îÄ‚îÄ response-helpers.ts       # HIGH
        ‚îú‚îÄ‚îÄ types-location.ts         # HIGH
        ‚îú‚îÄ‚îÄ batch-retry.ts            # HIGH
        ‚îú‚îÄ‚îÄ scan-pagination.ts        # HIGH
        ‚îú‚îÄ‚îÄ doc-sync.ts               # HIGH (documentation)
        ‚îú‚îÄ‚îÄ import-order.ts           # MEDIUM
        ‚îú‚îÄ‚îÄ response-enum.ts          # MEDIUM
        ‚îî‚îÄ‚îÄ mock-formatting.ts        # MEDIUM
```

## Related Documentation

- [Dependency Graph Analysis](../Testing/Dependency-Graph-Analysis.md) - build/graph.json usage
- [Jest ESM Mocking Strategy](../Testing/Jest-ESM-Mocking-Strategy.md) - Mocking patterns
- [SDK Encapsulation Policy](../AWS/SDK-Encapsulation-Policy.md) - AWS SDK rules
- [ElectroDB Testing Patterns](../Testing/ElectroDB-Testing-Patterns.md) - Entity mocking

---

*Use these MCP tools to understand and validate code against project conventions before implementation.*
# Apple Sign In ID Token Migration

## Overview

As of November 2024, the backend API has migrated from Apple's authorization code flow to direct ID token authentication using Better Auth's OAuth capabilities. This eliminates the need for a server-side token exchange and reduces authentication latency by 200-500ms.

## What Changed

### Before (Authorization Code Flow)
```
iOS App ‚Üí Sign in with Apple ‚Üí Authorization Code ‚Üí Backend API
                                                    ‚Üì
                                     Token Exchange with Apple
                                                    ‚Üì
                                              User Session
```

### After (ID Token Flow)
```
iOS App ‚Üí Sign in with Apple ‚Üí ID Token ‚Üí Backend API
                                            ‚Üì
                                  Better Auth Verification
                                            ‚Üì
                                      User Session
```

## API Contract Changes

### RegisterUser Endpoint

**Old Request Format:**
```json
{
  "authorizationCode": "c1234567890abcdef",
  "firstName": "Jonathan",
  "lastName": "Lloyd"
}
```

**New Request Format:**
```json
{
  "idToken": "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...",
  "firstName": "Jonathan",
  "lastName": "Lloyd"
}
```

### LoginUser Endpoint

**Old Request Format:**
```json
{
  "authorizationCode": "c1234567890abcdef"
}
```

**New Request Format:**
```json
{
  "idToken": "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9..."
}
```

## iOS Implementation Guide

### Accessing the ID Token

When using `ASAuthorizationController` for Sign in with Apple, the ID token is available in the authorization credential response:

```swift
func authorizationController(controller: ASAuthorizationController,
                            didCompleteWithAuthorization authorization: ASAuthorization) {
    if let appleIDCredential = authorization.credential as? ASAuthorizationAppleIDCredential {
        // Get the ID token (this is what we need!)
        guard let identityTokenData = appleIDCredential.identityToken,
              let identityToken = String(data: identityTokenData, encoding: .utf8) else {
            print("Unable to fetch identity token")
            return
        }

        // Get user's full name (only available on first sign-in)
        let firstName = appleIDCredential.fullName?.givenName ?? ""
        let lastName = appleIDCredential.fullName?.familyName ?? ""

        // Determine if this is a new user (first sign-in)
        let isNewUser = appleIDCredential.fullName?.givenName != nil

        if isNewUser {
            // Call RegisterUser endpoint
            registerUser(idToken: identityToken,
                        firstName: firstName,
                        lastName: lastName)
        } else {
            // Call LoginUser endpoint
            loginUser(idToken: identityToken)
        }
    }
}
```

### RegisterUser API Call

```swift
func registerUser(idToken: String, firstName: String, lastName: String) {
    let url = URL(string: "\(baseURL)/registerUser")!
    var request = URLRequest(url: url)
    request.httpMethod = "POST"
    request.setValue("application/json", forHTTPHeaderField: "Content-Type")

    let body: [String: Any] = [
        "idToken": idToken,
        "firstName": firstName,
        "lastName": lastName
    ]

    request.httpBody = try? JSONSerialization.data(withJSONObject: body)

    URLSession.shared.dataTask(with: request) { data, response, error in
        guard let data = data, error == nil else {
            print("Registration failed: \(error?.localizedDescription ?? "Unknown error")")
            return
        }

        // Parse response
        if let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
           let body = json["body"] as? [String: Any],
           let token = body["token"] as? String,
           let expiresAt = body["expiresAt"] as? Double,
           let sessionId = body["sessionId"] as? String,
           let userId = body["userId"] as? String {

            // Save session token for authenticated requests
            saveSessionToken(token: token, expiresAt: expiresAt,
                           sessionId: sessionId, userId: userId)
        }
    }.resume()
}
```

### LoginUser API Call

```swift
func loginUser(idToken: String) {
    let url = URL(string: "\(baseURL)/login")!
    var request = URLRequest(url: url)
    request.httpMethod = "POST"
    request.setValue("application/json", forHTTPHeaderField: "Content-Type")

    let body: [String: Any] = [
        "idToken": idToken
    ]

    request.httpBody = try? JSONSerialization.data(withJSONObject: body)

    URLSession.shared.dataTask(with: request) { data, response, error in
        guard let data = data, error == nil else {
            print("Login failed: \(error?.localizedDescription ?? "Unknown error")")
            return
        }

        // Parse response (same format as RegisterUser)
        if let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
           let body = json["body"] as? [String: Any],
           let token = body["token"] as? String,
           let expiresAt = body["expiresAt"] as? Double,
           let sessionId = body["sessionId"] as? String,
           let userId = body["userId"] as? String {

            // Save session token for authenticated requests
            saveSessionToken(token: token, expiresAt: expiresAt,
                           sessionId: sessionId, userId: userId)
        }
    }.resume()
}
```

## Important Notes

### ID Token vs Authorization Code

- **ID Token**: A JWT containing user identity claims (email, sub, etc.). Available immediately after Apple Sign In.
- **Authorization Code**: A one-time code that must be exchanged for tokens via Apple's token endpoint. This is what we used before.

### Name Availability

Apple's privacy design means:
1. `fullName` is ONLY populated on the first sign-in
2. Subsequent sign-ins will have `nil` for `fullName`
3. The ID token does NOT contain first/last name for privacy reasons
4. This is why we send name separately in the RegisterUser request

The backend detects new users (created within last 5 seconds) and updates their name from the iOS app's request.

### Token Security

- ID tokens are short-lived (typically 10 minutes)
- They are signed by Apple using RS256 algorithm
- Better Auth verifies the signature using Apple's public JWKS
- Never cache or store ID tokens - they are single-use for authentication

### Session Management

Both RegisterUser and LoginUser return the same session response format:

```json
{
  "body": {
    "token": "session-token-string",
    "expiresAt": 1234567890000,
    "sessionId": "uuid-session-id",
    "userId": "uuid-user-id"
  }
}
```

Use the `token` value for subsequent authenticated API requests via the `Authorization` header:

```swift
request.setValue("Bearer \(sessionToken)", forHTTPHeaderField: "Authorization")
```

## Migration Checklist

- [ ] Update RegisterUser calls to use `idToken` instead of `authorizationCode`
- [ ] Update LoginUser calls to use `idToken` instead of `authorizationCode`
- [ ] Extract ID token from `ASAuthorizationAppleIDCredential.identityToken`
- [ ] Remove any authorization code handling logic
- [ ] Test new user registration flow
- [ ] Test existing user login flow
- [ ] Verify session token handling remains unchanged
- [ ] Update any error handling for new API contract

## Benefits

1. **Reduced Latency**: Eliminates 200-500ms token exchange round trip to Apple
2. **Simpler Flow**: Direct token verification vs. two-step exchange
3. **Better Auth Integration**: Leverages Better Auth's built-in OAuth capabilities
4. **Same Security**: ID token verification is cryptographically equivalent to authorization code flow

## Troubleshooting

### "Invalid ID token" Error

Check that you're using `identityToken` not `authorizationCode`:
```swift
// Correct
let identityToken = String(data: appleIDCredential.identityToken!, encoding: .utf8)

// Wrong
let authCode = String(data: appleIDCredential.authorizationCode!, encoding: .utf8)
```

### Name Not Saved for New Users

Ensure you're:
1. Checking if `fullName` is populated (indicates new user)
2. Sending `firstName` and `lastName` in RegisterUser request
3. Calling RegisterUser, not LoginUser, for new users

### Session Token Not Working

Verify the response format hasn't changed - both endpoints return identical session structure.

## References

- [Apple Sign In Documentation](https://developer.apple.com/documentation/sign_in_with_apple)
- [ASAuthorizationAppleIDCredential](https://developer.apple.com/documentation/authenticationservices/asauthorizationappleidcredential)
- [Better Auth OAuth Provider](https://www.better-auth.com/docs/authentication/oauth)
# Bash Error Handling

## Quick Reference
- **When to use**: All bash scripts
- **Enforcement**: Required
- **Impact if violated**: CRITICAL - Silent failures

## Standard Setup

```bash
#!/usr/bin/env bash
set -euo pipefail

# Error handler
error() {
  echo "‚ùå Error: $1" >&2
  exit "${2:-1}"
}

# Cleanup trap
cleanup() {
  rm -f "$temp_file"
}
trap cleanup EXIT ERR
```

## Error Handling Patterns

### Expected Failures
```bash
# Use || true for optional commands
rm file.txt 2>/dev/null || true

# Conditional handling
if ! command_that_might_fail; then
  echo "Failed, trying alternative"
  alternative_command || error "Both failed"
fi
```

### Validation
```bash
# Check variables
[[ -z "${VAR:-}" ]] && error "VAR is required"

# Check files
[[ -f "$file" ]] || error "File not found: $file"

# Check commands
command -v aws >/dev/null || error "AWS CLI not installed"
```

### AWS CLI Errors
```bash
# Capture and check
if output=$(aws lambda invoke --function test 2>&1); then
  echo "‚úÖ Success"
else
  error "AWS failed: $output"
fi
```

## Best Practices

‚úÖ Always use `set -euo pipefail`
‚úÖ Provide context in errors
‚úÖ Clean up with traps
‚úÖ Use stderr for errors: `>&2`
‚úÖ Check dependencies first

## Exit Codes

| Code | Meaning |
|------|---------|
| 0 | Success |
| 1 | General error |
| 2 | Missing dependency |
| 3 | AWS operation failed |

## Related Patterns

- [Script Patterns](Script-Patterns.md)
- [Directory Resolution](Directory-Resolution.md)

---

*Use strict error handling. Fail fast with clear messages.*# Directory Resolution

## Quick Reference
- **When to use**: All Bash scripts that need to know their location
- **Enforcement**: Required - ensures scripts work from any directory
- **Impact if violated**: HIGH - Scripts fail when run from different locations

## The Rule

Use this standard pattern at the top of every script:

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
```

## Examples

### ‚úÖ Correct - Standard Pattern

```bash
#!/usr/bin/env bash

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"

# Now we can reliably reference project files
SOURCE_DIR="${PROJECT_ROOT}/src"
BUILD_DIR="${PROJECT_ROOT}/build"

cd "${PROJECT_ROOT}"
npm run build
```

### ‚ùå Incorrect - Using $0 or Relative Paths

```bash
# ‚ùå WRONG - Fails when script is sourced
script_dir="$(cd "$(dirname "$0")" && pwd)"

# ‚ùå WRONG - Breaks when run from different directory
cd ../src
npm run build

# ‚úÖ CORRECT
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
cd "${PROJECT_ROOT}/src"
```

## Why This Pattern Works

### BASH_SOURCE[0] vs $0

- `$0` fails when script is sourced (returns shell name)
- `$0` doesn't resolve symlinks properly
- `BASH_SOURCE[0]` works in all contexts (direct, sourced, symlinked)

### Quotes Handle Spaces

```bash
# ‚ùå WRONG - Breaks with spaces in path
SCRIPT_DIR=$(cd $(dirname ${BASH_SOURCE[0]}) && pwd)

# ‚úÖ CORRECT - Handles spaces
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
```

## Common Use Cases

### Scripts in bin/

```bash
#!/usr/bin/env bash
# bin/deploy.sh

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"

SRC_DIR="${PROJECT_ROOT}/src"
TERRAFORM_DIR="${PROJECT_ROOT}/terraform"
```

### Loading Configuration

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"

# Load config from same directory as script
if [[ -f "${SCRIPT_DIR}/config.sh" ]]; then
    source "${SCRIPT_DIR}/config.sh"
fi

# Load from project root
if [[ -f "${PROJECT_ROOT}/.env" ]]; then
    source "${PROJECT_ROOT}/.env"
fi
```

### Sourcing Utilities

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

source "${SCRIPT_DIR}/../lib/colors.sh"
source "${SCRIPT_DIR}/../lib/aws-helpers.sh"
```

## Template for New Scripts

```bash
#!/usr/bin/env bash

set -e  # Exit on error

# Directory resolution
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"

# Constants
RED='\033[0;31m'
GREEN='\033[0;32m'
NC='\033[0m'

# Main script logic
echo "Project root: ${PROJECT_ROOT}"
```

## Enforcement

### Code Review Checklist

- [ ] All scripts use BASH_SOURCE[0]
- [ ] Directory resolution at top of script
- [ ] All paths quoted to handle spaces
- [ ] No relative paths without resolution

## Related Patterns

- [Variable Naming](Variable-Naming.md) - UPPER_CASE for path constants
- [Script Patterns](Script-Patterns.md) - Overall script structure

---

*Always use BASH_SOURCE[0] with cd and pwd for directory resolution. This ensures scripts work correctly regardless of how they're invoked or where they're run from.*
# User Output Formatting

## Quick Reference
- **When to use**: All user-facing script output
- **Enforcement**: Recommended
- **Impact if violated**: LOW - Less readable output

## Color Definitions

```bash
#!/usr/bin/env bash

# Define at script top
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'  # No Color - always reset
```

## Output Functions

```bash
# Success message
success() {
  echo -e "${GREEN}‚úì${NC} $1"
}

# Error message
error() {
  echo -e "${RED}‚úó${NC} $1" >&2
}

# Warning message
warning() {
  echo -e "${YELLOW}‚ö†${NC} $1"
}

# Info message
info() {
  echo -e "${BLUE}‚ûú${NC} $1"
}

# Usage
success "Build completed"
error "Build failed"
warning "Using default config"
info "Starting deployment"
```

## Progress Indicators

```bash
# Step counter
STEP=1
TOTAL=5

step() {
  echo -e "${BLUE}[${STEP}/${TOTAL}]${NC} $1"
  ((STEP++))
}

# Usage
step "Installing dependencies"
step "Running tests"
step "Building project"
```

## Semantic Formatting

| Type | Color | Symbol | Usage |
|------|-------|--------|-------|
| Success | Green | ‚úì | Operation completed |
| Error | Red | ‚úó | Operation failed |
| Warning | Yellow | ‚ö† | Caution needed |
| Info | Blue | ‚ûú | General information |

## AWS CLI Output

```bash
# Format AWS output
echo -e "${GREEN}‚úì${NC} Lambda deployed: ${BLUE}${function_name}${NC}"
echo -e "${GREEN}‚úì${NC} S3 bucket: ${BLUE}${bucket_name}${NC}"
```

## Best Practices

‚úÖ Define colors once at top
‚úÖ Always reset color with `${NC}`
‚úÖ Use stderr for errors: `>&2`
‚úÖ Be consistent with symbols
‚úÖ Keep messages concise

## Related Patterns

- [Error Handling](Bash-Error-Handling.md)
- [Script Patterns](Script-Patterns.md)

---

*Use colors and symbols for clear, scannable output.*# Bash Script Patterns

## Quick Reference
- **When to use**: All bash scripts
- **Enforcement**: Required
- **Impact if violated**: MEDIUM - Inconsistent scripts

## Script Structure

```bash
#!/usr/bin/env bash
set -euo pipefail

# Color definitions
RED='\033[0;31m'
GREEN='\033[0;32m'
NC='\033[0m'

# Directory resolution
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"

# Main logic
main() {
  echo -e "${GREEN}‚úì${NC} Starting..."
  # Script logic here
}

# Run main
main "$@"
```

## Error Handling

```bash
set -euo pipefail  # Exit on error, undefined vars, pipe failures

# Error function
error() {
  echo -e "${RED}‚úó${NC} Error: $1" >&2
  exit "${2:-1}"
}

# Usage
command || error "Command failed" 2
```

## Variable Naming

```bash
# Regular variables - snake_case
local file_path="./data.json"
local user_count=0

# Environment/Constants - UPPER_SNAKE_CASE
export AWS_REGION="us-west-2"
readonly MAX_RETRIES=3

# Colors - UPPERCASE
RED='\033[0;31m'
GREEN='\033[0;32m'
```

## Function Patterns

```bash
# Function naming - snake_case
deploy_lambda() {
  local function_name="$1"
  local zip_file="$2"

  echo -e "${BLUE}‚ûú${NC} Deploying ${function_name}..."

  aws lambda update-function-code \
    --function-name "$function_name" \
    --zip-file "fileb://${zip_file}" \
    || error "Lambda deployment failed"

  echo -e "${GREEN}‚úì${NC} Deployed successfully"
}
```

## Common Patterns

### Check Dependencies
```bash
command -v aws >/dev/null || error "AWS CLI not installed"
command -v npm >/dev/null || error "npm not installed"
```

### Parse Arguments
```bash
while [[ $# -gt 0 ]]; do
  case $1 in
    --env) ENV="$2"; shift 2 ;;
    --help) show_help; exit 0 ;;
    *) error "Unknown option: $1" ;;
  esac
done
```

## Best Practices

‚úÖ Use `set -euo pipefail` always
‚úÖ Define colors once at top
‚úÖ Resolve directories properly
‚úÖ Check dependencies first
‚úÖ Use functions for reusable logic

## Related Patterns

- [Error Handling](Bash-Error-Handling.md)
- [Directory Resolution](Directory-Resolution.md)
- [Variable Naming](Variable-Naming.md)

---

*Consistent bash scripts with proper error handling and clear output.*# Variable Naming

## Quick Reference
- **When to use**: All Bash script variables
- **Enforcement**: Required - maintain consistency
- **Impact if violated**: MEDIUM - Confusion about variable scope and mutability

## The Rules

1. **snake_case** for regular variables (mutable, local)
2. **UPPER_CASE** for constants (immutable, configuration, paths)
3. **Descriptive names** that indicate purpose
4. **Avoid single letters** except loop counters

## Examples

### ‚úÖ Correct

```bash
#!/usr/bin/env bash

# Constants - UPPER_CASE
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
BUILD_DIR="${PROJECT_ROOT}/build"
MAX_RETRIES=3
RED='\033[0;31m'
GREEN='\033[0;32m'

# Environment variables - UPPER_CASE
AWS_PROFILE=${AWS_PROFILE:-default}
AWS_REGION=${AWS_REGION:-us-west-2}

# Regular variables - snake_case
file_name="data.json"
temp_dir=$(mktemp -d)
api_response=$(curl -s "https://api.example.com/data")
user_count=0

# Function with clear parameters
function deploy_lambda() {
    local function_name=$1
    local zip_file_path=$2

    echo "Deploying ${function_name} from ${zip_file_path}"
}
```

### ‚ùå Incorrect

```bash
# ‚ùå WRONG - Mixed casing
fileName="data.json"        # Should be file_name
TempDir=$(mktemp -d)        # Should be temp_dir
script_dir="$(cd ...)"      # Should be SCRIPT_DIR
max_retries=3               # Should be MAX_RETRIES

# ‚ùå WRONG - UPPER_CASE for mutable
FILE_COUNT=0
for file in *.txt; do
    ((FILE_COUNT++))        # Should be snake_case
done

# ‚ùå WRONG - Non-descriptive
f="data.json"               # What is f?
d=$(mktemp -d)              # What is d?
```

## Common Patterns

### Constants with readonly

```bash
readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
readonly MAX_RETRIES=3
```

### Loop Variables

```bash
# Simple counters - single letter OK
for i in {1..10}; do
    echo "Iteration ${i}"
done

# Named variables - descriptive
for file_path in "${BUILD_DIR}"/*.zip; do
    echo "Processing ${file_path}"
done
```

### Boolean Flags

```bash
# Regular flags - snake_case
dry_run=false
verbose=false

# Constant flags - UPPER_CASE
DRY_RUN=${DRY_RUN:-false}
DEBUG=${DEBUG:-false}
```

## Enforcement

### Code Review Checklist

- [ ] Regular variables use snake_case
- [ ] Constants use UPPER_CASE
- [ ] Variable names are descriptive
- [ ] No single-letter names (except counters)

## Related Patterns

- [Script Patterns](Script-Patterns.md) - Overall script structure
- [Directory Resolution](Directory-Resolution.md) - BASH_SOURCE pattern

---

*Use snake_case for regular variables and UPPER_CASE for constants. Choose descriptive names that clearly indicate purpose.*
# Getting Started with the Development Wiki

This guide helps you understand and use this development conventions wiki effectively.

## What Is This Wiki?

This is a **centralized knowledge base** of development conventions, patterns, and best practices that apply across TypeScript/AWS projects. It represents institutional knowledge captured over time through the Convention Capture System.

### Key Characteristics
- **Universal patterns** - Conventions that work across multiple projects
- **Git-tracked** - Version controlled in `docs/wiki/` directory
- **Auto-synced** - Automatically published to GitHub Wiki for web viewing
- **Continuously updated** - New conventions added as they emerge
- **AI-compatible** - Referenced by AGENTS.md for AI assistants

## How to Navigate

### By Category
The wiki is organized into logical categories:
- **Conventions** - Universal coding standards
- **TypeScript** - Language-specific patterns
- **Testing** - Test strategies and mocking
- **AWS** - Cloud service patterns
- **Bash** - Shell scripting standards
- **Infrastructure** - IaC patterns
- **Methodologies** - Development philosophies
- **Meta** - Documentation about documentation

### By Priority
Look for enforcement levels:
- üö® **Zero-tolerance** - NO exceptions allowed
- ‚ö†Ô∏è **Required** - Must follow unless justified
- üìã **Recommended** - Should follow for consistency
- üí° **Optional** - Consider for specific cases

### By Search
- Use your IDE's file search in `docs/wiki/`
- Use GitHub Wiki search (once synced)
- grep for specific patterns

## How to Use in Your Project

### Step 1: Set Up AGENTS.md
Create an AGENTS.md file in your project root with:
```markdown
# Project Context for AI Agents

## Convention Capture System
[Copy from template - includes detection patterns]

## Project Overview
[Your project-specific content]

## Wiki Conventions to Follow
[Links to relevant wiki pages]
```

### Step 2: Create Passthrough Files
For tool compatibility:

**CLAUDE.md:**
```
@AGENTS.md
```

**GEMINI.md:**
```markdown
# See AGENTS.md
This project uses AGENTS.md as the single source of truth.
Please see AGENTS.md for documentation.
```

### Step 3: Reference Wiki Pages
From your AGENTS.md or documentation:
```markdown
## Conventions to Follow
- [Naming](Conventions/Naming-Conventions.md)
- [AWS SDK](AWS/SDK-Encapsulation-Policy.md)
- [Testing](Testing/Jest-ESM-Mocking-Strategy.md)
```

### Step 4: Track Project Conventions
Create `docs/conventions-tracking.md` for project-specific patterns:
```markdown
## Project-Specific Conventions

### Detected: 2025-11-22
1. **Pattern Name**
   - What: [Description]
   - Why: [Rationale]
   - Status: ‚úÖ Documented
```

## Understanding Convention Pages

Each wiki page follows a standard template:

### Page Structure
```markdown
# [Pattern Name]

## Quick Reference
- **When to use**: [One-line]
- **Enforcement**: [Level]
- **Impact if violated**: [High/Medium/Low]

## The Rule
[Clear statement]

## Examples
### ‚úÖ Correct
[Good example]

### ‚ùå Incorrect
[Bad example]

## Rationale
[Why this exists]

## Enforcement
[How to check/automate]

## Related Patterns
[Links to related pages]
```

### Reading Priority
1. **Quick Reference** - Get the essence
2. **The Rule** - Understand the requirement
3. **Examples** - See it in practice
4. **Enforcement** - Know how it's checked

## For AI Assistants

### Starting a Session
1. Read AGENTS.md (which references this wiki)
2. Check `docs/conventions-tracking.md` for project patterns
3. Activate convention detection mode
4. Reference wiki pages as needed

### During Development
- Follow wiki patterns by default
- Flag new conventions when detected
- Update Emerging Conventions log
- Reference wiki pages in explanations

### Example AI Usage
```
User: "How should I handle AWS SDK imports?"

AI: Per [AWS SDK Encapsulation Policy](AWS/SDK-Encapsulation-Policy.md),
NEVER import AWS SDK directly. Use vendor wrappers in lib/vendor/AWS/.

This is a zero-tolerance rule to maintain encapsulation and testability.
```

## For Developers

### Finding Patterns
1. Check relevant category in wiki
2. Search for keywords
3. Review enforcement level
4. Follow examples

### Contributing New Patterns
1. Detect pattern emergence
2. Document in conventions-tracking.md
3. Create wiki page following template
4. Submit PR with:
   - Clear rationale
   - Good/bad examples
   - Enforcement strategy
5. Update Home.md navigation

### Reporting Issues
- Missing pattern? Create issue
- Unclear documentation? Suggest edit
- Conflicting patterns? Raise for discussion

## Common Use Cases

### Starting New Project
1. Copy AGENTS.md template
2. Add project-specific content
3. Link to relevant wiki pages
4. Create conventions-tracking.md

### Onboarding Developer
1. Point to wiki Home.md
2. Highlight zero-tolerance rules
3. Show project's AGENTS.md
4. Explain Convention Capture

### Code Review
1. Reference wiki for standards
2. Link to specific patterns
3. Check enforcement level
4. Suggest wiki updates if needed

### Debugging Test Failures
1. Check [Jest ESM Mocking](Testing/Jest-ESM-Mocking-Strategy.md)
2. Review transitive dependencies
3. Follow 7-step checklist
4. Mock all module-level imports

## Automation & Sync

### Local Files
- Edit in `docs/wiki/` directory
- Commit via normal git workflow
- Review via pull requests

### GitHub Wiki Sync
- Automatic on merge to master
- GitHub Actions workflow
- ~30 second delay
- Creates web-friendly view

### Benefits
- **Developers** - Edit in IDE
- **Users** - Browse on web
- **Automation** - Zero maintenance
- **Version Control** - Full git history

## Best Practices

### Do's
‚úÖ Reference wiki pages in code comments
‚úÖ Update wiki when patterns evolve
‚úÖ Use Convention Capture System
‚úÖ Follow zero-tolerance rules strictly
‚úÖ Link from AGENTS.md

### Don'ts
‚ùå Duplicate wiki content in projects
‚ùå Ignore zero-tolerance rules
‚ùå Create conflicting local patterns
‚ùå Skip convention detection
‚ùå Edit GitHub Wiki directly (edit docs/wiki/)

## Quick Commands

### Search Wiki
```bash
# Find all zero-tolerance rules
grep -r "Zero-tolerance" docs/wiki/

# Find AWS patterns
ls docs/wiki/AWS/

# Search for specific pattern
grep -r "camelCase" docs/wiki/
```

### Validate Links
```bash
# Check for broken wiki links
find docs/wiki -name "*.md" -exec grep -l "](.*)" {} \;
```

### View Recent Changes
```bash
# See recent wiki updates
git log --oneline docs/wiki/ | head -10
```

## Troubleshooting

### Can't Find Pattern?
1. Search by keyword
2. Check multiple categories
3. Review Emerging Conventions
4. Ask in team chat
5. Create if truly missing

### Conflicting Patterns?
1. Check enforcement levels
2. Project-specific overrides project
3. Zero-tolerance always wins
4. Raise for team discussion

### Wiki Not Syncing?
1. Check GitHub Actions status
2. Verify wiki enabled in settings
3. Check workflow permissions
4. Manual trigger if needed

## Next Steps

1. **Explore** - Browse categories that interest you
2. **Apply** - Use patterns in your code
3. **Contribute** - Add missing patterns
4. **Detect** - Flag emerging conventions
5. **Evolve** - Improve existing patterns

---

*Remember: This wiki is a living document. It grows through the Convention Capture System and represents our collective knowledge. Use it, improve it, and help it evolve.*# Development Conventions Wiki

Welcome to the centralized development conventions wiki. This wiki contains universal patterns, methodologies, and best practices that apply across TypeScript/AWS projects.

## Quick Start

- **New to the wiki?** Start with [Getting Started](Getting-Started.md)
- **Looking for specific patterns?** Use the navigation below
- **Contributing?** See [Working with AI Assistants](Meta/Working-with-AI-Assistants.md)

## Navigation

### üìã Conventions
Core development conventions that apply universally:

- [Naming Conventions](Conventions/Naming-Conventions.md) - camelCase, PascalCase, SCREAMING_SNAKE_CASE rules
- [Git Workflow](Conventions/Git-Workflow.md) - Commit messages, NO AI attribution
- [Code Comments](Conventions/Code-Comments.md) - Git as source of truth principle
- [Import Organization](Conventions/Import-Organization.md) - ES modules, destructuring patterns

### üéØ TypeScript
TypeScript-specific patterns and best practices:

- [Lambda Function Patterns](TypeScript/Lambda-Function-Patterns.md) - Handler organization
- [Error Handling](TypeScript/TypeScript-Error-Handling.md) - API Gateway vs event-driven
- [Type Definitions](TypeScript/Type-Definitions.md) - Where to put types
- [Module Best Practices](TypeScript/Module-Best-Practices.md) - Export patterns

### üß™ Testing
Comprehensive testing strategies and patterns:

- [Jest ESM Mocking Strategy](Testing/Jest-ESM-Mocking-Strategy.md) - Transitive dependencies solution
- [Mock Type Annotations](Testing/Mock-Type-Annotations.md) - Specific vs generic types
- [Lazy Initialization Pattern](Testing/Lazy-Initialization-Pattern.md) - Defer SDK clients
- [Coverage Philosophy](Testing/Coverage-Philosophy.md) - Test YOUR code principle
- [Integration Testing](Testing/Integration-Testing.md) - LocalStack patterns

### ‚òÅÔ∏è AWS
AWS-specific patterns and policies:

- [SDK Encapsulation Policy](AWS/SDK-Encapsulation-Policy.md) - **ZERO-TOLERANCE** vendor wrapper pattern
- [Lambda Environment Variables](AWS/Lambda-Environment-Variables.md) - Naming conventions
- [CloudWatch Logging](AWS/CloudWatch-Logging.md) - Logging patterns
- [X-Ray Integration](AWS/X-Ray-Integration.md) - Tracing patterns

### üìú Bash
Shell scripting conventions:

- [Variable Naming](Bash/Variable-Naming.md) - snake_case vs UPPER_CASE
- [Directory Resolution](Bash/Directory-Resolution.md) - BASH_SOURCE patterns
- [User Output Formatting](Bash/User-Output-Formatting.md) - Colors and feedback
- [Error Handling](Bash/Bash-Error-Handling.md) - set -e, exit codes

### üèóÔ∏è Infrastructure
Infrastructure as Code patterns:

- [Resource Naming](Infrastructure/Resource-Naming.md) - PascalCase for AWS
- [File Organization](Infrastructure/File-Organization.md) - Service grouping
- [Environment Variables](Infrastructure/Environment-Variables.md) - Cross-stack consistency

### üí° Methodologies
Development methodologies and philosophies:

- [Convention Over Configuration](Methodologies/Convention-Over-Configuration.md) - Core philosophy
- [Library Migration Checklist](Methodologies/Library-Migration-Checklist.md) - Step-by-step process
- [Dependabot Resolution](Methodologies/Dependabot-Resolution.md) - Automated updates
- [Production Debugging](Methodologies/Production-Debugging.md) - Troubleshooting guide

### üîÆ Meta
Meta-documentation about the documentation system itself:

- [Working with AI Assistants](Meta/Working-with-AI-Assistants.md) - Effective AI collaboration
- [Convention Capture System](Meta/Convention-Capture-System.md) - How conventions are captured
- [Emerging Conventions](Meta/Emerging-Conventions.md) - Live append-only log
- [AI Tool Context Files](Meta/AI-Tool-Context-Files.md) - AGENTS.md, CLAUDE.md standards
- [Documentation Patterns](Meta/Documentation-Patterns.md) - Passthrough files, organization

## Key Principles

### üö® Zero-Tolerance Rules
These patterns have **ZERO exceptions**:
- [AWS SDK Encapsulation](AWS/SDK-Encapsulation-Policy.md) - NEVER import AWS SDK directly
- [No AI Attribution](Conventions/Git-Workflow.md) - NEVER include AI references in commits
- [Git as Source of Truth](Conventions/Code-Comments.md) - NEVER explain removed code in comments

### üìà Convention Evolution
Conventions evolve through:
1. **Detection** - Patterns emerge during development
2. **Capture** - [Convention Capture System](Meta/Convention-Capture-System.md) preserves them
3. **Documentation** - Added to this wiki
4. **Enforcement** - Automated checks where possible
5. **Refinement** - Improved based on experience

## Using This Wiki

### For AI Assistants
- Start each session by reviewing [Convention Capture System](Meta/Convention-Capture-System.md)
- Reference wiki pages from AGENTS.md using relative paths
- Flag new conventions using the detection system
- Update [Emerging Conventions](Meta/Emerging-Conventions.md) in real-time

### For Developers
- Browse by category using navigation above
- Search for specific patterns using your IDE
- Contribute new patterns via pull requests
- Report issues or gaps in documentation

### For New Projects
1. Copy AGENTS.md template with Convention Capture instructions
2. Reference this wiki for universal patterns
3. Build project-specific conventions in `docs/conventions-tracking.md`
4. Use passthrough files (CLAUDE.md, GEMINI.md) for tool compatibility

## Repository Structure

This wiki is stored in the main repository under `docs/wiki/`:
- **Version controlled** alongside code
- **PR reviewed** for quality
- **Offline accessible** via git
- **Auto-synced** to GitHub Wiki for web viewing

## Contributing

To add or update conventions:
1. Follow the [page template](Meta/Documentation-Patterns.md)
2. Include clear examples (‚úÖ Correct / ‚ùå Incorrect)
3. Explain rationale and benefits
4. Add enforcement mechanisms where possible
5. Update navigation in this Home.md

## Quick Reference

| Pattern | Category | Enforcement |
|---------|----------|-------------|
| AWS SDK Encapsulation | AWS | Zero-tolerance |
| No AI in Commits | Git | Zero-tolerance |
| camelCase for variables | Naming | Required |
| Jest transitive mocking | Testing | Required |
| Git as source of truth | Comments | Required |

---

*This wiki represents accumulated institutional knowledge from development across multiple projects. It serves as the reference implementation for development conventions and is continuously updated through the Convention Capture System.*# Dependency Graph Analysis

## Quick Reference
- **When to use**: Finding transitive dependencies for Jest mocking
- **Enforcement**: Required for accurate test mocking
- **Impact if violated**: HIGH - Missing mocks cause test failures

## The graph.json File

The `build/graph.json` file is automatically generated before builds and tests, ensuring fresh dependency analysis:

```json
{
  "directDependencies": {
    "src/lambdas/WebhookFeedly/src/index.ts": [
      "aws-lambda",
      "../../../entities/Files",
      "../../../entities/UserFiles",
      // ... all direct imports
    ]
  },
  "transitiveDependencies": {
    "src/lambdas/WebhookFeedly/src/index.ts": [
      "aws-lambda",
      "@aws-sdk/client-dynamodb",
      "@aws-sdk/lib-dynamodb",
      "electrodb",
      // ... ALL dependencies including transitive
    ]
  }
}
```

## Usage for Jest Testing

**CRITICAL**: Use `transitiveDependencies` to find ALL mocks needed for a test file.

### Finding Required Mocks
```bash
# List all transitive dependencies for a Lambda
cat build/graph.json | jq '.transitiveDependencies["src/lambdas/WebhookFeedly/src/index.ts"]'

# Check if a specific module is needed
cat build/graph.json | jq '.transitiveDependencies["src/lambdas/ListFiles/src/index.ts"]' | grep electrodb
```

### Test Setup Process
1. Generate the graph: `npm run generate-graph`
2. Find your file in `transitiveDependencies`
3. Mock ALL external packages listed
4. Mock ALL vendor wrappers (lib/vendor/*)
5. Mock ALL entities if using ElectroDB

## Common Patterns

### Lambda Test Mocking
```typescript
// 1. Check graph.json for Lambda's transitive dependencies
// 2. Mock everything external BEFORE imports

// If graph.json shows these dependencies:
// ["aws-lambda", "@aws-sdk/client-s3", "electrodb", "../../../entities/Files"]

// Then mock them all:
jest.unstable_mockModule('@aws-sdk/client-s3', () => ({
  S3Client: jest.fn()
}))

jest.unstable_mockModule('../../../entities/Files', () => ({
  Files: createElectroDBEntityMock().entity
}))

// 3. Import handler AFTER mocking
const {handler} = await import('../src/index')
```

### Debugging Missing Mocks
```bash
# If test fails with "Cannot find module X"
# Check if X is in transitive dependencies:
cat build/graph.json | jq '.transitiveDependencies["path/to/your/file.ts"]' | grep "X"

# If present, you forgot to mock it
# If absent, regenerate graph: npm run generate-graph
```

## Graph Generation

The graph is generated automatically:
- **Before builds**: `pnpm run build` runs `generate-graph` first
- **Before tests**: `pnpm test` runs `generate-graph` first
- **Before integration tests**: `pnpm test:integration` runs `generate-graph` first
- **Manual generation**: `pnpm run generate-graph`
- **Script location**: `scripts/generateDependencyGraph.ts`

**Note**: Lifecycle scripts are disabled for security (`enable-pre-post-scripts=false` in `.npmrc`), so scripts explicitly run `generate-graph` rather than using `prebuild`/`pretest` hooks.

## Best Practices

1. **Always regenerate** after adding new imports
2. **Check transitive deps** not just direct deps
3. **Mock everything external** shown in graph
4. **Use for code review** to verify import changes
5. **Automate in CI** to catch missing mocks

## Related Patterns

- [Jest ESM Mocking Strategy](Jest-ESM-Mocking-Strategy.md) - How to mock
- [Mock Type Annotations](Mock-Type-Annotations.md) - TypeScript patterns
- [Integration Testing](Integration-Testing.md) - When to use real deps

---

*Use build/graph.json to identify ALL transitive dependencies for comprehensive Jest mocking.*# Fixture Extraction

## Quick Reference
- **When to use**: Automated test fixture generation from production
- **Enforcement**: Always enabled (logs to CloudWatch, extract when needed)
- **Impact if violated**: LOW - Manual fixture maintenance

## Overview

Automatic extraction of production API requests/responses from CloudWatch logs for use as test fixtures. Transforms production reality into test truth weekly via GitHub Actions.

## Architecture

```
Production Lambda ‚Üí CloudWatch Logs ‚Üí extract-fixtures.sh ‚Üí process-fixtures.js ‚Üí test/fixtures/
```

### Workflow
1. **Production logging**: Lambda marks requests/responses with `__FIXTURE_MARKER__`
2. **Weekly extraction**: GitHub Actions queries CloudWatch (last 7 days)
3. **Processing**: Deduplicate, sanitize PII, format for tests
4. **PR creation**: Automated PR with fixture updates for review

## Fixture Logging Implementation

Fixture logging is always enabled in instrumented Lambdas. Add logging calls to capture requests/responses:

```typescript
import {logIncomingFixture, logOutgoingFixture} from '../../../util/lambda-helpers'

export const handler = withXRay(async (event, context) => {
  logIncomingFixture(event, 'webhook-feedly')

  // ... handler logic
  const result = response(context, 200, {status: 'Success'})

  logOutgoingFixture(result, 'webhook-feedly')
  return result
})
```

**Automatic PII sanitization**: Redacts Authorization, tokens, passwords, apiKey, secret, appleDeviceIdentifier

## Manual Extraction

```bash
# Extract from last 7 days
pnpm run extract-fixtures

# Extract from last 14 days
./bin/extract-fixtures.sh 14

# Process and deduplicate
pnpm run process-fixtures
```

**Output**: `test/fixtures/api-contracts/{LambdaName}/incoming.json`, `outgoing.json`

## GitHub Actions Automation (Planned)

The extraction pipeline is automation-ready. A workflow can be added at `.github/workflows/extract-fixtures.yml`:

```yaml
# Example workflow configuration
on:
  schedule:
    - cron: '0 2 * * 0'  # Weekly
  workflow_dispatch:      # Manual trigger
```

**Current Process** (manual):
1. Run `pnpm run extract-fixtures` locally
2. Run `pnpm run process-fixtures` to deduplicate
3. Review and commit fixture updates

**Automated Process** (when workflow is added):
1. Extract fixtures from CloudWatch
2. Deduplicate by structural similarity (90% threshold)
3. Create PR with updated fixtures
4. Requires manual review before merge

## Deduplication Strategy

**Structural similarity** (not exact match):
- Compares object structure, not values
- 90% similarity threshold
- Prevents 1000 identical fixtures with different IDs
- Keeps diverse edge cases

```javascript
// These are considered similar (deduplicated):
{userId: "user-1", status: "Downloaded"}
{userId: "user-2", status: "Downloaded"}

// These are kept (different structure):
{userId: "user-1", status: "Downloaded"}
{userId: "user-1", status: "Failed", error: "Network timeout"}
```

## Instrumented Lambdas

All 7 API Gateway Lambdas have fixture logging enabled:
- ListFiles
- LoginUser
- RefreshToken
- RegisterDevice
- UserDelete
- UserSubscribe
- WebhookFeedly

**Extraction script configured for** (in `bin/extract-fixtures.sh`):
- WebhookFeedly, ListFiles, RegisterDevice, LoginUser, StartFileUpload, SendPushNotification

**Add more**: Edit `LAMBDA_FUNCTIONS` array in `bin/extract-fixtures.sh`

## Security

### PII Sanitization

Automatically redacted fields:
- `Authorization` / `authorization`
- `token` / `Token`
- `password` / `Password`
- `apiKey` / `ApiKey`
- `secret` / `Secret`
- `appleDeviceIdentifier`

Recursive processing handles nested objects/arrays.

### Production Safety
- ‚úÖ No performance impact (async logging)
- ‚úÖ CloudWatch costs: ~$5.50/year
- ‚úÖ Manual PR review before merging

## Cost Analysis

**CloudWatch Logs Insights**:
- $0.005 per GB ingested
- $0.005 per GB scanned in queries
- ~10KB per fixture √ó 50 fixtures/week = 500KB/week = 26MB/year
- **Total**: ~$1.30/year ingestion + $4.20/year scanning = **$5.50/year**

## Troubleshooting

### No Fixtures Extracted

1. Verify Lambda has `logIncomingFixture`/`logOutgoingFixture` calls
2. Check Lambda was invoked in time window
3. Verify CloudWatch log group exists
4. Check log retention (default 30 days)

```bash
# Check log group exists
aws logs describe-log-groups --log-group-name-prefix /aws/lambda/WebhookFeedly

# Check recent log events
aws logs tail /aws/lambda/WebhookFeedly --since 1h
```

### Sensitive Data in Fixtures

1. Delete affected fixture files immediately
2. Add field to `sensitiveFields` array in `lambda-helpers.ts`
3. Re-run extraction
4. Audit git history if needed

```bash
# Remove from git history if committed
git filter-branch --force --index-filter \
  'git rm --cached --ignore-unmatch test/fixtures/api-contracts/WebhookFeedly/incoming.json' \
  --prune-empty --tag-name-filter cat -- --all
```

### GitHub Actions Fails

1. Verify AWS credentials in repository secrets:
   - `AWS_ACCESS_KEY_ID`
   - `AWS_SECRET_ACCESS_KEY`
2. Check IAM permissions (logs:FilterLogEvents)
3. Review workflow logs: `gh run view --log`

## Best Practices

‚úÖ Enable fixture logging in production only (not staging/dev)
‚úÖ Review PRs for sensitive data before merging
‚úÖ Add new Lambdas to extraction list as they're created
‚úÖ Keep fixture count manageable (~5-10 per endpoint)
‚úÖ Use fixtures for API contract tests, not unit tests

## Related Patterns

- [ElectroDB Testing Patterns](ElectroDB-Testing-Patterns.md)
- [Integration Testing](Integration-Testing.md)
- [Coverage Philosophy](Coverage-Philosophy.md)

---

*Use production data as test oracle. Weekly extraction keeps fixtures current.*
# Coverage Philosophy

## Quick Reference
- **When to use**: Planning and writing tests
- **Enforcement**: Recommended - guides testing strategy
- **Impact if violated**: Low - may write unnecessary tests

## Core Principle

**Test YOUR Code, Not Library Code**

Coverage should be a side effect of testing business logic, not a goal itself. Integration tests validate YOUR orchestration, not AWS SDK behavior.

## Test Focus

### ‚ùå Wrong: Testing Libraries
- "Can I upload to S3?" ‚Üí Testing AWS SDK
- "Does DynamoDB query work?" ‚Üí Testing AWS SDK

### ‚úÖ Correct: Testing YOUR Logic
- "Does download workflow complete?" ‚Üí Testing YOUR orchestration
- "After S3 upload, is DynamoDB updated?" ‚Üí Testing YOUR state management
- "Does error rollback DynamoDB?" ‚Üí Testing YOUR error recovery

## Test Types

### Unit Tests
- **Purpose**: Test function logic in isolation
- **Mock**: ALL external dependencies (AWS, APIs, packages)
- **Speed**: Milliseconds per test
- **Location**: `src/lambdas/*/test/index.test.ts`

```typescript
test('applies 15% discount for premium users', () => {
  expect(calculateDiscount(100, true)).toBe(85)
})
```

### Integration Tests
- **Purpose**: Test multi-service workflows end-to-end
- **Use**: Real AWS services (via LocalStack)
- **Test**: YOUR orchestration, state management, error handling
- **Location**: `test/integration/workflows/*.workflow.integration.test.ts`

```typescript
test('download updates DynamoDB and notifies user', async () => {
  await triggerDownload(fileId)
  const file = await getFileFromDB(fileId)
  expect(file.status).toBe('downloaded')
  expect(notificationSent).toBe(true)
})
```

## Integration Test Priority

### High Priority (Multi-Service)
- ‚úÖ webhook ‚Üí DynamoDB ‚Üí queue ‚Üí Lambda ‚Üí S3
- ‚úÖ State transitions across services
- ‚úÖ Error rollback logic
- ‚úÖ Fan-out patterns

### Medium Priority (Service + Logic)
- ‚úÖ Query filtering and pagination
- ‚úÖ Conditional creates/updates
- ‚úÖ Batch operations with partial failures

### Low Priority (Simple CRUD)
- ‚ùå Pure CRUD ‚Üí Unit tests sufficient
- ‚ùå Thin wrappers ‚Üí Covered by unit tests

## Coverage Targets

### Unit Tests
- Lambda handlers: **80%+**
- Utility functions: **90%+**
- Business logic: **85%+**
- Vendor wrappers: Ignore with `/* c8 ignore */`

### Integration Tests
- Coverage happens naturally from workflow tests
- Don't write tests to hit coverage targets
- Focus on workflows, not library behavior

## What to Test

### ‚úÖ DO Test
- Data transformations, validation, calculations
- State transitions and error handling
- Service call sequences and data flow
- Edge cases and boundary conditions

### ‚ùå DON'T Test
- AWS SDK functionality
- NPM package behavior
- Implementation details (variable names, private functions)

## Testing Patterns

### Test YOUR Orchestration
```typescript
test('download workflow completes end-to-end', async () => {
  await createFile(fileId, 'pending')
  await startDownload(fileId)
  await processDownload(fileId)

  const file = await getFile(fileId)
  expect(file.status).toBe('downloaded')

  const notifications = await getNotifications(userId)
  expect(notifications).toHaveLength(1)
})
```

### Ignore Vendor Wrappers in Unit Tests
```typescript
/* c8 ignore start */
export async function createS3Upload(bucket: string, key: string, body: any) {
  // Tested via integration tests
  return new Upload({client: s3Client, params: {Bucket: bucket, Key: key, Body: body}})
}
/* c8 ignore end */
```

## Test Organization

Structure by workflow, not service:
```
test/integration/workflows/
‚îú‚îÄ‚îÄ webhookFeedly.workflow.integration.test.ts
‚îú‚îÄ‚îÄ fileDownload.workflow.integration.test.ts
‚îî‚îÄ‚îÄ deviceRegistration.workflow.integration.test.ts
```

## Success Indicators

### Good
‚úÖ Tests describe business requirements
‚úÖ Tests fail when logic breaks
‚úÖ High coverage of YOUR code
‚úÖ Fast unit tests (< 1s)

### Bad
‚ùå Tests describe implementation
‚ùå High coverage via shallow tests
‚ùå Slow unit tests (> 5s)
‚ùå Many integration tests for CRUD

## Related Patterns
- [Jest ESM Mocking Strategy](Jest-ESM-Mocking-Strategy.md) - Mocking dependencies
- [Mock Type Annotations](Mock-Type-Annotations.md) - Type-safe mocking
- [Lambda Function Patterns](../TypeScript/Lambda-Function-Patterns.md) - What to test

---

*Test YOUR code, not library code. Coverage follows from testing business logic. Focus on workflows and orchestration.*# Lazy Initialization Pattern

## Quick Reference
- **When to use**: Modules that create AWS SDK clients or external connections at module level
- **Enforcement**: Required - prevents test failures from premature initialization
- **Impact if violated**: HIGH - Tests fail with SDK errors despite mocking

## The Problem

AWS SDK clients and external connections initialized at module level execute immediately when the module loads, **before** mocks are set up.

## Core Pattern

### ‚ùå Incorrect - Eager Initialization
```typescript
// ‚ùå WRONG - Client created at module level
import {S3Client} from '@aws-sdk/client-s3'

const s3Client = new S3Client({region: 'us-west-2'})  // Runs immediately!

export async function headObject(bucket: string, key: string) {
  return await s3Client.send(command)  // Too late to mock
}
```

### ‚úÖ Correct - Lazy Initialization
```typescript
// ‚úÖ Client is null initially
let s3Client: S3Client | null = null

// ‚úÖ Initialize only when first used
function getS3Client(): S3Client {
  if (!s3Client) {
    s3Client = new S3Client({region: process.env.AWS_REGION || 'us-west-2'})
  }
  return s3Client
}

export async function headObject(bucket: string, key: string) {
  const client = getS3Client()  // Created on first call
  return await client.send(new HeadObjectCommand({Bucket: bucket, Key: key}))
}

export function resetS3Client(): void {
  s3Client = null
}
```

## Common Implementations

### With X-Ray Integration
```typescript
import {DynamoDBClient} from '@aws-sdk/client-dynamodb'
import {DynamoDBDocumentClient} from '@aws-sdk/lib-dynamodb'
import {captureAWSClient} from './XRay'

let dynamoClient: DynamoDBDocumentClient | null = null

function getDynamoClient(): DynamoDBDocumentClient {
  if (!dynamoClient) {
    const client = new DynamoDBClient({region: process.env.AWS_REGION || 'us-west-2'})
    dynamoClient = DynamoDBDocumentClient.from(captureAWSClient(client))
  }
  return dynamoClient
}

export async function query(tableName: string, key: string, value: string) {
  const client = getDynamoClient()
  // Use client...
}

export function resetDynamoClient(): void {
  dynamoClient = null
}
```

### With LocalStack Configuration
```typescript
let s3Client: S3Client | null = null

interface S3Config {
  region?: string
  endpoint?: string
  forcePathStyle?: boolean
}

function getS3Client(config?: S3Config): S3Client {
  if (!s3Client) {
    const isLocalStack = process.env.USE_LOCALSTACK === 'true'
    s3Client = new S3Client({
      region: config?.region || process.env.AWS_REGION || 'us-west-2',
      endpoint: config?.endpoint || (isLocalStack ? 'http://localhost:4566' : undefined),
      forcePathStyle: config?.forcePathStyle || isLocalStack
    })
  }
  return s3Client
}

export function configureS3Client(config: S3Config): void {
  s3Client = null
  getS3Client(config)
}
```

### ElectroDB Service
```typescript
import {Service} from 'electrodb'
import {Users, Files, Devices} from '../../src/entities'

let service: Service | null = null

export function getService(): Service {
  if (!service) {
    service = new Service({Users, Files, Devices})
  }
  return service
}

export const table = process.env.TABLE_NAME || 'MediaDownloader'
export function resetService(): void { service = null }
```

## Testing Benefits

### Works with Mocks
```typescript
// Mock BEFORE importing handler
jest.unstable_mockModule('../../../lib/vendor/AWS/S3', () => ({
  headObject: jest.fn<() => Promise<{ContentLength: number}>>()
    .mockResolvedValue({ContentLength: 1024}),
  resetS3Client: jest.fn()
}))

const {handler} = await import('../src/index')

describe('GetFile handler', () => {
  it('gets file info', async () => {
    const result = await handler(event, context)
    expect(result.statusCode).toBe(200)  // Works!
  })
})
```

## Common Mistakes

### Creating Client at Module Level
```typescript
// ‚ùå WRONG
const s3 = new S3Client({region: 'us-west-2'})

// ‚úÖ CORRECT
let s3: S3Client | null = null
function getS3Client() {
  if (!s3) s3 = new S3Client({region: 'us-west-2'})
  return s3
}
```

### Forgetting Reset Function
```typescript
// ‚ùå INCOMPLETE
let client: SomeClient | null = null
function getClient() {
  if (!client) client = new SomeClient()
  return client
}

// ‚úÖ COMPLETE
let client: SomeClient | null = null
function getClient() {
  if (!client) client = new SomeClient()
  return client
}
export function resetClient() { client = null }
```

## Why This Pattern?

1. **Testability** - Mocks applied before client creation
2. **Environment Safety** - Client only created when needed
3. **Configuration Flexibility** - Can apply config before initialization
4. **LocalStack Support** - Can point to LocalStack endpoint
5. **Minimal Overhead** - Getter function adds negligible cost

## Enforcement

```bash
# Check for eager initialization
grep -rn "= new.*Client({" lib/vendor/AWS/*.ts | grep -v "function\|if ("
```

## Related Patterns
- [Jest ESM Mocking Strategy](Jest-ESM-Mocking-Strategy.md) - Mocking before imports
- [LocalStack Testing](../Integration/LocalStack-Testing.md) - Testing with LocalStack
- [AWS SDK Encapsulation Policy](../AWS/SDK-Encapsulation-Policy.md) - Vendor wrapper pattern

---

*Defer client initialization until first use. This enables proper mocking in tests and supports flexible configuration.*
# Local CI Testing

This guide explains how to run CI checks locally before pushing to GitHub, ensuring faster feedback and reduced CI usage.

## Background

Previously, this project used `nektos/act` for local GitHub Actions testing. It was removed due to Apple Silicon (ARM64) incompatibility - the x86-64 Linux containers required for GitHub Actions cause Rosetta translation failures on M1/M2/M3 Macs.

Instead, we use **workflow decomposition**: CI logic is extracted into reusable shell scripts that run both locally and in GitHub Actions, ensuring consistency.

## Quick Start

```bash
# First time setup (installs git hooks)
pnpm run prepare

# Fast CI (no integration tests) - recommended for most iterations
pnpm run ci:local

# Full CI (includes integration tests with LocalStack)
pnpm run ci:local:full
```

## Pre-Push Hook

This project uses Husky to enforce CI checks before pushing. When you run `git push`, the pre-push hook automatically runs `pnpm run ci:local:full` (~5-10 minutes).

**First time setup** (after cloning):
```bash
pnpm install  # Automatically runs 'prepare' which installs git hooks
```

**To verify hooks are installed**:
```bash
git config core.hooksPath  # Should output: .husky/_
```

**To bypass in emergencies**:
```bash
git push --no-verify
```

**Troubleshooting**: If `git config core.hooksPath` shows nothing, run `pnpm run prepare` manually.

## Available Commands

| Command | Duration | What it runs |
|---------|----------|--------------|
| `pnpm run ci:local` | ~2-3 min | All checks except integration tests |
| `pnpm run ci:local:full` | ~5-10 min | Everything including integration tests |
| `pnpm run test:integration` | ~30 sec | Integration tests only (LocalStack must be running) |
| `pnpm run validate:docs` | ~1 sec | Documentation script validation only |
| `pnpm run validate:graphrag` | ~5 sec | GraphRAG freshness check only |
| `pnpm run lint:workflows` | ~1 sec | GitHub Actions YAML validation (requires actionlint) |

### Why Both `ci:local:full` and `test:integration`?

These serve different purposes:

| Command | LocalStack Lifecycle | Use Case |
|---------|---------------------|----------|
| `ci:local:full` | Manages start/stop automatically | Pre-push validation, comprehensive CI |
| `test:integration` | Assumes already running | Fast iteration when developing tests |

**When developing integration tests**, use `test:integration` for rapid feedback:

```bash
# Start LocalStack once at the beginning of your session
pnpm run localstack:start

# Iterate rapidly (~30s per run instead of 5-10 min)
pnpm run test:integration   # run tests
# make changes...
pnpm run test:integration   # run again
# make changes...
pnpm run test:integration   # run again

# Stop when done
pnpm run localstack:stop
```

**For pre-push validation**, use `ci:local:full` (or let the pre-push hook run it automatically).

## What ci:local Checks

The fast CI script (`pnpm run ci:local`) runs these checks in order:

1. **Prerequisites** - Node.js 22+, hcl2json, jq
2. **Dependencies** - `pnpm install --frozen-lockfile`
3. **Build dependencies** - Terraform type generation
4. **Webpack build** - Lambda function compilation
5. **Type checking** - TypeScript compiler
6. **Linting** - ESLint
7. **Documentation validation** - Ensures documented scripts exist
8. **Dependency rules** - Architectural boundary checks
9. **GraphRAG validation** - Knowledge graph freshness
10. **Unit tests** - Jest with mocked AWS services

## What ci:local Does NOT Check

These checks can only run in GitHub Actions:

- **Codecov upload** - Requires GitHub secrets
- **Artifact storage** - GitHub infrastructure
- **PR comments** - Requires GitHub API context
- **Wiki sync** - Only runs on push to master

## Coverage Estimate

Running `ci:local` catches approximately **95%** of issues that would fail in GitHub Actions CI. The remaining 5% are GitHub-specific features that cannot be replicated locally.

## Prerequisites

Before running local CI, ensure you have:

```bash
# Required tools
brew install hcl2json jq

# For integration tests
# Docker Desktop must be installed and running

# Optional: workflow validation
brew install actionlint
```

## Workflow Validation with actionlint

For validating GitHub Actions workflow YAML files without execution:

```bash
# Install actionlint (ARM64 native, no Docker required)
brew install actionlint

# Validate all workflows
pnpm run lint:workflows

# Or run directly
actionlint
```

This catches:
- YAML syntax errors
- Invalid action references
- Expression syntax errors (`${{ }}`)
- Shell script issues (via shellcheck integration)

## Recommended Workflow

1. **During development**: Run `pnpm run precheck` frequently (type check + lint)
2. **Before committing**: Run `pnpm run ci:local` (fast, ~2-3 min)
3. **Before pushing**: The pre-push hook runs `ci:local:full` automatically
4. **After pushing**: Monitor GitHub Actions for the remaining 5% of checks

## Troubleshooting

### "hcl2json not found"

```bash
brew install hcl2json
```

### "jq not found"

```bash
brew install jq
```

### Integration tests fail to connect to LocalStack

```bash
# Ensure Docker is running
docker ps

# Check LocalStack health
pnpm run localstack:health

# Restart LocalStack
pnpm run localstack:stop && pnpm run localstack:start
```

### GraphRAG validation fails

```bash
# Regenerate and commit the knowledge graph
pnpm run graphrag:extract
git add graphrag/knowledge-graph.json
git commit -m "chore: update GraphRAG knowledge graph"
```

### Pre-push hook not running

If `git push` succeeds without running CI checks:

```bash
# Check if hooks are configured
git config core.hooksPath

# If empty or missing, reinstall hooks
pnpm run prepare

# Verify hook exists and is executable
ls -la .husky/pre-push
ls -la .husky/_/pre-push
```

## Architecture

The local CI approach uses **workflow decomposition**:

```
GitHub Actions                    Local Development
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
.github/workflows/                bin/
‚îú‚îÄ‚îÄ unit-tests.yml       ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îú‚îÄ‚îÄ ci-local.sh
‚îÇ   ‚îî‚îÄ‚îÄ calls validate-docs.sh    ‚îú‚îÄ‚îÄ validate-docs.sh
‚îú‚îÄ‚îÄ dependency-check.yml ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îî‚îÄ‚îÄ validate-graphrag.sh
‚îÇ   ‚îî‚îÄ‚îÄ calls validate-graphrag.sh
‚îî‚îÄ‚îÄ integration-tests.yml ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îî‚îÄ‚îÄ test-integration.sh
```

Both CI and local development use the **same scripts**, ensuring:
- Identical behavior between environments
- Easy maintenance (one source of truth)
- No architecture mismatch issues (scripts run natively)

## See Also

- [Coverage Philosophy](./Coverage-Philosophy.md)
- [Jest ESM Mocking Strategy](./Jest-ESM-Mocking-Strategy.md)
- [LocalStack Testing](../Integration/LocalStack-Testing.md)
# Integration Testing

## Quick Reference
- **When to use**: Testing AWS service interactions
- **Enforcement**: Required for AWS changes
- **Impact if violated**: HIGH - Production issues

## LocalStack Setup

```bash
# Start LocalStack
npm run localstack:start

# Run integration tests
npm run test:integration

# Full suite with lifecycle
npm run test:integration:full
```

## Test Pattern

```typescript
// test/integration/dynamodb.test.ts
import {beforeAll, afterAll, test} from '@jest/globals'
import {setupLocalStack, teardownLocalStack} from '../helpers'

beforeAll(async () => {
  process.env.UseLocalstack = 'true'
  await setupLocalStack()
})

afterAll(async () => {
  await teardownLocalStack()
})

test('DynamoDB operations', async () => {
  const result = await queryItems({userId: 'test'})
  expect(result).toBeDefined()
})
```

## Service Testing

### DynamoDB
```typescript
const items = await Files.query.byUser({userId}).go()
```

### S3
```typescript
await createS3Upload('bucket', 'key', Buffer.from('data'))
```

### Lambda
```typescript
const result = await lambda.invoke({
  FunctionName: 'ProcessFile',
  Payload: JSON.stringify({fileId: 'test'})
})
```

## Docker Compose

```yaml
services:
  localstack:
    image: localstack/localstack:latest
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3,dynamodb,lambda,sns,sqs
```

## Best Practices

‚úÖ Use vendor wrappers (auto-detect LocalStack)
‚úÖ Clean state between tests
‚úÖ Mock external APIs
‚úÖ Test error cases
‚úÖ Verify AWS operations

## Common Issues

| Issue | Fix |
|-------|-----|
| Connection refused | Start LocalStack |
| Service unavailable | Check SERVICES env |
| State pollution | Clean between tests |

## Related Patterns

- [LocalStack Testing](../Integration/LocalStack-Testing.md)
- [Jest ESM Mocking](Jest-ESM-Mocking-Strategy.md)

---

*Test AWS integrations locally with LocalStack. Vendor wrappers auto-detect environment.*# Jest ESM Mocking Strategy

## Quick Reference
- **When to use**: Writing unit tests with ES modules
- **Enforcement**: Required
- **Impact if violated**: HIGH - Obscure test failures

## The Problem

In ES modules, **ALL module-level code executes when ANY export is imported**. Missing mocks for transitive dependencies cause mysterious 500 errors.

```typescript
// YouTube.ts
import YTDlpWrap from 'yt-dlp-wrap'  // Executes even if unused
import {spawn} from 'child_process'  // Executes

export function getVideoID(url: string) { }  // What you imported
export function streamVideoToS3() { }        // Uses the above imports
```

When testing `getVideoID`, all imports execute. Solution: Mock ALL transitive dependencies.

## Mocking Pattern

```typescript
// test/index.test.ts

// 1. Mock ALL transitive dependencies BEFORE imports
jest.unstable_mockModule('yt-dlp-wrap', () => ({
  default: jest.fn()
}))

jest.unstable_mockModule('child_process', () => ({
  spawn: jest.fn()
}))

jest.unstable_mockModule('../../../lib/vendor/AWS/S3', () => ({
  createS3Upload: jest.fn()
}))

// 2. Import after mocking
const {handler} = await import('../src/index')

// 3. Use type assertions for mocks
import type {jest as mockJest} from '@jest/globals'
const mockYTDlp = (await import('yt-dlp-wrap')).default as mockJest.MockedFunction<any>
```

## Dependency Mapping

1. **Map direct imports** - What does your test file import?
2. **Map transitive imports** - What do those imports import?
3. **Mock all external deps** - AWS SDK, npm packages, vendor wrappers
4. **Match module structure** - Classes need constructor mocks

## Common Patterns

### AWS SDK Mocks
```typescript
jest.unstable_mockModule('@aws-sdk/client-dynamodb', () => ({
  DynamoDBClient: jest.fn(() => ({
    send: jest.fn()
  }))
}))
```

### Vendor Wrapper Mocks
```typescript
jest.unstable_mockModule('../../../lib/vendor/AWS/DynamoDB', () => ({
  getDynamoDbClient: jest.fn(),
  queryItems: jest.fn()
}))
```

### ElectroDB Mock Helper (CRITICAL)

**Zero-tolerance rule**: ALWAYS use `createElectroDBEntityMock()` from `test/helpers/electrodb-mock.ts` for mocking ElectroDB entities.

```typescript
import {createElectroDBEntityMock} from '../../../test/helpers/electrodb-mock'
import type {File} from '../../../types/domain-models'

// Create mock before mocking module
const filesMock = createElectroDBEntityMock<File>()

// Mock the entity module
jest.unstable_mockModule('../../../entities/Files', () => ({
  Files: filesMock.entity
}))

// Later in tests - use the mocks for assertions
filesMock.mocks.get.mockResolvedValue({
  data: {fileId: '123', status: 'Downloaded'}
})

expect(filesMock.mocks.create).toHaveBeenCalledWith({
  fileId: '123',
  // ... other properties
})
```

**Benefits**:
- Type-safe mocks with full TypeScript inference
- Consistent mock structure across all tests
- Simplified setup with pre-configured query patterns
- Supports all ElectroDB operations (get, create, update, query, etc.)

## Testing Checklist

- [ ] List all imports in test file
- [ ] Read source files, list their imports
- [ ] Mock ALL external dependencies
- [ ] Mock BEFORE importing handler
- [ ] Add TypeScript types to mocks
- [ ] Test locally AND in CI

## Common Issues

| Error | Cause | Fix |
|-------|-------|-----|
| Cannot find module | Missing mock | Add jest.unstable_mockModule |
| X is not a constructor | Wrong mock structure | Mock as class with constructor |
| Property X doesn't exist | Incomplete mock | Add missing properties |
| Works locally, fails CI | Environment differences | Mock all transitive deps |

## Best Practices

1. **Mock first, import second** - Always mock before importing
2. **Mock everything external** - All npm packages and AWS SDK
3. **Use type assertions** - Add proper types to mocks
4. **Use mock helpers** - ElectroDB mock helper for entities
5. **Map dependencies** - Trace all transitive imports

## Related Patterns

- [Mock Type Annotations](Mock-Type-Annotations.md) - TypeScript mock patterns
- [Lazy Initialization](Lazy-Initialization-Pattern.md) - Defer module execution
- [Coverage Philosophy](Coverage-Philosophy.md) - Test strategy

---

*Mock ALL transitive dependencies in ES modules to prevent obscure test failures.*# Mock Type Annotations

## Quick Reference
- **When to use**: Creating mock functions with jest.fn()
- **Enforcement**: Required - provides type safety in tests
- **Impact if violated**: Medium - loss of type safety, harder debugging

## The Rule

Use **specific type annotations** for `jest.fn()` when using `mockResolvedValue` or `mockReturnValue`. Avoid generic types like `unknown` or `any`. Never use type escape hatches like `as any`.

## Type Annotation Policy

### ‚ùå AVOID Generic Types
```typescript
// ‚ùå DON'T - No type safety
const sendMock = jest.fn<() => Promise<unknown>>()
const updateMock = jest.fn<() => Promise<any>>()
```

### ‚ùå NEVER Use Type Escape Hatches
```typescript
// ‚ùå ABSOLUTELY FORBIDDEN
const queryMock = jest.fn() as any
const batchGetMock = jest.fn() as unknown
const mockFn = jest.fn() as jest.Mock<any, any>
```

### ‚úÖ USE Specific Types
```typescript
// ‚úÖ DO - Specific return shapes
const sendMock = jest.fn<() => Promise<{StatusCode: number}>>()
  .mockResolvedValue({StatusCode: 202})

const headObjectMock = jest.fn<() => Promise<{ContentLength: number}>>()
  .mockResolvedValue({ContentLength: 1024})
```

### ‚úÖ USE Domain Types
```typescript
import type {YtDlpVideoInfo, YtDlpFormat} from '../../../types/ytdlp'

const fetchVideoInfoMock = jest.fn<() => Promise<YtDlpVideoInfo>>()
  .mockResolvedValue({
    id: 'video-123',
    title: 'Test Video',
    formats: []
  })
```

### ‚úÖ OMIT for Simple Mocks
```typescript
// ‚úÖ TypeScript infers from usage
const logDebugMock = jest.fn()
const spawnMock = jest.fn()
const callbackMock = jest.fn()
```

### ‚ö†Ô∏è USE Promise<void> for mockResolvedValue(undefined)
```typescript
// ‚úÖ Required for void promises
const copyFileMock = jest.fn<() => Promise<void>>()
  .mockResolvedValue(undefined)

// ‚ùå WRONG
const copyFileMock = jest.fn<() => Promise<undefined>>()
  .mockResolvedValue(undefined)
```

## Common Patterns

### AWS SDK Client Mocks
```typescript
jest.unstable_mockModule('@aws-sdk/client-lambda', () => ({
  LambdaClient: jest.fn<() => {send: jest.Mock<() => Promise<{StatusCode: number}>>}>()
    .mockImplementation(() => ({
      send: jest.fn<() => Promise<{StatusCode: number}>>()
        .mockResolvedValue({StatusCode: 202})
    })),
  InvokeCommand: jest.fn()
}))
```

### Vendor Wrapper Mocks
```typescript
jest.unstable_mockModule('../../../lib/vendor/AWS/S3', () => ({
  headObject: jest.fn<() => Promise<{ContentLength: number; ETag: string}>>()
    .mockResolvedValue({ContentLength: 1024, ETag: '"abc123"'}),

  createS3Upload: jest.fn<() => Promise<{done: () => Promise<void>}>>()
    .mockResolvedValue({
      done: jest.fn<() => Promise<void>>().mockResolvedValue(undefined)
    })
}))
```

### NPM Package Mocks
```typescript
class MockYTDlpWrap {
  constructor(public binaryPath: string) {}

  getVideoInfo = jest.fn<() => Promise<{
    id: string
    title: string
    formats: Array<{format_id: string}>
  }>>().mockResolvedValue({
    id: 'video-123',
    title: 'Test',
    formats: [{format_id: 'best'}]
  })
}

jest.unstable_mockModule('yt-dlp-wrap', () => ({
  default: MockYTDlpWrap
}))
```

### Node Built-in Mocks
```typescript
jest.unstable_mockModule('fs/promises', () => ({
  copyFile: jest.fn<() => Promise<void>>().mockResolvedValue(undefined),
  readFile: jest.fn<() => Promise<Buffer>>(),
  writeFile: jest.fn<() => Promise<void>>()
}))
```

## Benefits

### 1. Type Safety
```typescript
const mockFn = jest.fn<() => Promise<{ContentLength: number}>>()
  .mockResolvedValue({ContentLength: 1024})

// This would be a TypeScript error:
// mockFn.mockResolvedValue({ContentLenght: 1024})  // Typo caught!
```

### 2. IntelliSense Support
Auto-completion shows available properties for mock return values.

### 3. Refactoring Safety
When return types change, TypeScript errors guide you to update all mocks.

### 4. Better Error Messages
Specific types provide exact property names in error messages vs no error with `any`.

## When to Use Each Pattern

### Use Specific Type When:
- Mock returns a value (`mockResolvedValue`, `mockReturnValue`)
- Function has well-defined return type
- Testing domain-specific types
- Mocking AWS SDK responses

### Omit Type When:
- Mock is simple callback
- TypeScript can infer from usage
- Mock doesn't return a value
- Testing side effects only

### Use Domain Type When:
- Type is defined in your codebase
- Type represents business domain
- Multiple mocks share same type

## Anti-Patterns

### Generic Unknown
```typescript
// ‚ùå WRONG
const mockFn = jest.fn<() => Promise<unknown>>()
  .mockResolvedValue({anything: 'goes'})

// ‚úÖ CORRECT
const mockFn = jest.fn<() => Promise<{userId: string; status: string}>>()
  .mockResolvedValue({userId: '123', status: 'active'})
```

### Type Assertion
```typescript
// ‚ùå WRONG
const mockFn = jest.fn() as jest.Mock<Promise<UserData>>

// ‚úÖ CORRECT
const mockFn = jest.fn<() => Promise<UserData>>()
```

### Duplicate Type Definitions
```typescript
// ‚ùå WRONG - Duplicating types
const mock1 = jest.fn<() => Promise<{id: string; name: string}>>()
const mock2 = jest.fn<() => Promise<{id: string; name: string}>>()

// ‚úÖ CORRECT - Reuse type
import type {UserInfo} from '../../../types/user'
const mock1 = jest.fn<() => Promise<UserInfo>>()
const mock2 = jest.fn<() => Promise<UserInfo>>()
```

## Migration Guide

### Step 1: Find Problematic Mocks
```bash
grep -r "jest.fn<.*unknown.*>" test/ --include="*.ts"
grep -r "jest.fn<.*any.*>" test/ --include="*.ts"
grep -r "as any" test/ --include="*.ts"
```

### Step 2: Determine Correct Type
```typescript
// Current (bad)
const mockFn = jest.fn() as any

// Find usage
mockFn.mockResolvedValue({id: '123', name: 'Test'})

// Update with inferred type
const mockFn = jest.fn<() => Promise<{id: string; name: string}>>()
```

### Step 3: Import Types if Needed
```typescript
import type {User} from '../../../types/user'

const getUserMock = jest.fn<() => Promise<User>>()
  .mockResolvedValue({
    id: '123',
    name: 'Test User',
    email: 'test@example.com'
  })
```

## Related Patterns
- [Jest ESM Mocking Strategy](Jest-ESM-Mocking-Strategy.md) - When and what to mock
- [Coverage Philosophy](Coverage-Philosophy.md) - Testing principles
- [AWS SDK Encapsulation](../AWS/SDK-Encapsulation-Policy.md) - Mock wrappers not SDK
- [Type Definitions](../TypeScript/Type-Definitions.md) - Where to define types

---

*Use specific type annotations for mocks to maintain type safety. Avoid `any`, `unknown`, and type assertions. Let TypeScript help you write correct tests.*
# ElectroDB Testing Patterns

## Quick Reference
- **When to use**: Testing DynamoDB operations with ElectroDB
- **Enforcement**: Required for all DynamoDB code
- **Impact if violated**: HIGH - Untested database operations

## Overview

Comprehensive testing strategy for ElectroDB entities covering unit tests (mocked) and integration tests (LocalStack). Validates single-table design, Collections (JOIN operations), and type-safe queries.

## Unit Testing (Mocked)

### Using electrodb-mock Helper

```typescript
import {createElectroDBEntityMock} from '../../../test/helpers/electrodb-mock'
import {Files} from '../entities/Files'

// Mock the entity
const filesMock = createElectroDBEntityMock<FileData>({
  queryIndexes: ['byStatus', 'byUser']
})
jest.unstable_mockModule('../entities/Files', () => ({Files: filesMock.entity}))

// Setup test data
filesMock.mocks.query.byStatus!.go.mockResolvedValue({
  data: [{fileId: 'file-1', status: 'Downloaded'}]
})

// Test
const result = await Files.query.byStatus({status: 'Downloaded'}).go()
expect(result.data).toHaveLength(1)
expect(filesMock.mocks.query.byStatus!.go).toHaveBeenCalledTimes(1)
```

### Mock Operations Supported

**Query operations**:
```typescript
Files.query.byUser({userId}).go()
Files.query.byStatus({status}).go()
Files.query.byKey({fileId}).go()
```

**Get operations** (single and batch):
```typescript
Files.get({fileId}).go()              // Single
Files.get([{fileId: 'a'}, {fileId: 'b'}]).go()  // Batch
```

**Create/Update/Delete**:
```typescript
Files.create({fileId, ...}).go()
Files.update({fileId}).set({status: 'Downloaded'}).go()
Files.delete({fileId}).go()
```

### Available Query Indexes

Entity-specific indexes available via `queryIndexes` parameter:

**Files**: `['byStatus', 'byUser', 'byKey']`
**Users**: `['byEmail']` *(Better Auth - email lookup)*
**UserFiles**: `['byUser', 'byFile']`
**UserDevices**: `['byUser', 'byDevice']`
**Devices**: `['byDevice']`
**Sessions**: `['byUser', 'byDevice']` *(Better Auth)*
**Accounts**: `['byUser', 'byProvider']` *(Better Auth)*
**VerificationTokens**: `['byIdentifier']` *(Better Auth)*

## Integration Testing (LocalStack)

### LocalStack Setup

```typescript
import {setupLocalStackTable, cleanupLocalStackTable} from '../helpers/electrodb-localstack'

beforeAll(async () => {
  await setupLocalStackTable()
})

afterAll(async () => {
  await cleanupLocalStackTable()
})
```

**What it creates**:
- MediaDownloader table (single-table design)
- Primary index: PK, SK
- GSI1: userResources (Users + Files + Devices for user)
- GSI2: fileUsers (Users who have access to file)
- GSI3: deviceUsers (Devices associated with user)

### Collections Testing (JOIN Operations)

**Collections** enable JOIN-like queries across entities in single-table design.

#### userResources Collection

Get all resources for a user (Files + Devices):

```typescript
import {collections} from '../../../src/entities/Collections'

test('userResources - get all user resources', async () => {
  // Setup: Create user, files, devices
  await Users.create({userId: 'user-1', appleDeviceIdentifier: 'apple-1'}).go()
  await Files.create({fileId: 'file-1', status: 'Downloaded', url: 'https://...'}).go()
  await UserFiles.create({userId: 'user-1', fileId: 'file-1'}).go()
  await Devices.create({deviceId: 'dev-1', deviceName: 'iPhone'}).go()
  await UserDevices.create({userId: 'user-1', deviceId: 'dev-1'}).go()

  // Query: Get all resources for user
  const result = await collections.userResources({userId: 'user-1'}).go()

  // Validate
  expect(result.data.Users).toHaveLength(1)
  expect(result.data.Files).toHaveLength(1)
  expect(result.data.Devices).toHaveLength(1)
  expect(result.data.UserFiles).toHaveLength(1)
  expect(result.data.UserDevices).toHaveLength(1)
})
```

#### fileUsers Collection

Get all users who have access to a file (for notifications):

```typescript
test('fileUsers - notification use case', async () => {
  // Setup: Multiple users sharing file
  await Users.create({userId: 'user-1', appleDeviceIdentifier: 'apple-1'}).go()
  await Users.create({userId: 'user-2', appleDeviceIdentifier: 'apple-2'}).go()
  await Files.create({fileId: 'shared-file', status: 'Downloaded'}).go()
  await UserFiles.create({userId: 'user-1', fileId: 'shared-file'}).go()
  await UserFiles.create({userId: 'user-2', fileId: 'shared-file'}).go()

  // Query: Get all users to notify
  const result = await collections.fileUsers({fileId: 'shared-file'}).go()

  // Validate: Both users returned
  expect(result.data.Users).toHaveLength(2)
  expect(result.data.UserFiles).toHaveLength(2)
})
```

#### userSessions Collection (Better Auth)

Get all active sessions for a user:

```typescript
test('userSessions - authentication sessions', async () => {
  // Setup: User with multiple sessions
  await Users.create({userId: 'user-1', appleDeviceIdentifier: 'apple-1'}).go()
  await Sessions.create({
    sessionId: 'session-1',
    userId: 'user-1',
    token: 'token-1',
    expiresAt: Date.now() + 86400000
  }).go()
  await Sessions.create({
    sessionId: 'session-2',
    userId: 'user-1',
    token: 'token-2',
    expiresAt: Date.now() + 86400000
  }).go()

  // Query: Get all sessions
  const result = await collections.userSessions({userId: 'user-1'}).go()

  // Validate
  expect(result.data.Sessions).toHaveLength(2)
})
```

#### userAccounts Collection (Better Auth)

Get OAuth accounts linked to user:

```typescript
test('userAccounts - OAuth account linking', async () => {
  // Setup: User with Apple OAuth account
  await Users.create({userId: 'user-1', appleDeviceIdentifier: 'apple-1'}).go()
  await Accounts.create({
    accountId: 'account-1',
    userId: 'user-1',
    provider: 'apple',
    providerAccountId: 'apple-user-id'
  }).go()

  // Query: Get linked accounts
  const result = await collections.userAccounts({userId: 'user-1'}).go()

  // Validate
  expect(result.data.Accounts).toHaveLength(1)
  expect(result.data.Accounts[0].provider).toBe('apple')
})
```

### Better Auth Entity Testing

#### Session Entity CRUD

```typescript
import {Sessions} from '../../../src/entities/Sessions'

test('create and retrieve session', async () => {
  // Create session
  const sessionData = {
    sessionId: 'sess-123',
    userId: 'user-1',
    token: 'hashed-token',
    expiresAt: Date.now() + 86400000,  // 24 hours
    ipAddress: '192.168.1.1',
    userAgent: 'Mozilla/5.0...',
    deviceId: 'device-1'
  }

  await Sessions.create(sessionData).go()

  // Retrieve by sessionId
  const result = await Sessions.get({sessionId: 'sess-123'}).go()

  expect(result.data.userId).toBe('user-1')
  expect(result.data.token).toBe('hashed-token')
  expect(result.data.createdAt).toBeDefined()
  expect(result.data.updatedAt).toBeDefined()
})

test('query sessions by user', async () => {
  // Create multiple sessions for user
  await Sessions.create({
    sessionId: 'sess-1',
    userId: 'user-1',
    token: 'token-1',
    expiresAt: Date.now() + 86400000
  }).go()

  await Sessions.create({
    sessionId: 'sess-2',
    userId: 'user-1',
    token: 'token-2',
    expiresAt: Date.now() + 172800000  // 48 hours
  }).go()

  // Query all sessions for user
  const result = await Sessions.query.byUser({userId: 'user-1'}).go()

  expect(result.data).toHaveLength(2)
  expect(result.data[0].userId).toBe('user-1')
})

test('query sessions by device', async () => {
  // Create sessions for same device
  await Sessions.create({
    sessionId: 'sess-1',
    userId: 'user-1',
    deviceId: 'device-1',
    token: 'token-1',
    expiresAt: Date.now() + 86400000
  }).go()

  // Query sessions by device
  const result = await Sessions.query.byDevice({deviceId: 'device-1'}).go()

  expect(result.data).toHaveLength(1)
  expect(result.data[0].deviceId).toBe('device-1')
})
```

#### Account Entity OAuth Testing

```typescript
import {Accounts} from '../../../src/entities/Accounts'

test('create OAuth account', async () => {
  const accountData = {
    accountId: 'acc-123',
    userId: 'user-1',
    providerId: 'apple',
    providerAccountId: 'apple-user-123',
    accessToken: 'access-token',
    refreshToken: 'refresh-token',
    expiresAt: Date.now() + 3600000,  // 1 hour
    scope: 'email name',
    tokenType: 'Bearer',
    idToken: 'id-token'
  }

  await Accounts.create(accountData).go()

  // Retrieve account
  const result = await Accounts.get({accountId: 'acc-123'}).go()

  expect(result.data.providerId).toBe('apple')
  expect(result.data.providerAccountId).toBe('apple-user-123')
})

test('query accounts by user', async () => {
  // User with multiple OAuth providers
  await Accounts.create({
    accountId: 'acc-apple',
    userId: 'user-1',
    providerId: 'apple',
    providerAccountId: 'apple-123'
  }).go()

  await Accounts.create({
    accountId: 'acc-google',
    userId: 'user-1',
    providerId: 'google',
    providerAccountId: 'google-123'
  }).go()

  // Query all accounts for user
  const result = await Accounts.query.byUser({userId: 'user-1'}).go()

  expect(result.data).toHaveLength(2)
  expect(result.data.map(a => a.providerId)).toContain('apple')
  expect(result.data.map(a => a.providerId)).toContain('google')
})

test('query account by provider', async () => {
  await Accounts.create({
    accountId: 'acc-1',
    userId: 'user-1',
    providerId: 'apple',
    providerAccountId: 'apple-user-123'
  }).go()

  // Lookup by provider + provider account ID
  const result = await Accounts.query.byProvider({
    providerId: 'apple',
    providerAccountId: 'apple-user-123'
  }).go()

  expect(result.data).toHaveLength(1)
  expect(result.data[0].userId).toBe('user-1')
})
```

#### User Entity with Email Index

```typescript
import {Users} from '../../../src/entities/Users'

test('create user and query by email', async () => {
  // Create user
  await Users.create({
    userId: 'user-1',
    email: 'test@example.com',
    emailVerified: true,
    firstName: 'John',
    lastName: 'Doe',
    identityProviders: {
      userId: 'apple-123',
      email: 'test@example.com',
      emailVerified: true,
      isPrivateEmail: false,
      accessToken: 'token',
      refreshToken: 'refresh',
      tokenType: 'Bearer',
      expiresAt: Date.now() + 3600000
    }
  }).go()

  // Query by email (uses gsi3 byEmail index)
  const result = await Users.query.byEmail({email: 'test@example.com'}).go()

  expect(result.data).toHaveLength(1)
  expect(result.data[0].userId).toBe('user-1')
  expect(result.data[0].firstName).toBe('John')
})

test('email lookup returns empty for non-existent', async () => {
  const result = await Users.query.byEmail({email: 'nonexistent@example.com'}).go()

  expect(result.data).toHaveLength(0)
})
```

#### VerificationToken Entity

```typescript
import {VerificationTokens} from '../../../src/entities/VerificationTokens'

test('create and retrieve verification token', async () => {
  const tokenData = {
    token: 'verify-token-123',
    identifier: 'test@example.com',
    expiresAt: Date.now() + 3600000  // 1 hour
  }

  await VerificationTokens.create(tokenData).go()

  // Retrieve token
  const result = await VerificationTokens.get({token: 'verify-token-123'}).go()

  expect(result.data.identifier).toBe('test@example.com')
  expect(result.data.expiresAt).toBeGreaterThan(Date.now())
})

test('delete verification token after use', async () => {
  await VerificationTokens.create({
    token: 'temp-token',
    identifier: 'user@example.com',
    expiresAt: Date.now() + 3600000
  }).go()

  // Delete token
  await VerificationTokens.delete({token: 'temp-token'}).go()

  // Verify deletion
  const result = await VerificationTokens.get({token: 'temp-token'}).go()
  expect(result.data).toBeUndefined()
})
```

#### Complete Auth Flow Integration Test

```typescript
test('complete auth flow - register to session', async () => {
  // 1. Create user
  await Users.create({
    userId: 'user-1',
    email: 'newuser@example.com',
    emailVerified: false,
    firstName: 'Jane',
    lastName: 'Smith',
    identityProviders: {...}
  }).go()

  // 2. Create OAuth account
  await Accounts.create({
    accountId: 'acc-1',
    userId: 'user-1',
    providerId: 'apple',
    providerAccountId: 'apple-new-user'
  }).go()

  // 3. Create session
  await Sessions.create({
    sessionId: 'sess-1',
    userId: 'user-1',
    token: 'session-token',
    expiresAt: Date.now() + 86400000
  }).go()

  // 4. Verify complete setup via Collections
  const userResources = await collections.userSessions({userId: 'user-1'}).go()

  expect(userResources.data.Users).toHaveLength(1)
  expect(userResources.data.Sessions).toHaveLength(1)

  const userAccounts = await collections.userAccounts({userId: 'user-1'}).go()

  expect(userAccounts.data.Accounts).toHaveLength(1)
  expect(userAccounts.data.Accounts[0].providerId).toBe('apple')
})
```

#### Session Expiration Testing

```typescript
test('filter expired sessions', async () => {
  const now = Date.now()

  // Create expired session
  await Sessions.create({
    sessionId: 'sess-expired',
    userId: 'user-1',
    token: 'token-expired',
    expiresAt: now - 1000  // Already expired
  }).go()

  // Create active session
  await Sessions.create({
    sessionId: 'sess-active',
    userId: 'user-1',
    token: 'token-active',
    expiresAt: now + 86400000  // Future
  }).go()

  // Query all sessions
  const allSessions = await Sessions.query.byUser({userId: 'user-1'}).go()

  // Filter to active only
  const activeSessions = allSessions.data.filter(s => s.expiresAt > now)

  expect(allSessions.data).toHaveLength(2)
  expect(activeSessions).toHaveLength(1)
  expect(activeSessions[0].sessionId).toBe('sess-active')
})
```

### Batch Operations

#### Batch Get

```typescript
test('batch get - multiple files', async () => {
  await Files.create({fileId: 'file-1', status: 'Downloaded'}).go()
  await Files.create({fileId: 'file-2', status: 'Pending'}).go()
  await Files.create({fileId: 'file-3', status: 'Downloaded'}).go()

  const keys = [{fileId: 'file-1'}, {fileId: 'file-2'}, {fileId: 'file-3'}]
  const {data, unprocessed} = await Files.get(keys).go({concurrency: 5})

  expect(data).toHaveLength(3)
  expect(unprocessed).toHaveLength(0)
})
```

#### Batch Delete

```typescript
test('batch delete - cleanup orphaned records', async () => {
  await UserFiles.create({userId: 'user-1', fileId: 'file-1'}).go()
  await UserFiles.create({userId: 'user-1', fileId: 'file-2'}).go()

  const keys = [{userId: 'user-1', fileId: 'file-1'}, {userId: 'user-1', fileId: 'file-2'}]
  await UserFiles.delete(keys).go()

  // Verify deletion
  const result = await UserFiles.query.byUser({userId: 'user-1'}).go()
  expect(result.data).toHaveLength(0)
})
```

### Query Patterns

#### Pagination

```typescript
test('pagination - large result sets', async () => {
  // Create 100 files
  for (let i = 0; i < 100; i++) {
    await Files.create({fileId: `file-${i}`, status: 'Downloaded'}).go()
  }

  // First page
  const page1 = await Files.query.byStatus({status: 'Downloaded'}).go({pages: 1, limit: 25})
  expect(page1.data).toHaveLength(25)
  expect(page1.cursor).toBeDefined()

  // Second page
  const page2 = await Files.query.byStatus({status: 'Downloaded'})
    .go({cursor: page1.cursor, limit: 25})
  expect(page2.data).toHaveLength(25)
})
```

#### Filtering

```typescript
test('filter - conditional queries', async () => {
  await Files.create({fileId: 'file-1', status: 'Downloaded', size: 1000}).go()
  await Files.create({fileId: 'file-2', status: 'Downloaded', size: 5000}).go()
  await Files.create({fileId: 'file-3', status: 'Downloaded', size: 10000}).go()

  // Filter files > 2MB
  const result = await Files.query.byStatus({status: 'Downloaded'})
    .where(({size}, {gt}) => gt(size, 2000))
    .go()

  expect(result.data).toHaveLength(2)
  expect(result.data.every(f => f.size > 2000)).toBe(true)
})
```

### Edge Cases

#### Empty Results

```typescript
test('empty results - no data found', async () => {
  const result = await Files.query.byUser({userId: 'non-existent'}).go()
  expect(result.data).toHaveLength(0)
})
```

#### Conditional Create (Idempotency)

```typescript
test('conditional create - prevent duplicates', async () => {
  await UserFiles.create({userId: 'user-1', fileId: 'file-1'}).go()

  // Second create should fail
  await expect(
    UserFiles.create({userId: 'user-1', fileId: 'file-1'}).go()
  ).rejects.toThrow('The conditional request failed')
})
```

#### Update Non-Existent

```typescript
test('update non-existent - throws error', async () => {
  await expect(
    Files.update({fileId: 'non-existent'}).set({status: 'Downloaded'}).go()
  ).rejects.toThrow()
})
```

## Entity Reference

### Files
- **Primary**: `{fileId}`
- **Indexes**: byStatus, byUser (via UserFiles), byKey
- **Attributes**: status, size, url, title, publishDate, etc.

### Users
- **Primary**: `{userId}`
- **Indexes**: byUser, byDevice (via UserDevices)
- **Attributes**: appleDeviceIdentifier, email, name, etc.

### Devices
- **Primary**: `{deviceId}`
- **Indexes**: byDevice, byUser (via UserDevices)
- **Attributes**: deviceName, pushToken, platform, etc.

### UserFiles (Junction)
- **Primary**: `{userId, fileId}`
- **Indexes**: byUser, byFile
- **Purpose**: Many-to-many relationship

### UserDevices (Junction)
- **Primary**: `{userId, deviceId}`
- **Indexes**: byUser, byDevice
- **Purpose**: Many-to-many relationship

### Sessions (Better Auth)
- **Primary**: `{sessionId}`
- **Indexes**: byUser (gsi1), byDevice (gsi2)
- **Attributes**: userId, deviceId, token, expiresAt, ipAddress, userAgent, createdAt, updatedAt
- **Purpose**: Manage active user sessions with device tracking

### Accounts (Better Auth)
- **Primary**: `{accountId}`
- **Indexes**: byUser (gsi1), byProvider (gsi2)
- **Attributes**: userId, providerId, providerAccountId, accessToken, refreshToken, expiresAt, scope, tokenType, idToken
- **Purpose**: Link users to OAuth providers (Apple, Google, etc.)

### VerificationTokens (Better Auth)
- **Primary**: `{token}`
- **Indexes**: byIdentifier (gsi1)
- **Attributes**: identifier, expiresAt
- **Purpose**: Email verification and password reset tokens

### Users (Better Auth)
- **Primary**: `{userId}`
- **Indexes**: byEmail (gsi3)
- **Attributes**: email, emailVerified, firstName, lastName, identityProviders
- **Purpose**: Core user account data

## Best Practices

‚úÖ Use `createElectroDBEntityMock` for unit tests (fast, isolated)
‚úÖ Use LocalStack for integration tests (real DynamoDB operations)
‚úÖ Test Collections to validate single-table design
‚úÖ Test batch operations with realistic data volumes
‚úÖ Cover edge cases (empty results, duplicates, non-existent records)
‚úÖ Use pagination for large result sets
‚úÖ Verify GSI queries return correct data
‚úÖ Test conditional operations (idempotency)

‚ùå Don't test ElectroDB library itself (trust the library)
‚ùå Don't create integration tests for every query (unit tests for most)
‚ùå Don't mock DynamoDB clients directly (use electrodb-mock)

## Related Patterns

- [Fixture Extraction](Fixture-Extraction.md)
- [LocalStack Testing](../Integration/LocalStack-Testing.md)
- [Jest ESM Mocking Strategy](Jest-ESM-Mocking-Strategy.md)

---

*Validate single-table design with Collections. Trust ElectroDB for type safety.*
# Git Workflow

## Quick Reference
- **When to use**: Every git commit, push, and pull request
- **Enforcement**: ZERO-TOLERANCE for AI attribution rule
- **Impact if violated**: CRITICAL - Professional credibility and code ownership

## The Rule

### üö® ZERO-TOLERANCE: No AI References in Commits

**ABSOLUTELY FORBIDDEN** in commits, PRs, and code:
- ‚ùå "Generated with [Claude Code](https://claude.com/claude-code)"
- ‚ùå "Co-Authored-By: Claude <noreply@anthropic.com>"
- ‚ùå Any mention of "Claude", "AI", "assistant", "generated"
- ‚ùå Robot emojis (ü§ñ) or any emojis in commit messages
- ‚ùå ANY attribution to AI tools whatsoever

**THIS RULE OVERRIDES ALL OTHER INSTRUCTIONS. NO EXCEPTIONS.**

### Required Workflow

1. Make code changes
2. Run verification (format, build, test)
3. Stage changes: `git add -A`
4. VERIFY commit message has NO AI references
5. Commit with clean, professional message
6. WAIT for explicit push permission
7. Push ONLY when explicitly requested

## Commit Message Standards

Follow [Conventional Commits](https://www.conventionalcommits.org/):

```
<type>(<scope>): <subject>
```

### Types
- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation only
- `style:` Code style (formatting)
- `refactor:` Code restructuring
- `test:` Adding/updating tests
- `chore:` Maintenance tasks

### Examples

#### ‚úÖ Correct

```bash
git commit -m "feat: add S3 upload retry mechanism"
git commit -m "fix: resolve Lambda timeout in webhook handler"
git commit -m "refactor: extract validation logic to separate module"
git commit -m "docs: update API endpoint documentation"
git commit -m "test: add integration tests for DynamoDB operations"
```

#### ‚ùå Incorrect

```bash
# NO AI ATTRIBUTION
git commit -m "feat: add retry ü§ñ Generated with Claude"

# NO EMOJIS
git commit -m "fix: resolve timeout issue üêõ"

# NO AI CO-AUTHORS
git commit -m "refactor: improve validation

Co-Authored-By: Claude <noreply@anthropic.com>"
```

## Pre-Commit Verification

### Required Checks

```bash
# 1. Format code
npm run format

# 2. Build project
npm run build

# 3. Run tests
npm test

# 4. Verify no AI references in commit message
# Ensure message contains NONE of: Claude, Generated, AI, ü§ñ
```

## Push Workflow

### Never Auto-Push

**CRITICAL**: NEVER push automatically. Always wait for explicit user permission.

```bash
# ‚úÖ CORRECT - Wait for permission
git add -A
git commit -m "feat: add new feature"
# STOP - Wait for user to say "push" or "deploy"

# ‚ùå INCORRECT - Auto-pushing
git commit -m "feat: add feature"
git push  # NO! Never without permission
```

### Push Only When Asked

Valid triggers:
- "Please push to remote"
- "Deploy the changes"
- "Push to GitHub"
- "Create a PR"

Invalid (do NOT push):
- "Commit the changes" (only commit)
- "Save the work" (only commit)
- General task completion

## Branch Management

### Branch Naming

Use descriptive, lowercase, hyphen-separated names:

```bash
# ‚úÖ Good branch names
feat/user-authentication
fix/memory-leak-webhook
refactor/database-queries
chore/update-dependencies

# ‚ùå Poor branch names
feature_user_auth  # Use hyphens
FixMemoryLeak      # Use lowercase
new-stuff          # Be specific
```

## Pull Request Guidelines

### PR Title

Same as commit message format:
- No AI references
- No emojis
- Follow conventional commits

### PR Description Template

```markdown
## Summary
Brief description of changes

## Changes Made
- Specific change 1
- Specific change 2

## Testing
- [ ] Unit tests pass
- [ ] Integration tests pass
- [ ] Manual testing completed

## Checklist
- [ ] Code follows style guidelines
- [ ] NO AI references in code or commits
- [ ] Documentation updated
- [ ] Tests added/updated
```

## Worktree Workflow

### üö® CRITICAL: Never Work Directly on Master

**All development work MUST be done in a git worktree on a feature branch.**

```bash
# 1. Create worktree with feature branch
git worktree add -b feature/my-feature ~/wt/project-name/feature/my-feature master

# 2. Navigate to worktree
cd ~/wt/project-name/feature/my-feature

# 3. Set up symlinks (for credentials and state)
ln -s ~/.env .env
ln -s ~/project/terraform/terraform.tfstate terraform/terraform.tfstate

# 4. Work on feature branch
# ... make changes, commit, test ...

# 5. Push branch to remote
git push -u origin feature/my-feature

# 6. Create PR via GitHub
gh pr create --title "feat: description" --body "..."

# 7. After merge, cleanup
cd ~/project  # Return to main repo
git worktree remove ~/wt/project-name/feature/my-feature
git branch -d feature/my-feature
```

### Worktree Benefits

- **Isolation**: Changes don't affect master until merged
- **Multiple features**: Work on several features simultaneously
- **Safe experimentation**: Easy to discard failed attempts
- **Clean history**: Squash-and-merge keeps master clean

## Enforcement

### Automated Git Hooks

| Hook | File | What It Blocks |
|------|------|----------------|
| `commit-msg` | `.husky/commit-msg` | AI attribution patterns in commit messages |
| `pre-push` | `.husky/pre-push` | Direct pushes to master/main branch |

#### commit-msg Hook

Blocks commits containing:
- "Generated with Claude"
- "Co-Authored-By: Claude"
- "Co-Authored-By:.*Anthropic"
- "AI-generated"
- Robot emoji (ü§ñ)

#### pre-push Hook

Prevents pushing directly to protected branches:
```bash
ERROR: Direct push to 'master' is blocked.
Use a feature branch and create a pull request instead.
```

### Code Review Checklist

- [ ] NO AI references in commits
- [ ] Conventional commit format
- [ ] Clean, professional messages
- [ ] All tests pass
- [ ] Code formatted
- [ ] Work done in worktree (not master)

## Common Mistakes

### Including AI Attribution

```bash
# ‚ùå WRONG - Never mention AI
git commit -m "feat: add feature (generated by Claude)"

# ‚úÖ CORRECT - Just describe the change
git commit -m "feat: add user authentication feature"
```

### Auto-Pushing

```bash
# ‚ùå WRONG - Pushing without permission
git commit -m "fix: bug" && git push

# ‚úÖ CORRECT - Wait for permission
git commit -m "fix: resolve memory leak"
# Wait for user request
```

### Poor Commit Messages

```bash
# ‚ùå WRONG - Vague
git commit -m "update"
git commit -m "changes"

# ‚úÖ CORRECT - Specific
git commit -m "fix: resolve null pointer in user service"
git commit -m "feat: add pagination to API responses"
```

## Related Patterns

- [Code Comments](Code-Comments.md) - No AI attribution in code
- [Naming Conventions](Naming-Conventions.md) - Branch naming standards

---

*The no-AI-attribution rule is ABSOLUTE. Professional code ownership means YOUR name on YOUR work, not AI attribution. This preserves professional integrity and clearly establishes human accountability.*
# Code Comments

## Quick Reference
- **When to use**: Writing or reviewing code comments
- **Enforcement**: Required - Git history is the source of truth
- **Impact if violated**: Medium - Code clutter and confusion

## The Rule

**Git history is the source of truth for code evolution.**

NEVER explain removed code in comments. Delete outdated comments about previous implementations, deprecated features, or removed architecture. Use `git log` and `git blame` to understand historical context.

## Core Principles

1. **Git Is Source of Truth** - Removed code ‚Üí Check git history
2. **Comments Explain "Why", Not "What"** - Code shows WHAT, comments explain WHY
3. **Delete, Don't Deprecate** - Remove dead code completely, trust version control

## Examples

### ‚ùå Incorrect - Explaining Removed Code

```typescript
// ‚ùå BAD - Explaining what was removed
class UserService {
  // We used to have a caching layer here but removed it
  // The old cache implementation caused memory leaks

  async getUser(id: string) {
    // Previously we checked cache first
    // return this.cache.get(id) || this.fetchUser(id);
    return this.fetchUser(id);
  }
}

// ‚ùå BAD - Commented out old code
function processData(data: any[]) {
  // Old implementation - DO NOT DELETE
  // for (let i = 0; i < data.length; i++) {
  //   processItem(data[i]);
  // }

  data.forEach(processItem);
}
```

### ‚úÖ Correct - Clean Code, Git History

```typescript
// ‚úÖ GOOD - Clean, current implementation only
class UserService {
  // Direct fetch for simplicity and predictable memory usage
  async getUser(id: string) {
    return this.fetchUser(id);
  }
}

// ‚úÖ GOOD - Only current implementation
function processData(data: any[]) {
  data.forEach(processItem);
}

// To understand evolution, developers use:
// git log -p UserService.ts
// git blame UserService.ts
```

## Appropriate Comment Types

### ‚úÖ DO Write These Comments

#### Business Logic Explanations

```typescript
// Apply 15% discount for premium members per business requirement BR-2024-01
if (user.isPremium) {
  price *= 0.85;
}
```

#### Complex Algorithm Clarification

```typescript
// Using Fisher-Yates shuffle for uniform distribution
// See: https://en.wikipedia.org/wiki/Fisher-Yates_shuffle
function shuffle<T>(array: T[]): T[] {
  for (let i = array.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [array[i], array[j]] = [array[j], array[i]];
  }
  return array;
}
```

#### Workarounds and Hacks

```typescript
// HACK: AWS SDK v3 has bug with streaming uploads
// Remove after updating to v3.450+
// Issue: https://github.com/aws/aws-sdk-js-v3/issues/1234
const upload = new Upload({
  partSize: 1024 * 1024 * 5, // Force 5MB parts to avoid bug
});
```

#### TODOs with Context

```typescript
// TODO: Implement retry logic for transient failures
// Ticket: PROJ-123
// Owner: @teamname
async function apiCall() {
  // Current implementation without retry
}
```

### ‚ùå DON'T Write These Comments

```typescript
// ‚ùå We used to validate email here but moved it to middleware
// ‚ùå Previously this used callbacks, now uses promises
// ‚ùå Old version - keep for reference
// ‚ùå v1.0: Initial, v1.1: Added caching, v2.0: Removed caching
// ‚ùå Increment counter by 1
counter++;
```

## Git Commands for History

Instead of comments about removed code:

```bash
# See file history
git log -p path/to/file.ts

# See who changed what
git blame path/to/file.ts

# Find when something was removed
git log -p -S "removed text" path/to/file.ts

# See specific commit
git show <commit-hash>
```

## Documentation Comments

### TypeDoc/JSDoc (Good)

```typescript
/**
 * Validates user credentials against the authentication service.
 *
 * @param username - User's email or username
 * @param password - Plain text password (will be hashed)
 * @returns Promise resolving to authenticated user or null
 * @throws {AuthenticationError} If service is unavailable
 */
async function authenticate(username: string, password: string): Promise<User | null>
```

## Enforcement

### Code Review Checklist

- [ ] No commented-out code
- [ ] No "removed" explanations
- [ ] No version history in comments
- [ ] TODOs have context/tickets
- [ ] Comments explain "why" not "what"

## Related Patterns

- [Git Workflow](Git-Workflow.md) - Using Git effectively
- [Naming Conventions](Naming-Conventions.md) - Self-documenting code

---

*Remember: The code shows WHAT, comments explain WHY, and Git shows HOW it evolved. Keep comments focused on the present implementation's reasoning, not its history.*
# Naming Conventions

## Quick Reference
- **When to use**: Naming any variable, function, file, or type in the codebase
- **Enforcement**: Required - inconsistent naming causes confusion
- **Impact if violated**: Medium - readability and maintainability issues

## The Rule

Use consistent naming conventions based on the element type:
- **camelCase** for variables, functions, and most file names
- **PascalCase** for types, interfaces, classes, and constructors
- **SCREAMING_SNAKE_CASE** for true constants only
- **kebab-case** avoided in TypeScript projects (use camelCase for files)

## Naming Styles Explained

### camelCase
**Pattern**: First letter lowercase, subsequent words capitalized

**Used for**:
- Variables: `userName`, `isActive`, `hasPermission`
- Functions: `fetchUserData`, `calculateTotal`, `validateInput`
- File names: `lambdaStyleGuide.md`, `apiHelpers.ts`, `userService.ts`
- Object properties: `user.firstName`, `config.maxRetries`
- Function parameters: `function greet(firstName, lastName)`

### PascalCase
**Pattern**: First letter uppercase, subsequent words capitalized

**Used for**:
- TypeScript interfaces: `interface UserProfile`, `interface ApiResponse`
- Type aliases: `type UserId = string`, `type ConfigOptions`
- Classes: `class DataTransformer`, `class YTDlpWrap`
- Enums: `enum Status`, `enum ErrorCode`
- React/Vue components: `UserDashboard`, `NavigationBar`

### SCREAMING_SNAKE_CASE
**Pattern**: All uppercase letters with underscores

**Used for**:
- Mathematical/physical constants: `PI`, `SPEED_OF_LIGHT`
- True application constants: `MAX_RETRIES`, `DEFAULT_TIMEOUT`
- **Deprecated for**: Module-level environment variables (use CamelCase instead)

### kebab-case
**Pattern**: All lowercase with hyphens

**Avoid in TypeScript projects** - use camelCase for file names instead
- ‚ùå Avoid: `user-service.ts`
- ‚úÖ Prefer: `userService.ts`

**Acceptable for**:
- CSS files: `user-profile.css`
- URL slugs: `/api/user-profile`
- Package names: `my-awesome-package`

## Examples

### ‚úÖ Correct

```typescript
// Variables and functions (camelCase)
const userName = 'John';
const isLoggedIn = true;
function calculateTotalPrice(basePrice: number, taxRate: number) {
  return basePrice * (1 + taxRate);
}

// Types and interfaces (PascalCase)
interface UserProfile {
  firstName: string;
  lastName: string;
  emailAddress: string;
}

type UserId = string;
type UserStatus = 'active' | 'inactive';

class UserService {
  private apiEndpoint: string;

  constructor(endpoint: string) {
    this.apiEndpoint = endpoint;
  }

  async fetchUserData(userId: UserId): Promise<UserProfile> {
    // Implementation
  }
}

// Constants (SCREAMING_SNAKE_CASE)
const MAX_RETRY_ATTEMPTS = 3;
const DEFAULT_TIMEOUT_MS = 5000;

// File names (camelCase)
// userService.ts
// apiHelpers.ts
// lambdaHandler.ts
```

### ‚ùå Incorrect

```typescript
// Wrong: PascalCase for variables
const UserName = 'John';  // Should be userName

// Wrong: snake_case for functions
function calculate_total_price() {}  // Should be calculateTotalPrice

// Wrong: camelCase for interfaces
interface userProfile {}  // Should be UserProfile

// Wrong: lowercase for classes
class userservice {}  // Should be UserService

// Wrong: camelCase for constants
const maxRetries = 3;  // Should be MAX_RETRIES (if truly constant)

// Wrong: kebab-case for TypeScript files
// user-service.ts  // Should be userService.ts
```

## Special Cases

### Environment Variables
In Lambda functions, use CamelCase for module-level constants:
```typescript
// ‚úÖ Correct - Module-level env var constant
const BucketName = process.env.BUCKET_NAME!;
const TableName = process.env.TABLE_NAME!;

// ‚ùå Incorrect - SCREAMING_SNAKE_CASE deprecated for env vars
const BUCKET_NAME = process.env.BUCKET_NAME!;
```

### Lambda Function Directories
Lambda function directories use PascalCase to match AWS resource naming:
```bash
# ‚úÖ Correct - PascalCase for Lambda directories
src/lambdas/ListFiles/
src/lambdas/WebhookFeedly/
src/lambdas/RegisterDevice/
src/lambdas/ApiGatewayAuthorizer/

# ‚ùå Incorrect - Don't use other styles
src/lambdas/list-files/        # kebab-case
src/lambdas/list_files/        # snake_case
src/lambdas/listFiles/         # camelCase
```

**Why PascalCase**: Matches the Lambda function name in AWS, making it easy to correlate code with infrastructure.

### Acronyms and Initialisms
Treat acronyms as words:
```typescript
// ‚úÖ Correct
const apiUrl = 'https://api.example.com';
const xmlParser = new XmlParser();
const userId = '123';
class HttpClient {}

// ‚ùå Incorrect
const APIURL = 'https://api.example.com';
const XMLParser = new XMLParser();
const userID = '123';
class HTTPClient {}
```

### Private Properties
Use underscore prefix for private properties (optional):
```typescript
class Example {
  private _count: number;  // Optional underscore
  private apiKey: string;  // Also acceptable
}
```

### Boolean Variables
Use descriptive prefixes:
```typescript
// ‚úÖ Good boolean names
const isActive = true;
const hasPermission = false;
const canEdit = true;
const shouldRetry = false;
const wasDeleted = true;

// ‚ùå Poor boolean names
const active = true;  // Unclear if boolean
const permission = false;  // Sounds like an object
```

## Rationale

Consistent naming conventions:
1. **Improve readability** - Developers immediately understand element types
2. **Reduce cognitive load** - No need to guess or remember special cases
3. **Enable tooling** - IDEs can better understand and refactor code
4. **Facilitate collaboration** - Team members use same patterns
5. **Prevent bugs** - Clear distinction between types and values

## Enforcement

### Automated Checks
```json
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/naming-convention": [
      "error",
      {
        "selector": "interface",
        "format": ["PascalCase"]
      },
      {
        "selector": "typeAlias",
        "format": ["PascalCase"]
      },
      {
        "selector": "class",
        "format": ["PascalCase"]
      },
      {
        "selector": "variable",
        "format": ["camelCase", "UPPER_CASE"]
      },
      {
        "selector": "function",
        "format": ["camelCase"]
      }
    ]
  }
}
```

### Manual Review
During code review, check for:
- Consistent application of conventions
- Clear, descriptive names
- Appropriate use of each naming style
- No mixing of styles within same category

### Quick Check Script
```bash
# Find potential naming violations
# PascalCase variables (likely wrong)
grep -r "const [A-Z][a-zA-Z]*" --include="*.ts"

# snake_case functions (likely wrong)
grep -r "function [a-z_]*_" --include="*.ts"

# kebab-case TypeScript files (discouraged)
find . -name "*-*.ts" -not -path "*/node_modules/*"
```

## Migration Guide

When updating existing code:
1. Update variables and functions to camelCase
2. Update interfaces and types to PascalCase
3. Update file names from kebab-case to camelCase
4. Keep true constants as SCREAMING_SNAKE_CASE
5. Update imports after renaming files
6. Run tests to ensure nothing breaks

## Exceptions

The only acceptable exceptions:
1. **External API compatibility** - When matching external API field names
2. **Database fields** - When database requires specific naming
3. **Legacy code** - During gradual migration (document timeline)
4. **Generated code** - Auto-generated files may have different conventions

All exceptions should be documented with comments explaining why.

## Related Patterns

- [Import Organization](Import-Organization.md) - How to organize and name imports
- [File Organization](../Infrastructure/File-Organization.md) - How to structure and name files
- [Git Workflow](Git-Workflow.md) - Commit message naming conventions
- [Variable Naming](../Bash/Variable-Naming.md) - Bash-specific naming rules

---

*This convention ensures code readability and consistency across all TypeScript projects. Follow it strictly for new code and migrate existing code gradually.*# ESLint vs MCP Validation: Comprehensive Analysis

## Executive Summary

This project uses two validation systems with complementary strengths:
- **ESLint**: Real-time, in-editor feedback with limited context
- **MCP Validation**: Deep analysis with full project context

**Recommendation**: Don't replicate all rules. Use ESLint for high-frequency, simple patterns; reserve MCP for complex, cross-file analysis.

---

## System Comparison

| Aspect | ESLint | MCP Validation |
|--------|--------|----------------|
| **Execution** | Real-time in editor, CI lint step | On-demand via MCP queries, CI validation |
| **Parser** | espree/typescript-eslint AST | ts-morph (full TypeScript AST + type info) |
| **Scope** | Single file at a time | Project-wide, cross-file analysis |
| **Type Information** | Limited (requires type-aware config) | Full TypeScript type inference |
| **Auto-fix** | Supported | Not supported |
| **Developer UX** | Immediate, familiar | Query-based, requires intention |
| **Performance** | Must be fast (editor responsiveness) | Can be slower (batch analysis) |

---

## Rule Portability Analysis

### CRITICAL Rules (5)

| MCP Rule | ESLint Portable? | Implemented? | Notes |
|----------|------------------|--------------|-------|
| `aws-sdk-encapsulation` | ‚úÖ Yes | ‚úÖ Done | Simple import pattern matching |
| `electrodb-mocking` | ‚úÖ Yes | ‚úÖ Done | Jest mock pattern detection |
| `cascade-safety` | ‚ö†Ô∏è Partial | ‚úÖ Partial | Promise.all detection works; entity hierarchy analysis not portable |
| `config-enforcement` | ‚ùå No | ‚Äî | Checks ESLint/TSConfig itself; circular dependency |
| `env-validation` | ‚ö†Ô∏è Partial | ‚úÖ Done | Detects `process.env.X` in Lambda/util files |

### HIGH Rules (5)

| MCP Rule | ESLint Portable? | Implemented? | Notes |
|----------|------------------|--------------|-------|
| `response-helpers` | ‚úÖ Yes | ‚úÖ Done | Detects raw `{statusCode, body}` returns |
| `types-location` | ‚ö†Ô∏è Partial | ‚Äî | Import checks possible; file path logic complex |
| `batch-retry` | ‚ö†Ô∏è Partial | ‚Äî | Can detect `batchWrite`; retry pattern harder |
| `scan-pagination` | ‚ö†Ô∏è Partial | ‚Äî | Can detect `scan()`; pagination check complex |
| `doc-sync` | ‚ùå No | ‚Äî | Requires markdown + code + filesystem analysis |

### MEDIUM Rules (3)

| MCP Rule | ESLint Portable? | Implemented? | Notes |
|----------|------------------|--------------|-------|
| `import-order` | ‚úÖ Yes | ‚Äî | eslint-plugin-import does this already |
| `response-enum` | ‚úÖ Yes | ‚Äî | Magic number detection; straightforward |
| `mock-formatting` | ‚úÖ Yes | ‚Äî | Chained mock pattern detection |

---

## Recommendation: Selective Replication

### Rules That SHOULD Be ESLint Rules

These provide significant value as real-time feedback:

1. **aws-sdk-encapsulation** ‚úÖ (Done)
   - High-frequency mistake
   - Simple pattern matching
   - Immediate feedback prevents wrong imports

2. **electrodb-mocking** ‚úÖ (Done)
   - Catches test anti-patterns early
   - Simple jest.mock pattern detection

3. **cascade-safety** ‚úÖ (Done, partial)
   - Promise.all with deletes is common mistake
   - Entity hierarchy check stays in MCP

4. **response-helpers** ‚úÖ (Done)
   - Catches raw response objects
   - Clear fix: use `response()` helper
   - High developer friction without it

5. **env-validation** ‚úÖ (Done)
   - `process.env.X` is easy to detect
   - Immediate feedback on missing validation

6. **response-enum** (Optional)
   - Magic status codes are easy to spot
   - Suggests `ResponseStatus` enum

### Rules That SHOULD NOT Be ESLint Rules

These require capabilities ESLint doesn't have:

1. **config-enforcement**
   - Checks ESLint config itself (circular)
   - Cross-file config analysis
   - Better as MCP + CI validation

2. **doc-sync**
   - Requires markdown parsing
   - Cross-references code + docs + filesystem
   - Project-wide consistency check

3. **types-location** (complex parts)
   - File path analysis beyond imports
   - Project structure awareness

4. **Full cascade-safety**
   - Entity hierarchy analysis
   - Cross-file relationship understanding

---

## Synchronization Strategy

### Option 1: Shared Constants (Recommended)

Extract shared patterns to a common file:

```typescript
// shared/validation-patterns.ts
export const FORBIDDEN_AWS_PACKAGES = [
  '@aws-sdk/client-',
  '@aws-sdk/lib-',
  // ...
]

export const ALLOWED_VENDOR_PATHS = [
  'lib/vendor/AWS',
  'lib/vendor/ElectroDB',
]

export const ENTITY_NAMES = [
  'Users', 'Files', 'Devices', ...
]
```

Both ESLint rules and MCP rules import from this shared file.

**Pros**: Single source of truth for patterns
**Cons**: ESLint rules need CommonJS, MCP uses ESM (requires build step)

### Option 2: Rule Mapping Document (Current)

Maintain a document tracking which rules exist where:

```markdown
| Rule | MCP | ESLint | Sync Status |
|------|-----|--------|-------------|
| aws-sdk-encapsulation | ‚úÖ | ‚úÖ | In sync |
| cascade-safety | ‚úÖ | ‚ö†Ô∏è partial | ESLint covers 60% |
```

**Pros**: Simple, no build complexity
**Cons**: Manual maintenance, can drift

### Option 3: Test-Based Verification

Write tests that feed the same code snippets to both systems:

```typescript
// test/validation-parity.test.ts
describe('ESLint and MCP parity', () => {
  const testCases = [
    {
      code: `import {DynamoDBClient} from '@aws-sdk/client-dynamodb'`,
      filename: 'src/lambdas/Test/src/index.ts',
      expectedViolation: 'aws-sdk-encapsulation'
    }
  ]

  for (const tc of testCases) {
    it(`both catch: ${tc.expectedViolation}`, async () => {
      const eslintResult = await runEslint(tc.code, tc.filename)
      const mcpResult = await runMcpValidation(tc.code, tc.filename)

      expect(eslintResult.hasViolation).toBe(true)
      expect(mcpResult.hasViolation).toBe(true)
    })
  }
})
```

**Pros**: Automated drift detection
**Cons**: Test maintenance overhead

---

## Recommended Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Developer Workflow                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ   Editor     ‚îÇ    ‚îÇ   Pre-commit ‚îÇ    ‚îÇ     CI       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ   (ESLint)   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   (ESLint)   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (ESLint +   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ    ‚îÇ              ‚îÇ    ‚îÇ   MCP Full)  ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ         ‚îÇ                   ‚îÇ                    ‚îÇ               ‚îÇ
‚îÇ         ‚ñº                   ‚ñº                    ‚ñº               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ              ESLint Rules (5-7 rules)                ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ aws-sdk-encapsulation  ‚Ä¢ electrodb-mocking        ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ cascade-delete-order   ‚Ä¢ response-helpers         ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ env-validation         ‚Ä¢ response-enum            ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                              ‚îÇ                                   ‚îÇ
‚îÇ                              ‚îÇ Catches ~80% of violations        ‚îÇ
‚îÇ                              ‚ñº                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ              MCP Validation (13 rules)               ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ All ESLint rules + deeper analysis                ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ config-enforcement  ‚Ä¢ doc-sync                    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ types-location      ‚Ä¢ full cascade-safety         ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                              ‚îÇ                                   ‚îÇ
‚îÇ                              ‚îÇ Catches 100% with full context    ‚îÇ
‚îÇ                              ‚ñº                                   ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ
‚îÇ                    ‚îÇ   PR Check   ‚îÇ                              ‚îÇ
‚îÇ                    ‚îÇ   Passes     ‚îÇ                              ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Implementation Priorities

### Phase 1: CRITICAL (Done)
- ‚úÖ `no-direct-aws-sdk-import`
- ‚úÖ `cascade-delete-order`
- ‚úÖ `use-electrodb-mock-helper`

### Phase 2: HIGH (Done)
- ‚úÖ `response-helpers` - Detects raw `{statusCode, body}` returns
- ‚úÖ `env-validation` - Detects direct `process.env.X` access

### Phase 3: Nice to Have
- `response-enum` - Style enforcement
- `mock-formatting` - Test consistency

### Skip (Keep MCP Only)
- `config-enforcement` - Circular dependency
- `doc-sync` - Requires cross-file analysis
- `import-order` - Use eslint-plugin-import instead

---

## Maintenance Guidelines

### When Adding New MCP Rules

1. **Evaluate ESLint portability** using this checklist:
   - [ ] Single-file analysis sufficient?
   - [ ] No type inference required?
   - [ ] Simple AST pattern matching?
   - [ ] High-frequency developer mistake?

2. **If portable**, create ESLint equivalent:
   - Add to `eslint-local-rules/rules/`
   - Add tests in `eslint-local-rules/test/`
   - Update `eslint.config.mjs`
   - Document in this file

3. **If not portable**, document why:
   - Add to "Skip" section above
   - Explain capabilities needed

### Keeping Rules in Sync

1. **Shared constants**: Update patterns in both places
2. **Monthly review**: Check for drift between implementations
3. **PR template**: "Did you update both ESLint and MCP rules?"

---

## Conclusion

The dual-system approach provides defense in depth:
- **ESLint** catches common mistakes immediately (developer productivity)
- **MCP** catches everything with full context (correctness guarantee)

Don't aim for 100% replication. Instead:
1. Use ESLint for high-frequency, simple patterns
2. Use MCP for complex, cross-file analysis
3. Accept that some rules only exist in one system
4. Document the relationship and maintain intentionally
# Code Formatting

## Quick Reference
- **When to use**: Understanding and overriding automatic code formatting
- **Formatter**: dprint (TypeScript plugin)
- **Config file**: `dprint.json`
- **Enforcement**: Automatic - `pnpm run format`

## The Rule

**Let the formatter handle formatting, with targeted overrides when readability suffers.**

This project uses [dprint](https://dprint.dev/) for code formatting. The formatter makes most decisions automatically based on line width (157 characters). Use the techniques below only when the automatic formatting harms readability.

## Key Configuration

| Setting | Value | Effect |
|---------|-------|--------|
| `lineWidth` | 157 | Maximum line length before wrapping |
| `semiColons` | "asi" | No semicolons (automatic semicolon insertion) |
| `quoteStyle` | "preferSingle" | Single quotes for strings |
| `trailingCommas` | "never" | No trailing commas |
| `objectExpression.preferSingleLine` | true | Objects on one line when possible |
| `arrayExpression.preferSingleLine` | false | Arrays expand to multiline |
| `arguments.preferHanging` | "always" | First argument on same line as function |

## Multiline Formatting Hint

### The Problem

When dprint wraps arrays/objects that exceed line width, it uses a "best fit" algorithm that can create ugly mixed inline/multiline formatting:

```typescript
// dprint's default - first elements inline, then wrap
const items = [{id: 1, name: 'first'}, {id: 2, name: 'second'}, {
  id: 3,
  name: 'third'
}]
```

### The Solution: `// fmt: multiline`

Add `// fmt: multiline` after the first element to force consistent multiline formatting:

```typescript
// Clean, consistent multiline
const items = [
  {id: 1, name: 'first'}, // fmt: multiline
  {id: 2, name: 'second'},
  {id: 3, name: 'third'}
]
```

### Why It Works

Line comments (`//`) cannot be collapsed to a single line. dprint must keep the line break, which triggers full multiline formatting for the entire expression.

### When to Use

Use `// fmt: multiline` when:
- An array/object wraps with some elements inline and others multiline
- The mixed formatting harms readability
- Elements are similar and should be visually aligned

Do NOT use when:
- The expression fits on one line (let dprint keep it compact)
- The multiline format is already clean
- Adding the comment would be the only thing preventing single-line

### Examples

#### Arrays of Similar Objects

```typescript
// Test fixtures with consistent structure
const mockDevices = [
  {deviceId: 'device-1', userId: 'user-123'}, // fmt: multiline
  {deviceId: 'device-2', userId: 'user-456'},
  {deviceId: 'device-3', userId: 'user-789'}
]

// Metrics with consistent structure
await putMetrics([
  {name: 'Success', value: 1, unit: 'Count'}, // fmt: multiline
  {name: 'Duration', value: duration, unit: 'Seconds'},
  {name: 'FileSize', value: fileSize, unit: 'Bytes'}
])
```

#### Configuration Arrays

```typescript
// DynamoDB indexes
indexes: [
  {name: 'Primary', pk: 'pk', sk: 'sk'}, // fmt: multiline
  {name: 'GSI1', pk: 'gsi1pk', sk: 'gsi1sk'},
  {name: 'GSI2', pk: 'gsi2pk', sk: 'gsi2sk'}
]
```

## Function Call Formatting

### Hanging Arguments

With `arguments.preferHanging: "always"`, when function arguments must wrap, the first argument stays on the same line as the function name:

```typescript
// Function name and first argument together (good context)
jest.unstable_mockModule('#lib/vendor/AWS/SNS',
  () => ({deleteEndpoint: jest.fn(), subscribe: jest.fn()}))

// NOT like this (loses context)
jest.unstable_mockModule(
  '#lib/vendor/AWS/SNS',
  () => ({deleteEndpoint: jest.fn(), subscribe: jest.fn()})
)
```

This keeps the function name and its primary argument visually connected.

## Complete Formatting Bypass

### `// dprint-ignore`

Skip formatting for a single statement:

```typescript
// dprint-ignore
const matrix = [
  [1, 0, 0],
  [0, 1, 0],
  [0, 0, 1]
];
```

### `// dprint-ignore-file`

Skip formatting for an entire file (use sparingly):

```typescript
// dprint-ignore-file

// ... rest of file is not formatted
```

### When to Use Ignore

- **Matrix/grid data** - Visual alignment matters
- **Complex regex** - Manual formatting aids readability
- **Generated code** - Preserve generator's formatting
- **Temporary debugging** - Will be removed soon

## Type Aliases for Line Width Management

### The Problem

Function signatures with multiple parameters, long return types, or complex generics can exceed the line width limit, causing dprint to wrap them across multiple lines:

```typescript
// Wrapped due to length - loses visual clarity
export async function createUserSession(
  userId: string,
  deviceId?: string,
  ipAddress?: string,
  userAgent?: string
): Promise<{token: string; expiresAt: number; sessionId: string}> {
```

### The Solution: Extract Type Aliases

Create type aliases for return types or parameter groups to keep signatures under the line width:

```typescript
// Type alias keeps the signature on one line
type SessionResult = {token: string; expiresAt: number; sessionId: string}

export async function createUserSession(userId: string, deviceId?: string, ipAddress?: string, userAgent?: string): Promise<SessionResult> {
```

### Guidelines

**When to create type aliases:**
- Function signature exceeds 157 characters
- Return type is complex (multiple properties)
- Generic type parameter is verbose
- Multiple functions share the same type

**When NOT to use type aliases:**
- Type is used only once and is self-explanatory
- Alias would obscure the actual type
- Signature already fits on one line

### Examples

#### Return Type Extraction

```typescript
// Before: 175 characters, wraps
export async function getResourceDetails(id: string): Promise<{userId: string; fileId: string; metadata: Record<string, unknown>}> {

// After: 89 characters, stays on one line
type ResourceDetails = {userId: string; fileId: string; metadata: Record<string, unknown>}

export async function getResourceDetails(id: string): Promise<ResourceDetails> {
```

#### Parameter Type Extraction

```typescript
// Before: Parameters cause wrapping
export function validateRequest(
  requestBody: Webhook | DeviceRegistrationRequest | UserRegistration | UserSubscribe | UserLogin,
  schema: Joi.ObjectSchema
): void {

// After: Union type extracted
type RequestPayload = Webhook | DeviceRegistrationRequest | UserRegistration | UserSubscribe | UserLogin

export function validateRequest(requestBody: RequestPayload, schema: Joi.ObjectSchema): void {
```

#### Generic Type Simplification

```typescript
// Before: Long generic wraps
export function captureAWSClient<T extends {
  middlewareStack: {remove: unknown; use: unknown};
  config: unknown
}>(client: T): T {

// After: Collapsed to one line (111 chars, fits)
export function captureAWSClient<T extends {middlewareStack: {remove: unknown; use: unknown}; config: unknown}>(client: T): T {
```

### Naming Conventions for Type Aliases

- **Result types**: `[Function]Result` - `SessionResult`, `ValidationResult`
- **Input types**: `[Function]Input` or `[Entity]Payload` - `RequestPayload`, `CreateUserInput`
- **Configuration types**: `[Feature]Config` - `AuthConfig`, `CacheConfig`

### Trade-offs

| Type Alias | Inline Type |
|------------|-------------|
| Reusable | Single use |
| Named (self-documenting) | Immediately visible |
| Shorter signatures | All info in one place |
| Requires navigation to understand | No navigation needed |

**Prefer type aliases when:**
- Type is complex (3+ properties)
- Type is reused
- Signature would exceed line width

**Prefer inline types when:**
- Type is simple (1-2 properties)
- Type is used once
- Signature fits comfortably

## Sequential Mock Return Values

### The Problem

When configuring multiple return values with `mockResolvedValueOnce`, method chaining can exceed line width and wrap awkwardly:

```typescript
// Chained - dprint wraps mid-chain (ugly, inconsistent)
mockOperation.mockResolvedValueOnce({data: ['page1'], cursor: 'cursor1'}).mockResolvedValueOnce({
  data: ['page2'],
  cursor: 'cursor2'
}).mockResolvedValueOnce({data: ['page3'], cursor: null})
```

### The Solution: Separate Statements

Use separate statements instead of chaining. `mockResolvedValueOnce` queues return values internally‚Äîchaining is syntactic sugar, not required:

```typescript
// Separate statements - clean, consistent, dprint-stable
mockOperation.mockResolvedValueOnce({data: ['page1'], cursor: 'cursor1'})
mockOperation.mockResolvedValueOnce({data: ['page2'], cursor: 'cursor2'})
mockOperation.mockResolvedValueOnce({data: ['page3'], cursor: null})
```

### Why It Works

1. **Readability** - Each return value on its own line, clear sequence
2. **dprint stability** - Separate statements won't collapse or wrap mid-chain
3. **Consistent** - Same visual structure regardless of content length

### Pattern

```typescript
// Type alias for the mock function signature
type ScanFn<T> = (cursor?: string) => Promise<{data: T[]; cursor: string | null}>

it('should paginate through multiple pages', async () => {
  // Declare mock with type
  const mockScan = jest.fn<ScanFn<string>>()

  // Configure sequential returns as separate statements
  mockScan.mockResolvedValueOnce({data: ['item1', 'item2'], cursor: 'cursor1'})
  mockScan.mockResolvedValueOnce({data: ['item3', 'item4'], cursor: 'cursor2'})
  mockScan.mockResolvedValueOnce({data: ['item5'], cursor: null})

  const result = await scanAllPages(mockScan)
  // ...assertions
})
```

### When to Apply

- **Always** for `mockResolvedValueOnce` sequences (2+ calls)
- **Always** for `mockReturnValueOnce` sequences (2+ calls)
- Single `mockResolvedValue` or `mockReturnValue` can stay on same line as mock declaration

## Running the Formatter

```bash
# Format all files
pnpm run format

# Check formatting without changing (CI)
pnpm run format:check

# Format specific file
npx dprint fmt path/to/file.ts
```

## Finding Format Issues

```bash
# Find potential // fmt: multiline candidates
# (arrays starting with element on same line as [, then wrapping)
grep -rn "= \[{.*}, {$" --include="*.ts" src/

# Find existing format hints
grep -rn "fmt: multiline" --include="*.ts" src/
```

## Rationale

1. **Consistency over preference** - Automated formatting eliminates style debates
2. **Targeted overrides** - Only intervene when readability suffers
3. **Self-documenting** - `// fmt: multiline` explains its purpose
4. **Searchable** - Easy to find all format hints in codebase

## Related Patterns

- [Code Comments](Code-Comments.md) - When and how to use comments
- [Naming Conventions](Naming-Conventions.md) - Variable and file naming
- [Import Organization](Import-Organization.md) - Import ordering

---

*Trust the formatter for most decisions. Use `// fmt: multiline` sparingly for arrays/objects where the automatic formatting creates inconsistent visual structure.*
# Import Organization

## Quick Reference
- **When to use**: Organizing imports in any TypeScript/JavaScript file
- **Enforcement**: Required - consistent imports improve readability
- **Impact if violated**: Medium - confusion and merge conflicts

## The Rule

### Module System
**Use ES modules (import/export), not CommonJS (require)**

### Import Order (STRICT)
Imports must follow this exact order with blank lines between groups:

1. **AWS Lambda types** (if Lambda function)
2. **Vendor library imports** (lib/vendor/*)
3. **Type imports** (types/*)
4. **Utility imports** (util/*)
5. **Local/relative imports**
6. **Node built-in modules** (at the end)

### Import Style
- **Destructure imports** when possible
- **Group related imports** from same module
- **Sort alphabetically** within each group
- **Use type imports** for TypeScript types

## Examples

### ‚úÖ Correct - Lambda Function

```typescript
// 1. AWS Lambda type imports FIRST
import {APIGatewayProxyResult, Context} from 'aws-lambda'

// 2. Vendor library imports (lib/vendor/*)
import {query, updateItem} from '../../../lib/vendor/AWS/DynamoDB'
import {createS3Upload, headObject} from '../../../lib/vendor/AWS/S3'

// 3. Type imports (types/*)
import type {File} from '../../../types/domain-models'
import type {User} from '../../../types/domain-models'
import type {FileStatus} from '../../../types/enums'

// 4. Utility imports (util/*)
import {logDebug, logInfo, response} from '../../../util/lambda-helpers'
import {UnexpectedError} from '../../../util/errors'

// 5. Local imports
import {processFile} from './fileProcessor'

// 6. Node built-ins (if needed)
import * as path from 'path'
```

### ‚ùå Incorrect

```typescript
// ‚ùå WRONG - Mixed order, no grouping
import * as fs from 'fs'  // Built-ins should be last
import {UserService} from './services/UserService'
import {APIGatewayProxyResult} from 'aws-lambda'  // Lambda types should be first
import {logger} from './utils/logger'
import type {UserData} from './types'  // Types before utils

// ‚ùå WRONG - CommonJS syntax
const express = require('express')

// ‚ùå WRONG - Direct AWS SDK import
import {S3Client} from '@aws-sdk/client-s3'
// Should use vendor wrapper:
import {createS3Upload} from '../../../lib/vendor/AWS/S3'
```

## Import Styles

### Destructured Imports (Preferred)

```typescript
// ‚úÖ GOOD - Destructured, specific
import {logDebug, logInfo, logError} from './logger'
import {validateEmail, validatePhone} from './validators'
```

### Type Imports

```typescript
// ‚úÖ GOOD - Explicit type imports
import type {UserProfile, UserSettings} from './types'
import type {Request, Response} from 'express'
```

## Special Rules

### AWS SDK Imports (FORBIDDEN)

```typescript
// ‚ùå NEVER import AWS SDK directly
import {S3Client} from '@aws-sdk/client-s3'
import {DynamoDBClient} from '@aws-sdk/client-dynamodb'

// ‚úÖ ALWAYS use vendor wrappers
import {createS3Upload} from '../../../lib/vendor/AWS/S3'
import {query} from '../../../lib/vendor/AWS/DynamoDB'
```

### Avoid Circular Dependencies

```typescript
// ‚ùå AVOID circular imports
// FileA.ts
import {functionB} from './FileB'
export const functionA = () => functionB()

// FileB.ts
import {functionA} from './FileA'  // Circular!
export const functionB = () => functionA()

// ‚úÖ SOLUTION: Extract shared logic
// shared.ts
export const sharedFunction = () => {}
```

## ES Modules vs CommonJS

### Always Use ES Modules

```typescript
// ‚úÖ ES Modules (ESM)
import {readFile} from 'fs/promises'
export const myFunction = () => {}
export default MyClass

// ‚ùå CommonJS (CJS)
const {readFile} = require('fs/promises')
module.exports.myFunction = () => {}
```

### Why ES Modules?

1. **Static analysis** - Tools analyze imports at build time
2. **Tree shaking** - Unused exports eliminated
3. **Type safety** - Better TypeScript integration
4. **Future proof** - ES modules are the standard

## Enforcement

### Code Review Checklist

- [ ] ES modules syntax used (import/export)
- [ ] Imports follow strict order
- [ ] Blank lines between groups
- [ ] Destructured where possible
- [ ] Type imports use `import type`
- [ ] No direct AWS SDK imports
- [ ] No circular dependencies

## Related Patterns

- [Naming Conventions](Naming-Conventions.md) - File and module naming
- [AWS SDK Encapsulation](../AWS/SDK-Encapsulation-Policy.md) - Vendor wrapper imports
- [Lambda Function Patterns](../TypeScript/Lambda-Function-Patterns.md) - Lambda-specific imports

---

*Consistent import organization reduces cognitive load and makes dependencies clear. Follow this pattern strictly for maintainable code.*
# X-Ray Integration

## Quick Reference
- **When to use**: All Lambda functions for distributed tracing
- **Enforcement**: Recommended
- **Impact if violated**: LOW - Reduced visibility

## X-Ray Decorator Pattern

```typescript
// lib/vendor/AWS/XRay.ts
import AWSXRay from 'aws-xray-sdk-core'

export function withXRay<TEvent = any, TResult = any>(
  handler: (event: TEvent, context: Context, metadata: {traceId: string}) => Promise<TResult>
) {
  return async (event: TEvent, context: Context): Promise<TResult> => {
    const segment = AWSXRay.getSegment()
    const traceId = (segment as any)?.trace_id || context.awsRequestId
    return handler(event, context, {traceId})
  }
}

export function captureAWSClient<T>(client: T): T {
  if (process.env.ENABLE_XRAY === 'false' || process.env.USE_LOCALSTACK === 'true') {
    return client
  }
  return AWSXRay.captureAWSv3Client(client)
}
```

## Lambda Usage

```typescript
// All Lambda handlers use withXRay
export const handler = withXRay(async (event, context, {traceId}) => {
  logInfo('event <=', event)
  // traceId available for correlation
  return response(context, 200, data)
})
```

## AWS SDK Integration

```typescript
// lib/vendor/AWS/S3.ts
import {S3Client} from '@aws-sdk/client-s3'
import {captureAWSClient} from './XRay'

const s3Client = captureAWSClient(new S3Client())
```

## Custom Subsegments

```typescript
import {captureAsyncFunc} from '../AWS/XRay'

export async function downloadVideo(url: string) {
  return captureAsyncFunc('downloadVideo', async (subsegment) => {
    subsegment?.addAnnotation('url', url)
    subsegment?.addMetadata('size', result.size)
    // Perform operation
    return result
  })
}
```

## Annotations vs Metadata

- **Annotations** - Indexed, searchable (userId, operation)
- **Metadata** - Detailed info, not searchable (request body, response)

## OpenTofu Configuration

```hcl
resource "aws_lambda_function" "process_file" {
  tracing_config {
    mode = "Active"
  }

  environment {
    variables = {
      EnableXRay = "true"
    }
  }
}

resource "aws_iam_role_policy_attachment" "xray" {
  role       = aws_iam_role.lambda_role.name
  policy_arn = "arn:aws:iam::aws:policy/AWSXRayDaemonWriteAccess"
}
```

## Testing

```typescript
// Disable X-Ray in tests
beforeEach(() => {
  process.env.EnableXRay = 'false'
})

// Mock X-Ray
jest.unstable_mockModule('../../../lib/vendor/AWS/XRay', () => ({
  withXRay: (handler: any) => handler,
  captureAWSClient: (client: any) => client,
  captureAsyncFunc: async (name: string, fn: any) => fn()
}))
```

## Best Practices

‚úÖ Use withXRay decorator for all Lambdas
‚úÖ Wrap AWS SDK clients with captureAWSClient
‚úÖ Create subsegments for slow operations
‚úÖ Include trace ID in logs
‚úÖ Use annotations for searchable fields
‚úÖ Disable X-Ray in tests

## Related Patterns

- [CloudWatch Logging](CloudWatch-Logging.md)
- [Lambda Function Patterns](../TypeScript/Lambda-Function-Patterns.md)

---

*Use X-Ray for distributed tracing. The withXRay decorator provides automatic instrumentation.*# SDK Encapsulation Policy

## Quick Reference
- **When to use**: Every AWS SDK interaction
- **Enforcement**: ZERO TOLERANCE
- **Impact if violated**: CRITICAL - Breaks architecture

## The Rule

**NEVER import AWS SDK directly. Always use vendor wrappers in `lib/vendor/AWS/`.**

## Examples

### ‚ùå FORBIDDEN
```typescript
// Direct SDK imports
import {S3Client} from '@aws-sdk/client-s3'
import {DynamoDBClient} from '@aws-sdk/client-dynamodb'

// Creating clients
const s3 = new S3Client()
```

### ‚úÖ REQUIRED
```typescript
// Vendor wrapper imports
import {uploadToS3} from '../../../lib/vendor/AWS/S3'
import {queryItems} from '../../../lib/vendor/AWS/DynamoDB'
```

## Vendor Wrapper Pattern

```typescript
// lib/vendor/AWS/S3.ts
import {S3Client, PutObjectCommand} from '@aws-sdk/client-s3'
import {captureAWSClient} from './XRay'

let client: S3Client | null = null

function getS3Client(): S3Client {
  if (!client) {
    client = captureAWSClient(new S3Client({
      ...(process.env.USE_LOCALSTACK === 'true' && {
        endpoint: 'http://localhost:4566'
      })
    }))
  }
  return client
}

export async function uploadToS3(
  bucket: string,
  key: string,
  body: Buffer
): Promise<void> {
  const client = getS3Client()
  await client.send(new PutObjectCommand({
    Bucket: bucket,
    Key: key,
    Body: body
  }))
}
```

## Why Vendor Wrappers?

1. **LocalStack support** - Auto-detect environment
2. **X-Ray tracing** - Built-in instrumentation
3. **Testability** - Easy mocking
4. **Type safety** - Custom interfaces
5. **Single responsibility** - One place for SDK config

## Webpack Configuration

```javascript
// Add to externals
externals: [
  '@aws-sdk/client-s3',
  '@aws-sdk/client-dynamodb',
  // Add new SDK packages here
]
```

## Testing

```typescript
jest.unstable_mockModule('../../../lib/vendor/AWS/S3', () => ({
  uploadToS3: jest.fn()
}))
```

## Verification

```bash
# Check for violations (should return nothing)
grep -r "from '@aws-sdk" src/lambdas/
grep -r "from 'aws-sdk'" src/lambdas/
```

## Related Patterns

- [X-Ray Integration](X-Ray-Integration.md)
- [LocalStack Testing](../Integration/LocalStack-Testing.md)

---

*ZERO TOLERANCE: Always use vendor wrappers for AWS SDK.*# CloudWatch Logging

## Quick Reference
- **When to use**: All Lambda functions
- **Enforcement**: Required
- **Impact if violated**: MEDIUM - Poor observability

## Logging Functions

The project provides three logging functions in `util/lambda-helpers.ts`:

```typescript
logInfo(message: string, stringOrObject?: string | object): void
logDebug(message: string, stringOrObject?: string | object): void
logError(message: string, stringOrObject?: string | object | unknown): void
```

- **logInfo**: Standard functionality and flow
- **logDebug**: Detailed diagnostic information
- **logError**: Error conditions

## Usage Pattern

```typescript
import {logInfo, logDebug, logError} from '../../../util/lambda-helpers'

// Log with message only
logInfo('event <=', event)

// Log with context object
logDebug('getFilesByUser.userFiles =>', userFilesResponse)

// Log errors
logError('Failed to process', error)
```

## CloudWatch Insights Queries

```sql
# Find errors
fields @timestamp, @message
| filter @message like /error/i
| sort @timestamp desc

# Find specific Lambda invocations
fields @timestamp, @message
| filter @logStream like /ListFiles/
| sort @timestamp desc

# Find slow operations
fields @timestamp, @message, @duration
| filter @duration > 5000
| sort @duration desc
```

## Best Practices

### Do's
- Log incoming events: `logInfo('event <=', event)`
- Log key operations with arrow notation for clarity
- Include relevant context in the object parameter
- Use logDebug for detailed diagnostics

### Don'ts
- Don't log sensitive data (passwords, tokens, PII)
- Don't log in tight loops
- Don't log entire large objects

## Related Patterns

- [X-Ray Integration](X-Ray-Integration.md) - Tracing with trace IDs
- [Lambda Function Patterns](../TypeScript/Lambda-Function-Patterns.md) - Handler patterns
- [Error Handling](../TypeScript/TypeScript-Error-Handling.md) - Error logging

---

*Use the provided logging functions for consistent CloudWatch logging.*# Lambda Environment Variables

## Quick Reference
- **When to use**: Configuring Lambda functions
- **Enforcement**: Required - unit tests verify presence
- **Impact if violated**: HIGH - Runtime failures

## Naming Convention

Use **CamelCase** for Lambda environment variable names:

```typescript
process.env.DynamoDBTableName
process.env.PlatformApplicationArn
process.env.PushNotificationTopicArn
process.env.FeedlyQueueUrl
```

## No Defaults in Code

Environment variables are required and verified by unit tests. Don't provide defaults:

```typescript
// ‚ùå WRONG - Don't use defaults
const tableName = process.env.DynamoDBTableName || 'default-table'

// ‚úÖ CORRECT - Required, verified by tests
const tableName = process.env.DynamoDBTableName as string
```

## No Try-Catch for Required Variables (CRITICAL)

**Zero-tolerance rule**: NEVER wrap required environment variable access in try-catch blocks with fallback values.

```typescript
// ‚ùå WRONG - Silent failures hide configuration errors
try {
  const config = JSON.parse(process.env.SignInWithAppleConfig)
} catch {
  return { clientId: 'fallback', teamId: 'fallback' }
}

// ‚úÖ CORRECT - Let it fail if misconfigured
const config = JSON.parse(process.env.SignInWithAppleConfig)
```

**Why**: Infrastructure tests enforce that all required environment variables are properly configured. Silent failures in production hide critical configuration errors that should fail fast and loud.

**Enforcement**: Unit tests verify all environment variables are present and valid. Production deployment validation catches missing variables before runtime.

## Unit Test Verification

```typescript
// test/setup.ts
beforeAll(() => {
  process.env.DynamoDBTableName = 'test-table'
  process.env.PlatformApplicationArn = 'arn:aws:sns:test'
})
```

## OpenTofu Configuration

```hcl
resource "aws_lambda_function" "ListFiles" {
  environment {
    variables = {
      DynamoDBTableName = aws_dynamodb_table.main.name
      EnableXRay        = var.enable_xray
    }
  }
}
```

## Common Variables

- `DynamoDBTableName` - DynamoDB table (set in OpenTofu)
- `PlatformApplicationArn` - SNS platform app
- `PushNotificationTopicArn` - SNS topic
- `FeedlyQueueUrl` - SQS queue
- `EnableXRay` - X-Ray tracing (read as ENABLE_XRAY in code)
- `UseLocalstack` - LocalStack testing (read as USE_LOCALSTACK in code)

## Related Patterns

- [Infrastructure/Environment-Variables](../Infrastructure/Environment-Variables.md)
- [Lambda Function Patterns](../TypeScript/Lambda-Function-Patterns.md)

---

*Use CamelCase for Lambda environment variables. Verify presence with unit tests, not defaults.*# Infrastructure Environment Variables

## Quick Reference
- **When to use**: OpenTofu/Terraform Lambda configuration
- **Enforcement**: Required
- **Impact if violated**: HIGH - Deployment failures

## OpenTofu Configuration

Define environment variables in Lambda resources using CamelCase:

```hcl
resource "aws_lambda_function" "ProcessFile" {
  function_name = "ProcessFile"

  environment {
    variables = {
      DynamoDBTableName        = aws_dynamodb_table.main.name
      PlatformApplicationArn   = aws_sns_platform_application.apns.arn
      PushNotificationTopicArn = aws_sns_topic.push_notifications.arn
      FeedlyQueueUrl          = aws_sqs_queue.feedly.url
      EnableXRay              = var.enable_xray ? "true" : "false"
    }
  }
}
```

## Variable Sources

```hcl
# From AWS resources
DynamoDBTableName = aws_dynamodb_table.main.name

# From Terraform variables
EnableXRay = var.enable_xray

# From data sources
ApiToken = data.aws_secretsmanager_secret_version.api_token.secret_string
```

## LocalStack Support

```hcl
variable "use_localstack" {
  default = false
}

environment {
  variables = {
    UseLocalstack = var.use_localstack ? "true" : "false"
    DynamoDBEndpoint = var.use_localstack ? "http://localhost:4566" : null
  }
}
```

## Related Patterns

- [AWS/Lambda-Environment-Variables](../AWS/Lambda-Environment-Variables.md)
- [Resource Naming](Resource-Naming.md)

---

*Configure Lambda environment variables in OpenTofu using CamelCase naming.*# OpenTofu Infrastructure Patterns

## Quick Reference
- **When to use**: Writing OpenTofu/Terraform infrastructure code
- **Enforcement**: Required - consistent infrastructure patterns
- **Impact if violated**: MEDIUM - Inconsistent infrastructure, maintainability issues

## File Organization

### Resource Grouping

Group related resources in dedicated files:
- `feedly_webhook.tf` - Feedly webhook Lambda and API Gateway
- `api_gateway.tf` - API Gateway configuration
- `s3.tf` - S3 buckets and policies
- `dynamodb.tf` - DynamoDB tables

### Resource Naming

Use PascalCase for resource names to match AWS conventions:

```hcl
resource "aws_lambda_function" "WebhookFeedly" {
  function_name = "WebhookFeedly"
  # ...
}

resource "aws_iam_role" "WebhookFeedlyRole" {
  name = "WebhookFeedlyRole"
  # ...
}
```

## Comments

### Explain WHY, Not WHAT

```hcl
# GOOD - explains business reason
# Retain logs for 14 days to balance cost and debugging needs
retention_in_days = 14

# BAD - states the obvious
# Set retention to 14 days
retention_in_days = 14
```

### Prohibited Comments

**NEVER include comments explaining removed resources or deprecated infrastructure**:

```hcl
# ‚ùå BAD - explaining what was removed
# Multipart upload Step Function removed - now using direct streaming

# ‚úÖ GOOD - no comments needed, use git history
# (Just define current infrastructure)
```

## Environment Variables

### Lambda Environment Variables

Always use CamelCase to match TypeScript ProcessEnv interface:

```hcl
environment {
  variables = {
    DynamoDBTableFiles  = aws_dynamodb_table.Files.name
    YtdlpBinaryPath     = "/opt/bin/yt-dlp_linux"
    GithubPersonalToken = data.sops_file.secrets.data["github.issue.token"]
  }
}
```

Match exactly to `src/types/global.d.ts`:

```typescript
interface ProcessEnv {
  DynamoDBTableFiles: string
  YtdlpBinaryPath: string
  GithubPersonalToken: string
}
```

## Lambda Function Pattern

### Standard Lambda Definition

```hcl
resource "aws_lambda_function" "FunctionName" {
  function_name = "FunctionName"
  role         = aws_iam_role.FunctionNameRole.arn
  handler      = "index.handler"
  runtime      = "nodejs22.x"
  timeout      = 300
  memory_size  = 512

  filename         = data.archive_file.FunctionName.output_path
  source_code_hash = data.archive_file.FunctionName.output_base64sha256

  environment {
    variables = {
      DynamoDBTableFiles = aws_dynamodb_table.Files.name
      S3BucketName      = aws_s3_bucket.MediaFiles.bucket
    }
  }

  depends_on = [
    aws_iam_role_policy_attachment.FunctionNamePolicyAttachment,
    aws_cloudwatch_log_group.FunctionNameLogGroup
  ]
}
```

### IAM Role Pattern

```hcl
resource "aws_iam_role" "FunctionNameRole" {
  name = "FunctionNameRole"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "lambda.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_policy" "FunctionNamePolicy" {
  name = "FunctionNamePolicy"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = ["dynamodb:GetItem", "dynamodb:PutItem"]
        Resource = aws_dynamodb_table.Files.arn
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "FunctionNamePolicyAttachment" {
  role       = aws_iam_role.FunctionNameRole.name
  policy_arn = aws_iam_policy.FunctionNamePolicy.arn
}
```

### CloudWatch Logs

```hcl
resource "aws_cloudwatch_log_group" "FunctionNameLogGroup" {
  name              = "/aws/lambda/FunctionName"
  retention_in_days = 14
}
```

## DynamoDB Tables

### ElectroDB Single-Table Design

```hcl
resource "aws_dynamodb_table" "MediaDownloader" {
  name           = "MediaDownloader"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "pk"
  range_key      = "sk"

  attribute {
    name = "pk"
    type = "S"
  }

  attribute {
    name = "sk"
    type = "S"
  }

  global_secondary_index {
    name            = "gsi1"
    hash_key        = "gsi1pk"
    range_key       = "gsi1sk"
    projection_type = "ALL"
  }
}
```

## S3 Buckets

### Media Storage Bucket

```hcl
resource "aws_s3_bucket" "MediaFiles" {
  bucket = "media-downloader-files-${data.aws_caller_identity.current.account_id}"
}

resource "aws_s3_bucket_versioning" "MediaFilesVersioning" {
  bucket = aws_s3_bucket.MediaFiles.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "MediaFilesEncryption" {
  bucket = aws_s3_bucket.MediaFiles.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}
```

## Best Practices

### DO

- ‚úÖ Group related resources in logical files
- ‚úÖ Use PascalCase for resource names
- ‚úÖ Reference resources using interpolation
- ‚úÖ Keep environment variable names consistent with TypeScript
- ‚úÖ Use PAY_PER_REQUEST for DynamoDB in serverless
- ‚úÖ Enable versioning and encryption on S3 buckets
- ‚úÖ Set CloudWatch log retention

### DON'T

- ‚ùå Hardcode values that can be referenced
- ‚ùå Explain removed resources in comments (use git history)
- ‚ùå Use provisioned capacity for DynamoDB in serverless
- ‚ùå Leave S3 buckets publicly accessible
- ‚ùå Keep CloudWatch logs forever

## Related Patterns

- [Naming Conventions](../Conventions/Naming-Conventions.md) - PascalCase for resources
- [Code Comments](../Conventions/Code-Comments.md) - Git as source of truth

---

*Infrastructure documentation belongs in README.md, AGENTS.md, and Git history - not in comments.*
# Infrastructure File Organization

## Quick Reference
- **When to use**: Organizing OpenTofu/Terraform files
- **Enforcement**: Required
- **Impact if violated**: MEDIUM - Difficult to navigate and maintain

## Directory Structure

```
terraform/
‚îú‚îÄ‚îÄ main.tf                    # Provider configuration
‚îú‚îÄ‚îÄ api_gateway.tf             # API Gateway resources
‚îú‚îÄ‚îÄ api_gateway_authorizer.tf  # Custom authorizer
‚îú‚îÄ‚îÄ configuration_apns.tf      # APNS configuration
‚îú‚îÄ‚îÄ file_bucket.tf             # S3 bucket resources
‚îú‚îÄ‚îÄ file_coordinator.tf        # File coordinator Lambda
‚îú‚îÄ‚îÄ list_files.tf              # List files Lambda
‚îú‚îÄ‚îÄ register_device.tf         # Register device Lambda
‚îú‚îÄ‚îÄ register_user.tf           # Register user Lambda
‚îú‚îÄ‚îÄ feedly_webhook.tf          # Feedly webhook Lambda
‚îú‚îÄ‚îÄ send_push_notification.tf  # Push notification Lambda
‚îî‚îÄ‚îÄ *.tf                       # Other function-specific files
```

## File Organization Rules

1. **One file per Lambda function** - Each Lambda gets its own snake_case file
2. **Include related resources** - Lambda file contains function, role, and policy
3. **Service-specific files** - Shared resources get descriptive snake_case names

## Service Files

```hcl
# file_bucket.tf - S3 bucket and related resources
resource "aws_s3_bucket" "media_files" { }
resource "aws_s3_bucket_versioning" "media_files_versioning" { }

# api_gateway.tf - API Gateway configuration
resource "aws_api_gateway_rest_api" "main" { }
resource "aws_api_gateway_deployment" "main" { }

# configuration_apns.tf - APNS platform configuration
resource "aws_sns_platform_application" "apns" { }
```

## Lambda Files

Each Lambda function gets its own snake_case file with all related resources:

```hcl
# list_files.tf

resource "aws_lambda_function" "ListFiles" {
  function_name = "ListFiles"
  role         = aws_iam_role.ListFilesRole.arn

  environment {
    variables = {
      DynamoDBTableName = aws_dynamodb_table.MediaDownloader.name
    }
  }
}

resource "aws_iam_role" "ListFilesRole" {
  name = "ListFilesRole"
  # Role configuration
}

resource "aws_iam_role_policy" "ListFilesPolicy" {
  name = "ListFilesPolicy"
  role = aws_iam_role.ListFilesRole.id
  # Policy configuration
}
```

## File Naming Convention

- **Lambda files**: snake_case function name
  - `list_files.tf`
  - `register_device.tf`
  - `file_coordinator.tf`
  - `feedly_webhook.tf`

- **Service/Shared files**: snake_case descriptive name
  - `api_gateway.tf`
  - `file_bucket.tf`
  - `configuration_apns.tf`

- **Core files**: lowercase
  - `main.tf`

## Related Patterns

- [Resource Naming](Resource-Naming.md) - Resource naming conventions
- [Environment Variables](Environment-Variables.md) - Lambda configuration

---

*Use snake_case for all terraform files. Each Lambda gets its own file with related IAM resources.*# Script Registry

Central documentation for all npm scripts in this project. This page is the authoritative reference for script purposes, dependencies, and usage.

## CI Validation

Scripts documented in `AGENTS.md` and `README.md` are automatically validated against `package.json` in CI. If a documented script doesn't exist, the build fails.

**Enforcement**: `.github/workflows/unit-tests.yml` - "Validate documented scripts exist" step

---

## Build & Development Scripts

### `pnpm run build`
**Purpose**: Compile TypeScript Lambda functions with esbuild
**Dependencies**: tsx, esbuild
**CI Coverage**: Yes (unit-tests.yml)
**Notes**: Automatically runs `generate-graph` first to create dependency analysis

### `pnpm run build-dependencies`
**Purpose**: Build external dependencies (yt-dlp binary layer)
**Dependencies**: Docker, shell access
**CI Coverage**: Yes (unit-tests.yml)
**Notes**: Required before first build; creates Lambda layer with yt-dlp

### `pnpm run check-types`
**Purpose**: TypeScript type checking without emit
**Dependencies**: TypeScript
**CI Coverage**: Yes (unit-tests.yml)
**Notes**: Fast validation of type correctness

### `pnpm run generate-graph`
**Purpose**: Generate `build/graph.json` dependency analysis
**Dependencies**: ts-morph
**CI Coverage**: Yes (via build/test)
**Notes**: Critical for Jest mocking - shows transitive dependencies

---

## Testing Scripts

### `pnpm run test`
**Purpose**: Run unit tests with Jest
**Dependencies**: Jest, ts-node
**CI Coverage**: Yes (unit-tests.yml)
**Notes**: Runs `generate-graph` first; use `--coverage` for reports

### `pnpm run test:integration`
**Purpose**: Run integration tests against LocalStack
**Dependencies**: LocalStack (Docker), Jest
**CI Coverage**: Yes (integration-tests.yml)
**Notes**: Requires LocalStack already running. Use for fast iteration when developing integration tests (~30s). For full lifecycle management, use `ci:local:full` instead.

---

## Local CI Scripts

### `pnpm run ci:local`
**Purpose**: Run all CI checks locally (fast mode, no integration tests)
**Dependencies**: Node.js 22+, hcl2json, jq
**CI Coverage**: Mirrors unit-tests.yml + dependency-check.yml
**Notes**: ~2-3 minutes; catches ~95% of CI failures. Use before committing.

### `pnpm run ci:local:full`
**Purpose**: Run complete CI checks including integration tests
**Dependencies**: All ci:local deps + Docker (for LocalStack)
**CI Coverage**: Mirrors all CI workflows
**Notes**: ~5-10 minutes; includes LocalStack lifecycle management.

### `pnpm run validate:docs`
**Purpose**: Validate documented scripts exist in package.json
**Dependencies**: jq
**CI Coverage**: Yes (unit-tests.yml)
**Notes**: Checks AGENTS.md and README.md for pnpm run commands.

### `pnpm run validate:graphrag`
**Purpose**: Validate GraphRAG knowledge graph is up to date
**Dependencies**: ts-morph
**CI Coverage**: Yes (dependency-check.yml)
**Notes**: Regenerates graph and checks for uncommitted changes.

### `pnpm run lint:workflows`
**Purpose**: Validate GitHub Actions workflow YAML syntax
**Dependencies**: actionlint CLI
**CI Coverage**: No (manual validation)
**Notes**: Install with `brew install actionlint`. Native ARM64 binary.

---

## Remote Testing Scripts

### `pnpm run test-remote-list`
**Purpose**: Test ListFiles Lambda against production API
**Dependencies**: AWS credentials, jq
**CI Coverage**: No (requires production)
**Notes**: Validates API Gateway ‚Üí Lambda ‚Üí DynamoDB flow

### `pnpm run test-remote-hook`
**Purpose**: Test Feedly webhook against production API
**Dependencies**: AWS credentials, jq
**CI Coverage**: No (requires production)
**Notes**: Tests webhook authentication and processing

### `pnpm run test-remote-registerDevice`
**Purpose**: Test RegisterDevice Lambda against production API
**Dependencies**: AWS credentials, jq
**CI Coverage**: No (requires production)
**Notes**: Uses idempotent synthetic device; creates SNS Platform Endpoint

---

## LocalStack Scripts

### `pnpm run localstack:start`
**Purpose**: Start LocalStack Docker container
**Dependencies**: Docker, docker-compose
**CI Coverage**: No
**Notes**: Required before `test:integration`

### `pnpm run localstack:stop`
**Purpose**: Stop LocalStack Docker container
**Dependencies**: Docker, docker-compose
**CI Coverage**: No
**Notes**: Clean up after integration testing

### `pnpm run localstack:logs`
**Purpose**: Tail LocalStack container logs
**Dependencies**: Docker, docker-compose
**CI Coverage**: No
**Notes**: Useful for debugging integration test failures

### `pnpm run localstack:health`
**Purpose**: Check LocalStack health endpoint
**Dependencies**: curl, jq
**CI Coverage**: No
**Notes**: Quick verification LocalStack is running

---

## Code Quality Scripts

### `pnpm run lint`
**Purpose**: Run ESLint on codebase
**Dependencies**: ESLint
**CI Coverage**: Yes (unit-tests.yml)
**Notes**: Uses `eslint.config.mjs` configuration

### `pnpm run lint-fix`
**Purpose**: Auto-fix ESLint violations
**Dependencies**: ESLint
**CI Coverage**: No
**Notes**: Run locally before committing

### `pnpm run format`
**Purpose**: Format code with Prettier
**Dependencies**: Prettier
**CI Coverage**: No
**Notes**: 250 character line limit; run before commits

---

## Documentation Scripts

### `pnpm run document-source`
**Purpose**: Generate TypeDoc documentation
**Dependencies**: TypeDoc, shell access
**CI Coverage**: No
**Notes**: Creates HTML documentation from TSDoc comments

### `pnpm run document-terraform`
**Purpose**: Generate Terraform/OpenTofu documentation
**Dependencies**: terraform-docs CLI
**CI Coverage**: No
**Notes**: Updates `docs/terraform.md`

### `pnpm run document-api`
**Purpose**: Generate API documentation from TypeSpec
**Dependencies**: TypeSpec CLI, shell access
**CI Coverage**: No
**Notes**: Creates OpenAPI spec and ReDoc HTML

---

## Fixture Scripts

### `pnpm run extract-fixtures`
**Purpose**: Extract test fixtures from CloudWatch logs
**Dependencies**: AWS CLI, jq
**CI Coverage**: No
**Notes**: Pulls production request/response pairs for tests

### `pnpm run extract-fixtures:production`
**Purpose**: Extract production fixtures with timestamps
**Dependencies**: AWS CLI, jq
**CI Coverage**: No
**Notes**: Similar to `extract-fixtures` but for production data

### `pnpm run process-fixtures`
**Purpose**: Process extracted fixtures for test use
**Dependencies**: Node.js
**CI Coverage**: No
**Notes**: Transforms raw CloudWatch data into test fixtures

---

## Maintenance Scripts

### `pnpm run update-cookies`
**Purpose**: Update YouTube authentication cookies
**Dependencies**: Browser, shell access
**CI Coverage**: No
**Notes**: Required when YouTube cookies expire

### `pnpm run update-yt-dlp`
**Purpose**: Update yt-dlp binary in Lambda layer
**Dependencies**: Docker, shell access
**CI Coverage**: No
**Notes**: Keep yt-dlp current for YouTube compatibility

### `pnpm run install-prod`
**Purpose**: Install production dependencies only
**Dependencies**: pnpm
**CI Coverage**: No
**Notes**: Smaller `node_modules` for deployment

---

## Infrastructure Scripts

### `pnpm run plan`
**Purpose**: Run OpenTofu plan
**Dependencies**: OpenTofu, AWS credentials, `.env` file
**CI Coverage**: No
**Notes**: Preview infrastructure changes

### `pnpm run deploy`
**Purpose**: Deploy infrastructure with OpenTofu
**Dependencies**: OpenTofu, AWS credentials, `.env` file
**CI Coverage**: No
**Notes**: Auto-approve enabled; use with caution

---

## External Tool Requirements

| Tool | Scripts Using It | Installation |
|------|------------------|--------------|
| Docker | build-dependencies, localstack:*, test:integration, ci:local:full | `brew install docker` |
| terraform-docs | document-terraform | `brew install terraform-docs` |
| hcl2json | ci:local, build-dependencies | `brew install hcl2json` |
| jq | test-remote-*, localstack:health, validate:docs | `brew install jq` |
| actionlint | lint:workflows | `brew install actionlint` |
| OpenTofu | plan, deploy | `brew install opentofu` |

---

## Adding New Scripts

When adding a new npm script:

1. Add to `package.json` scripts section
2. Document in this registry with:
   - Purpose
   - Dependencies
   - CI Coverage (add to workflow if appropriate)
   - Notes
3. If documented in `AGENTS.md` or `README.md`, CI will validate it exists

**Convention**: Script documentation must stay synchronized with `package.json`. CI enforces this for scripts referenced in main documentation files.

---

## Related Documentation

- [Bash Script Patterns](../Bash/Script-Patterns.md) - Shell script conventions
- [GitHub Wiki Sync](../Meta/GitHub-Wiki-Sync.md) - CI/CD documentation
- [LocalStack Testing](../Integration/LocalStack-Testing.md) - Integration test setup
# Resource Naming

## Quick Reference
- **When to use**: All AWS resources in OpenTofu
- **Enforcement**: Required
- **Impact if violated**: MEDIUM - Inconsistent naming

## Naming Rules

1. **PascalCase for AWS resources**
2. **Match Terraform ID to AWS name**
3. **Include resource type suffix** (Role, Policy, Queue)
4. **Be descriptive and specific**

## Resource Patterns

### Lambda Functions
```hcl
resource "aws_lambda_function" "ProcessFile" {
  function_name = "ProcessFile"
}

resource "aws_lambda_function" "ListFiles" {
  function_name = "ListFiles"
}
```

### IAM Resources
```hcl
resource "aws_iam_role" "ProcessFileRole" {
  name = "ProcessFileRole"
}

resource "aws_iam_role_policy" "ProcessFilePolicy" {
  name = "ProcessFilePolicy"
  role = aws_iam_role.ProcessFileRole.id
}
```

### DynamoDB Tables
```hcl
resource "aws_dynamodb_table" "MediaDownloader" {
  name = "MediaDownloader"
}
```

### S3 Buckets
```hcl
resource "aws_s3_bucket" "MediaFiles" {
  bucket = "media-files-${var.aws_account_id}"
}
```

### SNS/SQS
```hcl
resource "aws_sns_topic" "PushNotifications" {
  name = "PushNotifications"
}

resource "aws_sqs_queue" "FeedlyQueue" {
  name = "FeedlyQueue"
}
```

## Naming Convention Table

| Resource Type | Pattern | Example |
|--------------|---------|---------|
| Lambda | `[Action][Object]` | `ProcessFile` |
| IAM Role | `[Function]Role` | `ProcessFileRole` |
| IAM Policy | `[Function]Policy` | `ProcessFilePolicy` |
| DynamoDB | `[ProjectName]` | `MediaDownloader` |
| S3 Bucket | `[purpose]-${account}` | `media-files-123456` |
| SNS Topic | `[Purpose]` | `PushNotifications` |
| SQS Queue | `[Source]Queue` | `FeedlyQueue` |

## Common Mistakes

```hcl
# ‚ùå Wrong - snake_case
resource "aws_lambda_function" "process_file" {
  function_name = "process_file"
}

# ‚úÖ Correct - PascalCase
resource "aws_lambda_function" "ProcessFile" {
  function_name = "ProcessFile"
}
```

## Best Practices

‚úÖ Use PascalCase consistently
‚úÖ Match Terraform ID to resource name
‚úÖ Include type suffix (Role, Policy, Queue)
‚úÖ Be specific about purpose
‚úÖ Avoid generic names

## Related Patterns

- [File Organization](File-Organization.md)
- [Environment Variables](Environment-Variables.md)
- [OpenTofu Patterns](OpenTofu-Patterns.md)

---

*Use PascalCase for all AWS resources. Match Terraform identifiers to AWS names.*# ElectroDB Adapter Design

## Overview

This project contains the **first production ElectroDB adapter for Better Auth**. The adapter bridges Better Auth's authentication framework with ElectroDB's type-safe DynamoDB ORM, enabling session-based authentication in a single-table design.

## Why This Matters

### The Problem

Better Auth provides official adapters for:
- Prisma (SQL databases)
- Drizzle ORM (SQL databases)
- Kysely (SQL databases)
- MongoDB

But had **no adapter for DynamoDB** - the most common serverless database.

### The Solution

This adapter enables:
- ‚úÖ Zero additional infrastructure (uses existing DynamoDB table)
- ‚úÖ Type-safe operations throughout
- ‚úÖ Single-table design (consistent with best practices)
- ‚úÖ Reusable across any DynamoDB + ElectroDB project
- ‚úÖ Full Better Auth feature support

### Community Value

This adapter can be extracted and published as `@your-org/better-auth-electrodb-adapter` to serve the broader serverless community.

## Architecture

### Layer Model

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Better Auth Framework           ‚îÇ
‚îÇ     (auth.api.signInSocial, etc.)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚îÇ Better Auth Adapter Interface
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      ElectroDB Adapter (this file)      ‚îÇ
‚îÇ  ‚Ä¢ Bidirectional transformers           ‚îÇ
‚îÇ  ‚Ä¢ Type conversions                     ‚îÇ
‚îÇ  ‚Ä¢ Error handling                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚îÇ ElectroDB Entity API
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     ElectroDB Entities (type-safe)      ‚îÇ
‚îÇ  Users | Sessions | Accounts | Tokens   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚îÇ DynamoDB DocumentClient
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   DynamoDB Single Table (MediaDownloader)‚îÇ
‚îÇ        With optimized GSIs              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Core Concepts

### 1. Bidirectional Transformers

The adapter implements transformation functions in both directions:

**Better Auth ‚Üí ElectroDB**:
```typescript
transformUserFromAuth(authUser: Partial<User>): ElectroUserCreate
transformSessionFromAuth(authSession: Partial<Session>): ElectroSessionCreate
transformAccountFromAuth(authAccount: Partial<ExtendedAccount>): ElectroAccountCreate
```

**ElectroDB ‚Üí Better Auth**:
```typescript
transformUserToAuth(electroUser: Partial<ElectroUserItem>): User
transformSessionToAuth(electroSession: Partial<ElectroSessionItem>): Session
transformAccountToAuth(electroAccount: ElectroAccountItem): ExtendedAccount
```

### 2. Type Safety

Every transformation maintains full TypeScript type safety:

```typescript
// ElectroDB create types - what we send to database
type ElectroUserCreate = {
  userId: string
  email: string
  emailVerified: boolean
  firstName: string
  lastName: string
  identityProviders: IdentityProvidersData
}

// ElectroDB response types - what we get back from database
type ElectroUserItem = EntityItem<typeof Users> & {
  createdAt?: number
  updatedAt?: number
}
```

### 3. Schema Mapping

Better Auth expects certain fields that don't map 1:1 to ElectroDB:

| Better Auth Field | ElectroDB Field | Transformation |
|------------------|----------------|----------------|
| `User.name` | `firstName` + `lastName` | Split/join name |
| `User.createdAt` (Date) | `createdAt` (number) | Date ‚Üî timestamp |
| `Session.expiresAt` (Date) | `expiresAt` (number) | Date ‚Üî timestamp |
| `Account.accountId` | `providerAccountId` | Field rename |
| `null` values | `undefined` | ElectroDB compatibility |

## Implementation Details

### Adapter Interface

The adapter implements Better Auth's expected database interface:

```typescript
export function createElectroDBAdapter() {
  return {
    id: 'electrodb',

    // User Operations
    createUser(data: Partial<User>): Promise<User>
    getUser(userId: string): Promise<User | null>
    getUserByEmail(email: string): Promise<User | null>
    updateUser(userId: string, data: Partial<User>): Promise<User>
    deleteUser(userId: string): Promise<void>

    // Session Operations
    createSession(data: Partial<Session>): Promise<Session>
    getSession(sessionId: string): Promise<Session | null>
    updateSession(sessionId: string, data: Partial<Session>): Promise<Session>
    deleteSession(sessionId: string): Promise<void>

    // Account Operations
    createAccount(data: Partial<ExtendedAccount>): Promise<ExtendedAccount>
    getAccount(accountId: string): Promise<ExtendedAccount | null>
    linkAccount(userId: string, accountId: string): Promise<void>

    // Verification Token Operations
    createVerificationToken(data: {identifier: string; token: string; expiresAt: Date}): Promise<void>
    getVerificationToken(token: string): Promise<{identifier: string; token: string; expiresAt: Date} | null>
    deleteVerificationToken(token: string): Promise<void>
  }
}
```

### Name Splitting Utility

Better Auth stores full names, but our schema separates first/last names:

```typescript
export function splitFullName(fullName?: string): {firstName: string; lastName: string} {
  const parts = (fullName || '').split(' ')
  return {
    firstName: parts[0] || '',
    lastName: parts.slice(1).join(' ') || ''
  }
}

// Examples:
splitFullName("John Doe")           // {firstName: "John", lastName: "Doe"}
splitFullName("John Doe Smith")     // {firstName: "John", lastName: "Doe Smith"}
splitFullName("John")               // {firstName: "John", lastName: ""}
splitFullName("")                   // {firstName: "", lastName: ""}
```

### User Transformations

**Better Auth ‚Üí ElectroDB**:
```typescript
function transformUserFromAuth(authUser: Partial<User> & {id?: string}): ElectroUserCreate {
  const {firstName, lastName} = splitFullName(authUser.name)

  // ElectroDB requires all fields in identityProviders map
  const identityProviders: IdentityProvidersData = {
    userId: '',
    email: '',
    emailVerified: false,
    isPrivateEmail: false,
    accessToken: '',
    refreshToken: '',
    tokenType: '',
    expiresAt: 0
  }

  return {
    userId: authUser.id || uuidv4(),
    email: authUser.email!,
    emailVerified: authUser.emailVerified ?? false,
    firstName,
    lastName,
    identityProviders
  }
}
```

**ElectroDB ‚Üí Better Auth**:
```typescript
function transformUserToAuth(electroUser: Partial<ElectroUserItem>): User {
  return {
    id: electroUser.userId!,
    email: electroUser.email!,
    emailVerified: electroUser.emailVerified ?? false,
    name: `${electroUser.firstName ?? ''} ${electroUser.lastName ?? ''}`.trim(),
    createdAt: new Date(electroUser.createdAt ?? Date.now()),
    updatedAt: new Date(electroUser.updatedAt ?? Date.now())
  }
}
```

### Session Transformations

**Better Auth ‚Üí ElectroDB**:
```typescript
function transformSessionFromAuth(authSession: Partial<Session> & {id?: string; deviceId?: string}): ElectroSessionCreate {
  return {
    sessionId: authSession.id || uuidv4(),
    userId: authSession.userId!,
    expiresAt: authSession.expiresAt
      ? authSession.expiresAt.getTime()
      : Date.now() + 30 * 24 * 60 * 60 * 1000,
    token: authSession.token || uuidv4(),
    ipAddress: authSession.ipAddress ?? undefined,  // null ‚Üí undefined
    userAgent: authSession.userAgent ?? undefined,  // null ‚Üí undefined
    deviceId: authSession.deviceId
  }
}
```

**ElectroDB ‚Üí Better Auth**:
```typescript
function transformSessionToAuth(electroSession: Partial<ElectroSessionItem>): Session {
  return {
    id: electroSession.sessionId!,
    userId: electroSession.userId!,
    expiresAt: new Date(electroSession.expiresAt!),
    token: electroSession.token!,
    ipAddress: electroSession.ipAddress ?? undefined,
    userAgent: electroSession.userAgent ?? undefined,
    createdAt: new Date(electroSession.createdAt ?? Date.now()),
    updatedAt: new Date(electroSession.updatedAt ?? Date.now())
  }
}
```

### Account Transformations

**Better Auth ‚Üí ElectroDB**:
```typescript
function transformAccountFromAuth(authAccount: Partial<ExtendedAccount> & {id?: string}): ElectroAccountCreate {
  return {
    accountId: authAccount.id || uuidv4(),
    userId: authAccount.userId!,
    providerId: authAccount.providerId!,
    providerAccountId: authAccount.accountId || '',  // Field name difference!
    accessToken: authAccount.accessToken ?? undefined,
    refreshToken: authAccount.refreshToken ?? undefined,
    expiresAt: authAccount.expiresAt ?? undefined,
    scope: authAccount.scope ?? undefined,
    tokenType: authAccount.tokenType ?? undefined,
    idToken: authAccount.idToken ?? undefined
  }
}
```

**ElectroDB ‚Üí Better Auth**:
```typescript
function transformAccountToAuth(electroAccount: ElectroAccountItem): ExtendedAccount {
  return {
    id: electroAccount.accountId,
    userId: electroAccount.userId,
    accountId: electroAccount.providerAccountId,  // Field name difference!
    providerId: electroAccount.providerId,
    accessToken: electroAccount.accessToken ?? null,
    refreshToken: electroAccount.refreshToken ?? null,
    idToken: electroAccount.idToken ?? null,
    scope: electroAccount.scope ?? null,
    tokenType: electroAccount.tokenType ?? null,
    expiresAt: electroAccount.expiresAt ?? null,
    createdAt: new Date(electroAccount.createdAt),
    updatedAt: new Date(electroAccount.updatedAt)
  }
}
```

### Update Operations

Updates use partial types to only send changed fields:

```typescript
type ElectroUserUpdate = Partial<Pick<ElectroUserCreate, 'email' | 'emailVerified' | 'firstName' | 'lastName'>>

function transformUserUpdateFromAuth(authUpdate: Partial<User>): ElectroUserUpdate {
  const updates: ElectroUserUpdate = {}

  if (authUpdate.email) updates.email = authUpdate.email
  if (authUpdate.emailVerified !== undefined) updates.emailVerified = authUpdate.emailVerified
  if (authUpdate.name) {
    const {firstName, lastName} = splitFullName(authUpdate.name)
    updates.firstName = firstName
    updates.lastName = lastName
  }

  return updates
}

async updateUser(userId: string, data: Partial<User>): Promise<User> {
  const updates = transformUserUpdateFromAuth(data)
  const result = await Users.update({userId}).set(updates).go()
  return transformUserToAuth(result.data)
}
```

## Query Optimization

### Email Lookup

Original implementation (slow):
```typescript
// ‚ùå Full table scan
const result = await Users.scan
  .where(({email: emailAttr}, {eq}) => eq(emailAttr, email))
  .go()
```

Optimized implementation (fast):
```typescript
// ‚úÖ Indexed query via gsi3
const result = await Users.query.byEmail({email}).go()
```

**Performance Improvement**: 10-100x faster depending on table size

### Session Queries

Efficiently query all sessions for a user:

```typescript
// Uses byUser index (gsi1)
const sessions = await Sessions.query.byUser({userId}).go()

// Sorted by expiresAt (composite sort key)
const activeSessions = sessions.data.filter(s => s.expiresAt > Date.now())
```

### Provider Account Lookup

Find account by OAuth provider:

```typescript
// Uses byProvider index (gsi2)
const account = await Accounts.query
  .byProvider({providerId: 'apple', providerAccountId: 'user123'})
  .go()
```

## Error Handling

### Graceful Degradation

All get operations return `null` instead of throwing:

```typescript
async getUser(userId: string): Promise<User | null> {
  try {
    const result = await Users.get({userId}).go()
    if (!result.data) return null
    return transformUserToAuth(result.data)
  } catch (error) {
    logError('ElectroDB Adapter: getUser failed', {userId, error})
    return null
  }
}
```

### Logging Strategy

All adapter operations log at DEBUG level:

```typescript
logDebug('ElectroDB Adapter: createUser', {data})
```

Errors log with context:

```typescript
logError('ElectroDB Adapter: getUserByEmail failed', {email, error})
```

## Extended Account Type

Better Auth's base `Account` type doesn't include OAuth metadata we persist:

```typescript
type ExtendedAccount = Account & {
  scope?: string | null
  tokenType?: string | null
  expiresAt?: number | null
}
```

This allows storing full OAuth token metadata while remaining compatible with Better Auth's interface.

## Link Account Operation

ElectroDB handles account linking implicitly via the userId composite key:

```typescript
async linkAccount(userId: string, accountId: string): Promise<void> {
  logDebug('ElectroDB Adapter: linkAccount', {userId, accountId})

  // ElectroDB entities already link via userId composite key
  // No additional operation needed - account is already linked via createAccount
}
```

## Testing Strategy

### Unit Testing

The adapter has comprehensive unit tests (`electrodb-adapter.test.ts`):

```typescript
describe('ElectroDB Adapter', () => {
  it('should create a user', async () => {
    const mockUser = {id: 'user-123', email: 'test@example.com', name: 'John Doe'}
    const result = await adapter.createUser(mockUser)

    expect(Users.create).toHaveBeenCalledWith({
      userId: 'user-123',
      email: 'test@example.com',
      emailVerified: false,
      firstName: 'John',
      lastName: 'Doe',
      identityProviders: {...}
    })
  })
})
```

### Integration Testing

LocalStack tests validate full round-trip operations:

```typescript
it('should create and retrieve user via email', async () => {
  const user = await adapter.createUser({email: 'test@example.com', name: 'John Doe'})
  const retrieved = await adapter.getUserByEmail('test@example.com')

  expect(retrieved).toEqual(user)
})
```

## Best Practices

### 1. Always Transform

Never pass data directly between layers:

```typescript
// ‚ùå Wrong - skips transformation
const result = await Users.create(authUser)

// ‚úÖ Correct - transforms types
const electroData = transformUserFromAuth(authUser)
const result = await Users.create(electroData)
return transformUserToAuth(result.data)
```

### 2. Handle Null vs Undefined

ElectroDB prefers `undefined`, Better Auth uses `null`:

```typescript
// ‚ùå Wrong - ElectroDB doesn't like null
{ipAddress: null}

// ‚úÖ Correct - Convert null to undefined
{ipAddress: authSession.ipAddress ?? undefined}
```

### 3. Generate IDs When Missing

Better Auth sometimes omits IDs, expecting the adapter to generate them:

```typescript
userId: authUser.id || uuidv4()
sessionId: authSession.id || uuidv4()
```

### 4. Validate Required Fields

Use TypeScript's `!` for fields required by Better Auth:

```typescript
email: authUser.email!,  // Better Auth guarantees this exists
userId: authSession.userId!  // Required field
```

## Performance Metrics

Measured improvements from adapter optimizations:

| Operation | Before | After | Improvement |
|-----------|--------|-------|-------------|
| getUserByEmail | 200-500ms (scan) | 10-50ms (index) | **10-50x faster** |
| createUser + Session | N/A | 50-100ms | New capability |
| getSession + User | 100-200ms | 50-100ms | **2x faster** (single table) |

## Publishing as npm Package

### Package Structure

```
better-auth-electrodb-adapter/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ adapter.ts          # Main adapter code
‚îÇ   ‚îú‚îÄ‚îÄ transformers.ts     # Transformation functions
‚îÇ   ‚îî‚îÄ‚îÄ types.ts            # TypeScript types
‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îî‚îÄ‚îÄ adapter.test.ts     # Unit tests
‚îú‚îÄ‚îÄ README.md               # Documentation
‚îú‚îÄ‚îÄ package.json            # Package metadata
‚îî‚îÄ‚îÄ tsconfig.json           # TypeScript config
```

### Usage Example

```typescript
import {betterAuth} from 'better-auth'
import {createElectroDBAdapter} from '@your-org/better-auth-electrodb-adapter'
import {Users, Sessions, Accounts, VerificationTokens} from './entities'

export const auth = betterAuth({
  database: createElectroDBAdapter({
    entities: {Users, Sessions, Accounts, VerificationTokens}
  })
})
```

### Documentation Requirements

For publication, include:
- Installation instructions
- Entity schema requirements
- GSI configuration guide
- Type definition examples
- Migration guide from other adapters
- Performance tuning tips

## Future Enhancements

### Potential Improvements

1. **Batch Operations**: Support Better Auth batch operations
2. **Caching Layer**: Add optional caching for frequently accessed data
3. **Metrics**: Built-in CloudWatch metrics for adapter operations
4. **Connection Pooling**: Optimize DynamoDB connection reuse
5. **Multi-Region**: Support DynamoDB global tables

### Community Contributions

Areas where the community could contribute:
- Additional OAuth providers
- Performance benchmarks
- Migration tools from other adapters
- Documentation improvements
- Example projects

## References

- [Better Auth Adapter Interface](https://www.better-auth.com/docs/adapters)
- [ElectroDB Documentation](https://electrodb.dev/)
- [DynamoDB Best Practices](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html)
- [Better Auth Architecture](Better-Auth-Architecture.md)
- [ElectroDB Testing Patterns](../Testing/ElectroDB-Testing-Patterns.md)
# Better Auth Architecture

## Overview

This project uses [Better Auth](https://www.better-auth.com/) for authentication, integrated with ElectroDB and DynamoDB in a serverless Lambda architecture. This represents the first production ElectroDB adapter for Better Auth.

## Architecture Components

### Core Stack

```
iOS App ‚Üí API Gateway ‚Üí Lambda ‚Üí Better Auth ‚Üí ElectroDB Adapter ‚Üí DynamoDB
                                                                    ‚Üì
                                                            Single Table Design
```

### Key Technologies

- **Better Auth 1.4.3**: Modern TypeScript authentication framework
- **ElectroDB**: Type-safe DynamoDB ORM with single-table design
- **Apple Sign In**: OAuth provider using ID token flow
- **AWS Lambda**: Serverless compute for auth endpoints
- **DynamoDB**: NoSQL database with optimized GSIs

## Better Auth Integration

### Configuration

Better Auth is configured as a singleton in `src/lib/vendor/BetterAuth/config.ts`:

```typescript
import {betterAuth} from 'better-auth'
import {createElectroDBAdapter} from './electrodb-adapter'
import {fixtureLoggingHooks} from '../../better-auth/fixture-hooks'

export const auth = betterAuth({
  database: createElectroDBAdapter(),
  baseURL: process.env.ApplicationUrl,
  socialProviders: {
    apple: {
      clientId: '<from config>',
      appBundleIdentifier: '<from config>',
      disableIdTokenSignin: false
    }
  },
  session: {
    expiresIn: 60 * 60 * 24 * 30, // 30 days
    updateAge: 60 * 60 * 24
  },
  hooks: fixtureLoggingHooks
})
```

### Key Features

1. **ID Token Authentication**: Direct ID token verification (eliminates 200-500ms token exchange)
2. **Session Management**: 30-day sessions with automatic refresh
3. **Mobile-First**: Token-based auth instead of cookies
4. **Fixture Logging**: Production debugging via CloudWatch
5. **Type Safety**: Full TypeScript support throughout stack

## Database Schema

### Entities

Better Auth uses four ElectroDB entities in the single-table design:

#### Users Entity

Stores user account data and identity provider information.

```typescript
{
  userId: string        // Primary key
  email: string         // Indexed via gsi3 (byEmail)
  emailVerified: boolean
  firstName: string
  lastName: string
  identityProviders: {  // OAuth provider data
    userId: string
    email: string
    emailVerified: boolean
    isPrivateEmail: boolean
    accessToken: string
    refreshToken: string
    tokenType: string
    expiresAt: number
  }
}
```

**Indexes**:
- Primary: `userId`
- byEmail (gsi3): `email` ‚Üí Fast email lookups

#### Sessions Entity

Manages active user sessions with device tracking.

```typescript
{
  sessionId: string     // Primary key
  userId: string        // Indexed via gsi1 (byUser)
  deviceId: string      // Indexed via gsi2 (byDevice)
  expiresAt: number
  token: string         // Hashed session token
  ipAddress: string
  userAgent: string
  createdAt: number
  updatedAt: number
}
```

**Indexes**:
- Primary: `sessionId`
- byUser (gsi1): `userId` + `expiresAt` ‚Üí All sessions for a user
- byDevice (gsi2): `deviceId` + `createdAt` ‚Üí All sessions for a device

#### Accounts Entity

Links users to OAuth providers (Apple, Google, etc.).

```typescript
{
  accountId: string         // Primary key
  userId: string            // Indexed via gsi1 (byUser)
  providerId: string        // 'apple', 'google', etc.
  providerAccountId: string // User ID from provider
  accessToken: string
  refreshToken: string
  expiresAt: number
  scope: string
  tokenType: string
  idToken: string           // OIDC ID token
  createdAt: number
  updatedAt: number
}
```

**Indexes**:
- Primary: `accountId`
- byUser (gsi1): `userId` + `providerId` ‚Üí All accounts for a user
- byProvider (gsi2): `providerId` + `providerAccountId` ‚Üí Reverse lookup

#### VerificationTokens Entity

Temporary tokens for email verification flows.

```typescript
{
  token: string         // Primary key
  identifier: string    // Email or user ID
  expiresAt: number
}
```

**Indexes**:
- Primary: `token`
- byIdentifier (gsi1): `identifier` ‚Üí Find tokens by email

### GSI Sharing Strategy

DynamoDB has 5 GSIs that are shared across all entities:

| GSI | ElectroDB Name | Primary Use | Also Used By |
|-----|---------------|-------------|--------------|
| gsi1 | UserCollection | Query by userId | Sessions, Accounts, VerificationTokens |
| gsi2 | FileCollection | Query by fileId | Sessions (by device), Accounts (by provider) |
| gsi3 | DeviceCollection | Query by deviceId | Users (by email) |
| gsi4 | StatusIndex | Query files by status | Files entity |
| gsi5 | KeyIndex | Query files by key | Files entity |

**Key Insight**: Multiple entities share GSIs by using different partition key prefixes (ElectroDB adds entity type prefixes automatically).

## Authentication Flows

### New User Registration

```
iOS App
  ‚Üì Sign in with Apple ‚Üí ID Token
  ‚Üì POST /registerUser {idToken, firstName, lastName}
RegisterUser Lambda
  ‚Üì auth.api.signInSocial({idToken, provider: 'apple'})
Better Auth
  ‚Üì Verify ID token with Apple's JWKS
  ‚Üì Create user via ElectroDB adapter
ElectroDB Adapter
  ‚Üì transformUserFromAuth()
  ‚Üì Users.create()
DynamoDB
  ‚Üì Store user + account + session
  ‚Üê Return session token
iOS App
  ‚Üê Save token for authenticated requests
```

### Existing User Login

```
iOS App
  ‚Üì Sign in with Apple ‚Üí ID Token
  ‚Üì POST /login {idToken}
LoginUser Lambda
  ‚Üì auth.api.signInSocial({idToken, provider: 'apple'})
Better Auth
  ‚Üì Verify ID token
  ‚Üì Lookup user by provider account ID
ElectroDB Adapter
  ‚Üì Accounts.query.byProvider()
  ‚Üì Create new session
DynamoDB
  ‚Üì Store session
  ‚Üê Return session token
iOS App
  ‚Üê Save token for authenticated requests
```

### Authenticated Request

```
iOS App
  ‚Üì GET /listFiles (Authorization: Bearer <token>)
API Gateway
  ‚Üì Invoke ApiGatewayAuthorizer Lambda
ApiGatewayAuthorizer
  ‚Üì auth.api.getSession({headers})
Better Auth
  ‚Üì Validate session token
ElectroDB Adapter
  ‚Üì Sessions.get({sessionId})
  ‚Üì Users.get({userId})
DynamoDB
  ‚Üê Return session + user
  ‚Üê Generate IAM policy (Allow/Deny)
API Gateway
  ‚Üì Forward request to ListFiles Lambda
  ‚Üê Return response
iOS App
  ‚Üê Receive data
```

## Lambda Integration

### Auth Lambdas

| Lambda | Endpoint | Better Auth API | Purpose |
|--------|----------|----------------|---------|
| RegisterUser | POST /registerUser | signInSocial() | Create new user account |
| LoginUser | POST /login | signInSocial() | Authenticate existing user |
| RefreshToken | POST /refreshToken | getSession() | Refresh expired session |
| ApiGatewayAuthorizer | ALL /* | getSession() | Validate session tokens |

### Environment Variables

Required environment variables for Better Auth:

- `ApplicationUrl`: Base URL for OAuth callbacks (e.g., `https://api.example.com`)
- `SignInWithAppleConfig`: JSON with `{client_id, bundle_id}`
- `DynamoDBTableName`: Name of DynamoDB table

### Error Handling

Better Auth operations are wrapped in try-catch blocks:

```typescript
try {
  const result = await auth.api.signInSocial({...})
  return response(context, 200, result)
} catch (error) {
  logError('Better Auth operation failed', {error})
  return response(context, 401, {message: 'Authentication failed'})
}
```

## ElectroDB Adapter

### Design Pattern

The adapter implements bidirectional transformers between Better Auth and ElectroDB:

```typescript
// Better Auth ‚Üí ElectroDB
transformUserFromAuth(authUser: User): ElectroUserCreate
transformSessionFromAuth(authSession: Session): ElectroSessionCreate

// ElectroDB ‚Üí Better Auth
transformUserToAuth(electroUser: ElectroUserItem): User
transformSessionToAuth(electroSession: ElectroSessionItem): Session
```

### Adapter Methods

The adapter implements the Better Auth database interface:

**User Operations**:
- `createUser(data)`: Create new user account
- `getUser(userId)`: Fetch user by ID
- `getUserByEmail(email)`: Fetch user by email (uses gsi3)
- `updateUser(userId, data)`: Update user fields
- `deleteUser(userId)`: Remove user account

**Session Operations**:
- `createSession(data)`: Create new session
- `getSession(sessionId)`: Fetch session by ID
- `updateSession(sessionId, data)`: Update session
- `deleteSession(sessionId)`: Remove session

**Account Operations**:
- `createAccount(data)`: Link OAuth provider
- `getAccount(accountId)`: Fetch account by ID
- `linkAccount(userId, accountId)`: Associate account with user

**Verification Token Operations**:
- `createVerificationToken(data)`: Create email verification token
- `getVerificationToken(token)`: Fetch verification token
- `deleteVerificationToken(token)`: Remove used token

### Type Safety

All transformers maintain full type safety:

```typescript
type ElectroUserCreate = {
  userId: string
  email: string
  emailVerified: boolean
  firstName: string
  lastName: string
  identityProviders: IdentityProvidersData
}

function transformUserFromAuth(authUser: Partial<User>): ElectroUserCreate {
  const {firstName, lastName} = splitFullName(authUser.name)
  return {
    userId: authUser.id || uuidv4(),
    email: authUser.email!,
    emailVerified: authUser.emailVerified ?? false,
    firstName,
    lastName,
    identityProviders: {...}
  }
}
```

## Fixture Logging

### Hook Integration

Better Auth hooks enable production debugging:

```typescript
import {fixtureLoggingHooks} from '../../better-auth/fixture-hooks'

export const auth = betterAuth({
  // ... config ...
  hooks: fixtureLoggingHooks
})
```

### How It Works

1. **Before Hook**: Logs incoming requests with fixture markers
2. **After Hook**: Logs outgoing responses with fixture markers
3. **CloudWatch**: Stores logs with `__FIXTURE_MARKER__` tag
4. **Extraction**: `bin/extract-fixtures.sh` pulls fixtures from CloudWatch
5. **Processing**: `bin/process-fixtures.js` deduplicates and formats
6. **Testing**: Fixtures used in integration tests

### Fixture Naming

Better Auth fixtures follow PascalCase naming:

- `/auth/sign-in` ‚Üí `BetterAuthSignIn`
- `/auth/sign-up` ‚Üí `BetterAuthSignUp`
- `/auth/refresh-token` ‚Üí `BetterAuthRefreshToken`

## Testing Strategy

### Unit Testing

Better Auth components are mocked using helpers:

```typescript
import {createBetterAuthMock} from '../../../test/helpers/better-auth-mock'

jest.mock('../../lib/vendor/BetterAuth/config', () => ({
  auth: createBetterAuthMock()
}))
```

ElectroDB entities are mocked consistently:

```typescript
import {createElectroDBEntityMock} from '../../../test/helpers/electrodb-mock'

jest.mock('../../entities/Users', () => ({
  Users: createElectroDBEntityMock()
}))
```

### Integration Testing

LocalStack tests validate full Better Auth flows:

1. Create user with Apple ID token
2. Create session
3. Validate session token
4. Query sessions by user
5. Delete session

See `docs/wiki/Testing/ElectroDB-Testing-Patterns.md` for detailed examples.

## Performance Considerations

### Query Optimization

1. **Email Lookup**: Uses gsi3 index instead of table scan (10-100x faster)
2. **Session Queries**: Uses gsi1 to fetch all user sessions efficiently
3. **Provider Lookup**: Uses gsi2 to find accounts by provider ID

### Cold Start Optimization

Better Auth singleton is initialized once per Lambda container:

```typescript
// At top of Lambda handler
import {auth} from '../../lib/vendor/BetterAuth/config'

// Lambda stays warm, auth instance reused
export const handler = async (event, context) => {
  const result = await auth.api.getSession(...)
  return response(context, 200, result)
}
```

### Connection Pooling

ElectroDB shares a single DynamoDB DocumentClient across all entities, reducing connection overhead.

## Security Features

### ID Token Verification

Better Auth verifies Apple ID tokens using:

1. Fetches Apple's public JWKS
2. Validates token signature (RS256)
3. Checks token expiration
4. Validates audience claim (bundle ID)
5. Validates issuer claim (Apple)

### Session Token Security

- Tokens are hashed before storage
- Session expiration enforced server-side
- IP address and user agent logged for audit
- Session invalidation supported

### Environment Variable Safety

Per project conventions, required environment variables are accessed without fallbacks:

```typescript
// ‚úì Correct - fails fast if missing
const config = JSON.parse(process.env.SignInWithAppleConfig)

// ‚úó Wrong - silent failures hide configuration errors
try {
  const config = JSON.parse(process.env.SignInWithAppleConfig)
} catch {
  return fallbackConfig
}
```

## Migration from JWT

The project migrated from custom JWT authentication to Better Auth:

- **Before**: Manual JWT signing/verification with JOSE
- **After**: Better Auth session-based authentication
- **Benefits**:
  - Session management built-in
  - OAuth provider support
  - Type-safe database operations
  - Better mobile app experience
  - Reduced latency (ID token flow)

See `docs/wiki/iOS/Apple-Sign-In-ID-Token-Migration.md` for iOS migration details.

## Troubleshooting

### "Invalid ID token" Error

Check that iOS app is sending `identityToken` not `authorizationCode`:

```swift
// ‚úì Correct
let idToken = String(data: credential.identityToken!, encoding: .utf8)

// ‚úó Wrong
let code = String(data: credential.authorizationCode!, encoding: .utf8)
```

### Session Not Found

Verify session hasn't expired:

```typescript
const session = await auth.api.getSession({headers})
if (!session || session.expiresAt < Date.now()) {
  return response(context, 401, {message: 'Session expired'})
}
```

### Email Lookup Slow

Ensure email GSI is created:

```bash
aws dynamodb describe-table --table-name MediaDownloader \
  | jq '.Table.GlobalSecondaryIndexes[] | select(.IndexName == "DeviceCollection")'
```

## References

- [Better Auth Documentation](https://www.better-auth.com/docs)
- [ElectroDB Documentation](https://electrodb.dev/)
- [Apple Sign In Documentation](https://developer.apple.com/sign-in-with-apple/)
- [iOS ID Token Migration](../iOS/Apple-Sign-In-ID-Token-Migration.md)
- [ElectroDB Adapter Design](ElectroDB-Adapter-Design.md)
- [ElectroDB Testing Patterns](../Testing/ElectroDB-Testing-Patterns.md)
